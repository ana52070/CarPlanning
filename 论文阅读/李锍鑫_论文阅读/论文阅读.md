
## 1029
### Fastlivo2
论文链接：[[1029.fastlivo2-momo]]

#### **1. 摘要 (Abstract) - 解决了什么问题？**

- **核心问题**: 在机器人（尤其是无人机）的同步定位与建图（SLAM）任务中，如何融合激光雷达（LiDAR）、相机（Visual）和惯性测量单元（IMU）这三种传感器的信息，以实现**快速、精确、鲁棒**的状态估计。尤其是在计算资源有限的机载平台上，处理海量数据、应对单一传感器失效（如进入无纹理或无几何结构的区域）是巨大挑战。
    
- **解决方案**: 论文提出了 `FAST-LIVO2`，一个**快速且直接**的激光-惯性-视觉里程计框架。
    - **核心算法**: 它使用**误差状态迭代卡尔曼滤波器 (ESIKF)** 来高效地融合三种传感器的数据。
    - **直接法 (Direct Method)**: 为了提升效率和鲁棒性，它不提取特征点。激光雷达部分直接配准原始点云，视觉部分直接通过最小化图像块的光度误差来对齐图像。这让它在缺乏纹理或几何特征的环境中表现更好。
    - **统一的体素地图**: 激光雷达和视觉数据共享同一个地图。激光雷达点构建地图的几何结构，而相机的图像块则被“贴”在这些点上，为地图上色并提供视觉约束。
    - **关键创新**:
        1. **顺序更新**: 在卡尔曼滤波器中，先用激光雷达数据更新一次状态，再用视觉数据更新一次，解决了两种数据维度不匹配的问题。
        2. **平面先验**: 巧妙地利用激光雷达点云提供的平面信息来辅助和加速图像对齐，提高了精度。
        3. **在线曝光估计**: 能够实时估计相机的曝光时间，从而从容应对剧烈的光照变化（如从室内飞到室外）。
        4. **按需射线投射**: 当激光雷达因离物体太近而没有数据返回时，系统能主动“脑补”出视觉特征点，增强了鲁棒性。

#### **2. 实验部分 (Experiments) - 如何验证的？**

- **硬件平台**:
    - 主要测试平台是一台配备 **Intel i7-10700K CPU** 的台式电脑。
    - 为了验证其在嵌入式设备上的性能，还在 **高通 ARM 处理器 (RB5)** 上进行了测试。
- **测试环境与数据集**:
    - 在多个极具挑战性的**公开数据集**上进行了测试，包括 `NTU-VIRAL`（空中无人机）、`Hilti'22` 和 `Hilti'23`（手持设备在建筑工地）。
    - 制作了一个私有的 `FAST-LIVO2` 数据集，专门用于测试各种**极端场景**，如纯白墙、黑暗隧道、剧烈光照变化等激光雷达或视觉容易失效的环境。
- **对比方法**:
    - 将 `FAST-LIVO2` 与多个当前最先进的开源SLAM系统进行了全面对比，包括 `R3LIVE`、`LVI-SAM`、`FAST-LIO2` (一个非常流行的纯激光雷达方案) 和它自己的前一个版本 `FAST-LIVO`。
- **实验结果**:
    - **精度**: 在所有25个公开数据集序列上，`FAST-LIVO2` 的**平均绝对平移误差 (RMSE) 仅为 0.045 米**，远优于第二名 `FAST-LIVO` 的 0.137 米，精度提升了约3倍。
    - **鲁棒性**: 在各种退化场景（如长廊、纯色墙面、黑暗矿道）中，其他方法大多失效或产生巨大漂移，而 `FAST-LIVO2` 仍能生成高质量、高精度的地图。
    - **效率**: 在 i7 台式机上，平均处理一帧数据仅需 **30.03 毫秒**，远快于 `R3LIVE` 和 `LVI-SAM`。在 ARM 平台上也能达到约 78.44 毫秒，完全满足实时运行的要求。

#### **3. 结论 (Conclusion) - 效果怎么样？**

- **最终效果**: `FAST-LIVO2` 是一个极为成功的多传感器融合SLAM系统，在**精度、鲁棒性和计算效率**上都达到了顶尖水平，全面超越了当前其他主流的开源方案。
- **应用展示**: 论文展示了其强大的实际应用能力，包括：
    1. **完全机载的无人机自主导航**：在无人机上实时运行定位、规划和控制，实现了自主避障飞行。
    2. **高精度空中测绘**: 生成了细节丰富、色彩逼真的大规模三维地图。
    3. **三维模型渲染**: 重建的点云质量非常高，可以直接用于生成三角网格模型和新兴的**3D高斯泼溅 (3D Gaussian Splatting)** 渲染。
- **局限性与未来方向**:
    - **局限**: 作为一个“里程计”，它在超长距离运行时仍会不可避免地累积漂移。
    - **未来工作**: 计划引入**回环检测**和全局优化来消除长期漂移，并利用高质量的彩色点云进行**语义建图**（即识别出地图中的物体）。

### CarPlanner

论文链接：[[CarPlanner.pdf]]


#### **1. 摘要 (Abstract) - 解决了什么问题？**

- **核心问题**: 轨迹规划是自动驾驶的关键，但现有的[[#强化学习（RL）规划方法]]在处理大规模、真实的驾驶场景时，面临着**训练效率低**和**性能不佳**两大挑战。
- **解决方案**: 论文提出了一种名为 `CarPlanner` 的**一致性自回归规划器**。
    - 它采用**自回归结构**，可以高效地进行大规模强化学习训练。
    - 引入了**时间一致性**的概念，确保在规划轨迹的每一步都保持连贯，从而使策略学习更稳定。
    - 利用一个“生成-选择”框架，并设计了由专家经验引导的奖励函数，简化了强化学习的训练难度，提升了最终性能。
- **主要成就**: 论文宣称，这是**首次**证明基于强化学习的规划器，在极具挑战性的大规模真实世界数据集 `nuPlan` 上，其性能能够**超越**当前最先进的基于模仿学习（IL）和基于规则（Rule-based）的方法。

#### **2. 实验部分 (Experiments) - 如何验证的？**

- **硬件平台**: 实验在 **2 张 NVIDIA 3090 GPU** 上进行。
- **测试环境**:
    - **数据集与模拟器**: 使用了 `nuPlan` 数据集，这是一个为自动驾驶规划设计的大规模闭环仿真平台。它包含了在4个不同城市采集的1500小时真实驾驶数据。
    - **基准测试**: 在 `Test14-Random` 和 `Reduced-Val14` 这两个公开的基准上进行了测试。
- **评估指标**: 主要使用官方的**闭环分数 (Closed-loop Score, CLS)**，这个分数综合评估了规划器的**安全性**（如碰撞率）、**舒适性**、**行车效率**（进度）以及是否遵守交通规则等多个维度。
- **实验结果**:
    - `CarPlanner` 在 `Test14-Random` 基准测试中的综合分数（CLS-NR）达到了 **94.07**，显著高于当时最强的基于规则的方法 PDM-Closed (90.05) 和基于模仿学习的方法 PLUTO (91.92)。
    - 在保证高安全性的前提下，`CarPlanner` 在**行车效率 (S-PR)** 指标上提升尤为明显，这意味着它规划的路线更有效率，不会过于保守。

#### **3. 结论 (Conclusion) - 效果怎么样？**

- **最终效果**: 论文成功证明了 `CarPlanner` 作为一个一致性自回归框架的有效性。他们训练出的强化学习规划器，在性能上全面超越了现有的其他强化学习、模仿学习和基于规则的顶尖方法。
- **研究潜力**: 这项工作凸显了强化学习在解决复杂自动驾驶规划问题上的巨大潜力，能够有效应对模仿学习中常见的分布偏移和因果混淆等难题。
- **局限性与未来方向**:
    - **局限**: 论文也坦诚，强化学习方法的设计非常精细，容易受到输入数据的影响，并且可能对训练环境产生[[#过拟合]]。此外，目前依赖“专家引导”的奖励函数，可能会限制算法发现超越人类驾驶员更优策略的潜力。
    - **未来工作**: 未来的研究方向是开发更鲁棒的强化学习算法，使其能够在多变的环境中自主探索和泛化，摆脱对专家数据的强依赖。

#### 4.未知概念名词解释

##### 强化学习（RL）规划方法
强化学习（RL）规划方法就像是让智能体在一个环境中通过不断尝试不同动作，根据环境反馈的奖励来学习最优行动策略的过程。比如在自动驾驶中，智能体就是自动驾驶系统，环境是道路情况，动作是车辆的各种驾驶操作（如加速、转弯等），奖励就是根据驾驶表现（如是否安全、是否高效等）给予的反馈。强化学习规划的目标就是让自动驾驶系统学会在各种道路情况下，都能选择最优动作，实现安全高效驾驶。 


##### 过拟合
用 “教孩子做数学题” 的例子，就能把 “过拟合” 讲得特别明白 —— 核心就是 “学太死，只会做原题，换个花样就懵了”。

先从 “正常学习” 说起：  
如果孩子学 “加法” 时，既练了 “1+2”“3+5”，也理解了 “把两个数合起来” 的逻辑，那他遇到没见过的题（比如 “4+6”）也能做对。这就像好的 AI 模型：它学的是问题的 “通用规律”，能应对没见过的新情况。

而 “过拟合”，就是孩子走了歪路：  
假设老师只反复练 “1+2=3”“3+5=8” 这两道题，孩子没理解加法逻辑，只死记硬背 “看到 1 和 2 就写 3，看到 3 和 5 就写 8”。结果考试时，题目换成 “1+3”“2+5”，他立马不会了 —— 因为他学的不是 “加法规律”，而是 “原题的细节”，甚至连题目里数字的位置、字体都记下来了，一旦这些细节变了，就没用了。

放到 AI（比如 CarPlanner 这类强化学习模型）里，“过拟合” 就是这样：  
模型在 “训练环境” 里表现特别好 —— 比如训练时用的都是 “晴天、笔直公路、只有 3 辆车” 的场景，模型把这些场景的细节（比如车辆的固定间距、路灯的位置）都 “死记硬背” 下来了，规划轨迹又快又准。  
但一旦换到 “新环境”（比如雨天、弯道、突然窜出自行车），模型就 “懵了”—— 因为它没学到 “应对各种路况的通用规划逻辑”，只学了 “训练场景的专属细节”，换个场景就不管用了。

再结合你提到的 CarPlanner 的局限：  
它说 “可能对训练环境产生过拟合”，意思就是：  
现在模型在 “nuPlan 数据集”（训练用的真实驾驶数据）里表现很好，但如果真上路遇到 “数据里没出现过的情况”（比如极端天气、特殊路口），规划效果可能会变差 —— 因为模型把 “训练数据里的场景细节” 学太细了，反而没抓住 “自动驾驶规划的通用规律”。

总结一下：  
过拟合的本质是 ——**模型把 “训练时的特殊细节” 当成了 “通用规律”，导致在 “没见过的新情况” 下表现拉胯**。就像只会背原题的孩子，换题就翻车；只会 “适应训练场景” 的 AI，换个环境就失灵。


---
## 1030

### 多传感器融合室外移动机器人SLAM系统设计
[[多传感器融合室外移动机器人SLAM系统设计_邝禹聪.pdf]]


#### 1. 摘要 (解决了什么问题)

本文旨在解决室外移动机器人在复杂多变环境下自主移动的难题。传统的单一传感器方案难以应对光照变化、天气影响和复杂地形等挑战。

为此，该研究设计并实现了一个**多传感器融合的SLAM系统**，通过**松耦合**的方式结合了**多线激光雷达、IMU（惯性测量单元）和GPS**三种传感器。该系统的核心目标是：

*   **提高定位与建图的精度和稳定性**：通过传感器间的优势互补，克服单一传感器的局限性。
*   **实现高效的自主导航**：构建一个能够精确构建室外地图、进行高精度定位和可靠路径规划的机器人平台。

该技术可应用于环境检测、搜救、智能农业和无人配送等领域。

#### 2. 实验部分 (用了什么硬件、怎么做的测试)

##### 硬件平台

*   **机器人主体**：
    *   **车架**：金属方管焊接而成。
    *   **轮组**：步进电机驱动大尺寸车轮，以保证越障能力。
    *   **转向**：齿轮齿条式转向结构，节省空间。
*   **核心传感器**：
    *   **激光雷达**：VLP-16（一种16线激光雷达）。
    *   **惯性测量单元**：IMU。
    *   **全球定位系统**：GPS。
*   **控制系统**：
    *   **上位机**：负责处理传感器数据、运行SLAM算法并下发控制指令。
    *   **下位机**：接收上位机指令，将其解析为电机转速以控制底盘运动。

##### 测试流程

1.  **建图阶段 (离线)**：
    *   将机器人放置在起点，启动所有传感器。
    *   以 **1 m/s** 的速度遥控机器人移动，同时使用ROS的`bag`工具录制激光雷达的点云数据。
    *   使用 **NDT (Normal Distributions Transform) 算法** 对录制的点云数据进行离线处理，生成无扭曲、对齐良好的三维点云地图。

2.  **定位阶段**：
    *   加载预先构建好的点云地图。
    *   融合实时获取的 **激光雷达点云（经过降采样）、IMU数据和GPS数据**。
    *   利用 **NDT Matching 算法** 将实时传感器数据与地图进行匹配，从而实现机器人的高精度定位。当机器人偏离初始位置过远时，会利用GPS进行位置校准。

3.  **路径规划与避障阶段**：
    *   在定位成功的基础上，导入预设的路径点 (`waypoint`)。
    *   **A-star (A\*) 算法** (`astar_avoid`模块) 用于规划一条能够规避动态和静态障碍物的安全路径。
    *   **纯跟踪 (Pure Pursuit) 算法** 用于控制机器人精确地沿着规划好的路径行驶。
    *   系统通过速度滤波器处理速度和角速度的异常值，确保机器人行驶平顺。

##### 3. 结论 (效果怎么样)

*   **建图质量高**：实验生成的点云地图**无扭曲、无重影**，各方向上都能精确对齐。
*   **定位稳定精确**：融合了三种传感器的定位系统表现出很强的鲁棒性，即使在**上下坡、树木草丛密集**等复杂场景下，也能实现准确定位。
*   **导航有效**：机器人能够成功地根据A\*算法规划的路径进行自主移动，并利用纯跟踪算法实现稳定、高效的行驶。
*   **总体性能**：实验结果明确表明，采用**多传感器融合技术**能够**显著提高**室外移动机器人在自主移动过程中的**稳定性**和**可靠性**。





### 基于多传感器融合的自主移动机器人导航方法
[[基于多传感器融合的自主移动机器人导航方法_潘美君.pdf]]



#### 1. 摘要 (解决了什么问题)

本文旨在解决现有移动机器人导航技术中的两大核心痛点：

1.  **建图信息单一**：传统的二维激光雷达（LiDAR）地图缺乏三维环境信息，导致机器人对环境的理解不完整。
2.  **视觉SLAM的局限性**：纯视觉SLAM（同步定位与建图）方案容易受到光照变化、快速运动和纹理缺失等环境因素的干扰，影响定位和建图的鲁棒性。

为解决这些问题，该研究提出了一套**多传感器融合导航方案**，其核心贡献包括：

*   **融合建图**：结合 **RGB-D相机、二维激光雷达（LiDAR）和惯性测量单元（IMU）** 的数据，能够同时生成**高精度的二维栅格地图**和带有色彩信息的**三维点云地图**，极大地丰富了环境信息。
*   **改进的路径规划算法**：针对传统局部路径规划算法的缺陷，开发了 **Improved_TEB 算法**。该算法旨在改进 `TEB (Timed Elastic Band)` 算法容易陷入局部最优解以及 `DWA (Dynamic Window Approach)` 算法可能出现速度突变的问题。

最终目标是提升机器人在复杂环境下的建图质量、定位精度和导航效率。

#### 2. 实验部分 (用了什么硬件、怎么做的测试)

##### 硬件平台

*   **主控单元**：
    *   **上位机**：**NVIDIA Jetson Nano**，搭载 ARM Cortex-A57 CPU 和 Maxwell 架构的 GPU，负责运行ROS系统和核心算法。
    *   **下位机**：基于 **STM32** 的控制器。
*   **核心传感器**：
    *   **激光雷达 (LiDAR)**：**思岚科技 (Slamtec) RPLIDAR A1**，一款二维激光雷达，用于生成二维栅格地图。
    *   **深度相机 (RGB-D Camera)**：**奥比中光 (Orbbec) Astar Pro**，用于获取深度信息和彩色图像，以生成三维点云地图。
    *   **惯性测量单元 (IMU)**：**Hibot IMU**，用于提供机器人的姿态信息（角速度、加速度）。
*   **电源**：6V / 6000 mAh 锂电池。
*   **软件环境**：**Ubuntu 18.04** + **ROS Melodic**。

##### 测试流程

实验分为两个主要部分：建图算法对比和路径规划算法对比。

1.  **建图算法测试**：
    *   **对比方法**：
        *   **Karto SLAM**：一种经典的基于图优化的二维激光SLAM算法。
        *   **RTAB-Map (Real-Time Appearance-Based Mapping)**：本文采用的多传感器融合建图方案，同时利用激光雷达、RGB-D相机和IMU数据。
    *   **测试内容**：在同一室内环境下，分别使用两种算法进行建图。
    *   **评价指标**：
        *   **地图质量**：通过可视化工具 `RVIZ` 观察地图的还原度、清晰度和完整性。
        *   **定位精度**：通过比较机器人在地图中的估计位置与真实轨迹（或高精度参考）的误差，计算绝对轨迹误差（ATE）。

2.  **路径规划算法测试**：
    *   **对比方法**：
        *   **DWA (Dynamic Window Approach)**
        *   **TEB (Timed Elastic Band)**
        *   **Improved_TEB (本文提出的改进算法)**
    *   **测试场景**：在通过 RTAB-Map 构建的地图中设置6个导航目标点，并在路径上放置宽度为60cm的障碍物，模拟复杂导航任务。
    *   **测试过程**：每种算法在相同的场景下**重复执行30次**导航任务。
    *   **评价指标**：
        *   **导航成功率/碰撞次数**：记录每种算法在30次测试中发生碰撞的次数。
        *   **导航效率**：记录完成整个导航任务所需的平均时间。

##### 3. 结论 (效果怎么样)

*   **建图效果显著提升**：
    *   相比仅使用二维激光雷达的 **Karto SLAM**，本文提出的基于 **RTAB-Map** 的多传感器融合方案生成的地图在**环境还原度上提升了37.2%，清晰度提升了28.5%**。
    *   在定位精度方面，RTAB-Map方案的**绝对轨迹误差（ATE）均值仅为4.7 cm**，相比Karto SLAM的12.3 cm，**精度提高了62%**。这证明了融合RGB-D和IMU信息能有效校正里程计误差，提高定位建图精度。

*   **导航性能更优**：
    *   **安全性**：在30次导航测试中，**Improved_TEB 算法实现了0次碰撞**，成功率达到100%。相比之下，DWA 算法碰撞5次（成功率83.3%），TEB 算法碰撞3次（成功率90%）。
    *   **效率**：**Improved_TEB 算法的导航效率**相较于 **TEB 算法提升了4.2%**，相较于 **DWA 算法提升了11.5%**。

*   **总体评价**：该研究成功证明了多传感器融合（RGB-D + LiDAR + IMU）在建图方面的巨大优势，并且提出的 **Improved_TEB 算法**在保证安全性的前提下，有效提升了机器人的局部路径规划能力和导航效率。

### 面向矿井环境的激光雷达-惯性-视觉紧耦合SLAM算法
[[面向矿井环境的激光雷达-惯性-视觉紧耦合SLAM算法_卢艳军.pdf]]



#### 1. 摘要 (解决了什么问题)

本文旨在解决**矿井环境下移动机器人SLAM面临的严峻挑战**。矿井环境具有以下特点，导致单一传感器或传统多传感器融合方案性能不佳：

1.  **环境恶劣**：非结构化地形（如崎岖巷道、料堆）、狭窄空间、重复纹理（如相似的巷道壁）导致激光雷达和视觉传感器容易发生退化和误匹配。
2.  **光照条件差**：光照不足、光照突变、粉尘干扰等问题严重影响视觉传感器的特征提取和跟踪能力。
3.  **现有算法的局限性**：
    *   **单一传感器**：精度严重不足，如激光雷达在长廊中退化，视觉在弱光下失效，IMU存在累积漂移。
    *   **紧耦合算法**：虽然精度更高，但现有的一些LVI（激光-惯性-视觉）融合算法（如LIO-SAM, LVI-SAM）计算量大，不适合资源受限的矿用机器人。而一些快速算法（如FAST-LIVO）虽然计算量小，但其采用的**稀疏直接法**对光照变化敏感，在矿井光照突变场景下容易失效，导致位姿估计漂移。

为应对上述问题，该研究在 **FAST-LIVO** 算法的基础上提出了一种**改进的激光雷达-惯性-视觉紧耦合SLAM算法**。其核心创新点是：

*   **改进视觉前端以适应光照变化**：用**鲁棒的LK（Lucas-Kanade）光流法**替代了原有的、对光照敏感的稀疏直接法。光流法通过跟踪稳定特征点（如角点）来实现帧间匹配，对光照变化不敏感，更适合矿井环境。
*   **提高视觉约束质量**：在使用光流法跟踪特征点后，额外使用 **RANSAC（随机样本一致性）算法**来剔除外点（outliers），确保只有高质量的、匹配正确的视觉观测被用于后端优化。
*   **构建高质量彩色地图**：在实现高精度位姿估计的基础上，通过将激光雷达点云投影到对应的图像帧，为点云赋予RGB颜色信息，最终构建出能够清晰反映环境细节的**彩色三维点云地图**。

该算法旨在为矿井等恶劣环境下的移动机器人提供一个**高精度、高鲁棒性、高效率**的SLAM解决方案。

#### 2. 实验部分 (用了什么硬件、怎么做的测试)

##### 硬件平台

*   **传感器组合**：
    *   **激光雷达 (LiDAR)**：**Livox Mid-360**
    *   **惯性测量单元 (IMU)**：内置于Mid-360的6轴IMU
    *   **相机 (Camera)**：**Intel RealSense D435i**
*   **计算平台**：
    *   **仿真测试**：标准PC
    *   **实物测试**：**CODBOT-D100-P** 移动机器人 + **NUC11PAHi7** 机载主控计算机

##### 核心技术实现

1.  **多传感器数据紧耦合融合**：
    *   **IMU前端**：利用IMU的高频数据进行**前向传播**，为系统提供高频率的位姿**先验估计**，并用于补偿激光雷达点云的运动畸变。
    *   **视觉前端 (改进点)**：
        *   不再使用稀疏直接法，而是采用**LK光流法**在连续图像帧之间跟踪稳定特征点（通过Shi-Tomasi角点检测提取）。
        *   对光流法匹配得到的特征点对，使用**RANSAC算法**进行一次提纯，剔除因快速运动或场景变化导致的误匹配点（离群点）。
    *   **后端优化**：
        *   构建一个**迭代误差状态卡尔曼滤波器 (Iterated Error-State Kalman Filter)**。
        *   将三种传感器的观测残差共同纳入优化：
            1.  **IMU先验估计**
            2.  **激光雷达点到平面残差**
            3.  **视觉重投影误差** (来自光流法跟踪的内点)
        *   通过最小化一个包含上述三项的最大后验概率目标函数，迭代求解最优的机器人误差状态，并用其修正IMU预测的位姿，最终输出高精度的位姿估计。

2.  **地图构建**：
    *   **激光雷达局部地图**：使用**ikd-Tree**（一种增量式k-d树）来动态、高效地管理和更新激光雷达点云，支持快速的增、删、查操作。
    *   **视觉局部地图**：通过网格筛选和Shi-Tomasi得分计算，从投影到图像上的激光点中提取显著的视觉特征点，并用一个简单的数组进行管理。
    *   **全局彩色点云地图**：在每次卡尔曼滤波更新获得优化位姿后，将最新的激光雷达点云帧投影到对应的相机图像上，为每个激光点赋予其对应像素的RGB值，形成彩色点云帧。最后，将所有彩色点云帧依据优化后的位姿**拼接**起来，构建全局彩色点云地图。

##### 测试流程

1.  **Gazebo仿真测试**：
    *   搭建了一个长100m、宽5m、高3m的**模拟矿井巷道环境**，包含侧壁和料堆。
    *   让搭载传感器的机器人在仿真环境中以0.5 m/s的速度移动。
    *   对比本文算法与原始**FAST-LIVO**算法的**轨迹精度 (ATE, RPE)** 和**建图效果**。

2.  **公开数据集测试**：
    *   使用 **M2DGR 数据集**中的 `hall_04` 序列进行测试，该序列为室内长廊，特征与矿井环境相似（结构单一、特征稀疏）。
    *   对比本文算法与 **LeGO-LOAM, FAST-LIO, FAST-LIVO** 三种主流算法的**轨迹精度**。
    *   对比本文算法与FAST-LIVO的**计算效率**（单帧平均处理时间）。

3.  **真实模拟环境测试**：
    *   在一个与矿井巷道相似的**真实长走廊**中进行测试。
    *   使用搭载传感器的真实移动机器人平台采集数据。
    *   在测试前，使用**张正友标定法**对相机进行内参标定，并使用 `livox_camera_calib` 工具对激光雷达和相机进行外参标定。
    *   对比本文算法与FAST-LIVO的**建图质量**，观察对空间结构、线条、轮廓的还原清晰度以及噪点抑制效果。

#### 3. 结论 (效果怎么样)

*   **定位精度显著提升**：
    *   在Gazebo仿真矿井环境中，相比FAST-LIVO，本文算法的**ATE和RPE均降低了20%以上**。其中，ATE中值误差降低了**47.29%**，RPE中值误差降低了**36.56%**。
    *   在M2DGR公开数据集上，本文算法的ATE和RPE均方根误差均为最低，优于LeGO-LOAM, FAST-LIO和FAST-LIVO。尤其在**转弯处无明显漂移**，轨迹稳定性更优。

*   **计算效率更高**：
    *   在M2DGR数据集上，本文算法的**单帧平均处理时间为41.09 ms**，相比FAST-LIVO的49.46 ms，**耗时减少了约17%**。这表明改进视觉前端（光流法+RANSAC）比原有的稀疏直接法更高效。

*   **建图质量大幅改善**：
    *   在仿真和真实场景测试中，FAST-LIVO构建的地图存在特征模糊、细节缺失和噪点等问题。
    *   本文算法构建的地图则**特征清晰、结构规整**。无论是巷道侧壁、料堆轮廓，还是走廊的线条和细节，都能被**更清晰、更精准地还原**，且噪点抑制效果更佳。

*   **总体评价**：该研究提出的改进型LVI紧耦合SLAM算法，通过引入**鲁棒且高效的光流法**来替代对光照敏感的稀疏直接法，成功解决了FAST-LIVO算法在矿井等恶劣光照环境下的适应性问题。实验结果全面证明，该算法在**定位精度、轨迹稳定性、计算效率和建图质量**上均取得了显著提升，能够更准确地反映真实环境布局，为矿井机器人的高精度自主导航与环境感知提供了强有力的技术支持。


### 基于深度学习的动态场景视觉SLAM算法
[[基于深度学习的动态场景视觉SLAM算法_王晓栋.pdf]]

#### 1. 摘要 (解决了什么问题)

本文主要解决**视觉SLAM (同步定位与地图构建) 系统在动态环境下面临的精度和鲁棒性下降**的问题。

大多数传统的视觉SLAM算法（如经典的ORB-SLAM2）都基于一个核心假设：**场景是静态的**。然而，在现实应用中，环境中普遍存在动态物体（如行人、车辆），这些物体的运动会干扰SLAM系统后端优化所依赖的特征点，导致位姿估计出现严重偏差，甚至使系统崩溃。

为解决这一难题，该研究提出了一种**将深度学习与传统几何方法相结合**的动态SLAM算法。其核心思想是：

*   在成熟的 **ORB-SLAM2** 算法框架基础上，**引入一个基于YOLOv5的动态目标检测线程**。
*   该线程负责实时识别输入图像中的动态物体。
*   在进行位姿估计（里程计计算）之前，**主动剔除**这些被识别为动态物体的区域内的特征点。
*   通过这种方式，只利用场景中的静态背景特征点进行计算，从而**减少动态目标对系统定位精度的负面影响**。

最终目标是显著提升视觉SLAM算法在含有动态物体的真实场景下的**适用性、定位精度和稳定性**。

#### 2. 实验部分 (用了什么硬件、怎么做的测试)

##### 核心技术与硬件

*   **基础SLAM框架**：**ORB-SLAM2**，一个成熟的、基于特征点的视觉SLAM系统。
*   **动态目标检测网络**：**YOLOv5s**。选择`s`版本是因为其模型轻量，推理速度快，能够满足SLAM系统对实时性的高要求，并且便于未来在移动平台或嵌入式设备上部署。
*   **模型部署**：由于ORB-SLAM2使用C++编写，而YOLOv5基于Python和PyTorch，研究中通过将PyTorch模型转换为 **TorchScript** 格式，解决了跨语言部署问题，实现了在C++环境中的高效调用。
*   **实验平台**：
    *   **数据集**：**TUM数据集**。这是一个由慕尼黑工业大学发布的、广泛用于评估视觉SLAM性能的公开数据集。
    *   **测试序列**：重点使用了 `fr3/walking_xyz` 和 `fr3/walking_static` 两个序列。
        *   `walking_xyz`：包含一个在桌子旁来回行走的动态场景，用于测试算法在强动态干扰下的性能。
        *   `walking_static`：场景与前者类似，但人保持静止，用于对比算法在准静态环境下的表现。
    *   **评估工具**：**EVO (Evaluation of Odometry and SLAM)**，一个用于评估SLAM轨迹精度的常用Python工具。

##### 测试流程

1.  **系统构建**：
    *   在ORB-SLAM2的系统架构中，**新增一个独立的YOLO目标检测线程**。
    *   该线程接收每一帧输入图像，利用预训练好的 `yolov5s.torchscript.pt` 模型进行推理，识别出预定义的动态类别（如行人、车辆等），并输出这些动态物体的边界框（bounding box）。

2.  **动态特征点剔除**：
    *   在ORB-SLAM2原有的特征提取（Tracking）模块中，将提取到的所有ORB特征点与YOLO线程输出的动态物体边界框进行比较。
    *   **凡是落入动态物体边界框内的特征点，均被标记为“动态点”并从后续的计算中剔除**。
    *   只有未被标记的“静态点”才被用于位姿估计和地图构建。

3.  **运动一致性校验 (进一步优化)**：
    *   在剔除YOLO检测到的动态特征点后，研究还利用**对极几何约束**对剩余的静态特征点匹配对进行二次校验。
    *   通过计算特征点到其对应极线的距离，如果距离大于某个预设阈值，该点对也被视为由误匹配或未检测出的微小运动引起的“动态点”，并被剔除。这进一步保证了用于计算的特征点的可靠性。

4.  **对比实验**：
    *   **基线算法**：原始的 **ORB-SLAM2** 算法。
    *   **对比算法**：**DynaSLAM**，另一个当时主流的动态SLAM算法。
    *   在TUM数据集的动态和静态序列上，分别运行本文提出的算法、ORB-SLAM2和DynaSLAM。
    *   使用EVO工具比较三种算法输出的**估计轨迹**与数据集提供的**真实轨迹 (Ground Truth)**。

##### 评价指标

*   **绝对轨迹误差 (Absolute Trajectory Error, ATE)**：衡量估计轨迹与真实轨迹之间的全局差异。主要关注其**均方根误差 (RMSE)** 和**标准差 (STD)**。
    *   RMSE反映了轨迹的整体准确度，值越小越好。
    *   STD反映了轨迹的波动情况，即稳定性，值越小越好。

#### 3. 结论 (效果怎么样)

*   **在动态场景下性能大幅提升**：
    *   在 `fr3_walking_xyz` 动态序列上，本文算法的**ATE RMSE为0.0128米**，而原始ORB-SLAM2的误差高达0.2919米。**精度提升了约95.6%**。
    *   标准差（STD）也从0.1291米降至0.0068米，**稳定性提升了约94.7%**。
    *   轨迹对比图直观地显示，原始ORB-SLAM2的轨迹在动态物体出现时发生了严重漂移，而本文算法的轨迹则与真实轨迹高度吻合。

*   **优于其他动态SLAM算法**：
    *   在同一动态序列上，本文算法的ATE RMSE（0.0128米）也**优于DynaSLAM**（0.0150米），表明其在处理动态干扰方面具有更强的鲁棒性。

*   **在静态场景下保持高精度**：
    *   在 `fr3_walking_static` 静态序列上，本文算法的ATE RMSE为0.0098米，与原始ORB-SLAM2（0.0098米，修正后应为同一水平）和DynaSLAM（0.0060米）相比，虽然DynaSLAM略有优势，但本文算法依然保持在极低的误差范围内。
    *   这证明了该方法**没有因为引入动态检测模块而牺牲在静态场景下的性能**，具备良好的通用性。

*   **总体评价**：通过结合轻量级的YOLOv5目标检测和传统的对极几何约束，本文提出的方法成功地解决了视觉SLAM在动态环境下的关键痛点。它不仅**极大地提高了定位精度和鲁棒性**，而且保持了系统的高效运行，为视觉SLAM技术在真实复杂场景（如自动驾驶、服务机器人）中的应用提供了一个高效、可靠的解决方案。


### 基于YOLOv8实例分割和稠密建图的起重机视觉SLAM方法研究
[[基于YOLOv8实例分割和稠密建图的起重机视觉SLAM方法研究_谢孟杞.pdf]]


#### 1. 摘要 (解决了什么问题)

本文针对**起重机智能化、无人化升级**过程中，传统视觉SLAM系统在复杂工业场景下面临的核心挑战：

1.  **动态干扰问题**：起重机作业环境中频繁移动的载具、作业人员等动态物体会产生大量干扰特征点，导致传统SLAM系统**定位漂移、地图失真**。
2.  **实时性与精度矛盾**：一些用于处理动态物体的算法（如基于Mask R-CNN的Dyna-SLAM）计算量巨大，**实时性差**；而轻量化方案（如Detect-SLAM）虽然快，但检测精度不足，容易误删或漏删特征点。
3.  **地图稀疏性问题**：传统ORB-SLAM生成的稀疏地图无法满足工业场景中（如路径规划、避障）对环境细节的密集感知需求。

为解决上述问题，该研究提出了一种名为 **SLAM3-YOLOv8** 的新型视觉SLAM系统。其核心创新点在于：

*   **精准、高效的动态物体剔除**：将强大的 **ORB-SLAM3** 框架与最新的 **YOLOv8n-seg 实例分割**网络相结合。利用`n-seg`模型生成的**像素级掩膜 (mask)**，能够比传统边界框 (bounding box) 更精准地识别并剔除动态区域内的ORB特征点。
*   **实时性优化**：采用 **TensorRT** 对YOLOv8n-seg模型的推理过程进行加速，大幅缩短了目标检测的耗时，保证了整个系统在工业场景下的高实时性。
*   **构建高精度稠密地图**：在剔除动态特征点后，集成了一个**稠密建图模块**，利用筛选出的静态特征点和深度信息，构建**无重影、高精度的三维稠密点云地图**。

该系统的最终目标是为工业重载设备（如起重机）的智能化升级，提供一套在动态、复杂环境下**高精度、高实时性、高鲁棒性**的环境感知和建图技术方案。

#### 2. 实验部分 (用了什么硬件、怎么做的测试)

##### 硬件平台与软件环境

*   **CPU**：Intel i9-10900
*   **GPU**：NVIDIA RTX 2080Ti
*   **操作系统**：Ubuntu 18.04
*   **核心库**：CUDA 11.3, Cudnn 8.2.1, TensorRT
*   **传感器**：
    *   **公开数据集测试**：使用TUM数据集，该数据集由深度相机采集。
    *   **真实场景测试**：**Intel RealSense D435i** 深度相机，固定于桥式起重机的小车上。

##### 核心技术实现

1.  **动态特征点剔除**：
    *   在ORB-SLAM3原有的跟踪、建图、回环三个线程基础上，**新增一个独立的目标检测线程**。
    *   该线程接收RGB图像，利用 **YOLOv8n-seg** 模型进行实例分割，为每个识别出的物体（特别是动态物体）生成一个**像素级别的分割掩膜**。
    *   使用**非极大值抑制 (NMS)** 去除重叠的检测框，IoU阈值设为0.7。
    *   在跟踪线程中，将提取的ORB特征点坐标与动态物体的掩膜进行比对，**凡是落在掩膜内的特征点，一律被判定为动态点并予以剔除**。

2.  **网络加速**：
    *   为了在C++环境的ORB-SLAM3中高效运行Python开发的YOLOv8，模型被导出为 **ONNX** 格式。
    *   利用 **TensorRT 引擎** 加载ONNX模型并进行推理。通过模型压缩、内核自动调优等技术，极大地**加速了YOLOv8的推理速度**，解决了目标检测带来的额外耗时问题。

3.  **三维稠密地图重建**：
    *   在剔除了动态特征点、完成了位姿估计后，系统利用筛选出的**静态关键帧**进行建图。
    *   通过相机内参，将静态关键帧中每个像素的**二维坐标和深度值**，转换为**三维空间坐标**。
    *   将所有关键帧生成的三维点云进行**拼接**。
    *   最后，使用**统计滤波器**去除离群点，并用**体素滤波器**进行降采样，在保留场景结构的同时减少冗余，最终生成高精度的三维稠密点云地图。

##### 测试流程

1.  **公开数据集验证**：
    *   **数据集**：TUM动态数据集中的5个序列 (`walking_xyz`, `walking_halfsphere`, `walking_rpy`, `walking_static`, `sitting_static`)，覆盖了高动态和低动态场景。
    *   **对比算法**：原始ORB-SLAM3、Dyna-SLAM、SLAM3-YOLOv5。
    *   **评价指标**：
        *   **绝对轨迹误差 (ATE)**：衡量全局轨迹的准确度。
        *   **相对位姿误差 (RPE)**：衡量局部运动估计的准确度，包括平移和旋转误差。
        *   **实时性**：对比各系统单帧跟踪的平均处理时间。

2.  **真实起重机场景验证**：
    *   搭建了一个**桥式起重机运动实验平台**，让起重机大车和小车按预设的矩形轨迹运动。
    *   分别在**静态场景**和有人员走动的**动态场景**下，运行原始ORB-SLAM3和本文的SLAM3-YOLOv8系统。
    *   **定性比较**两种系统生成的**运动轨迹**与理想矩形轨迹的吻合度及闭合情况。
    *   **定性比较**两种系统构建的**三维稠密点云地图**是否存在重影和失真。

#### 3. 结论 (效果怎么样)

*   **定位精度显著提升**：
    *   在TUM高动态数据集上，相比原始ORB-SLAM3，SLAM3-YOLOv8的**绝对轨迹误差(ATE)最大降低了95.42%**，**相对位姿误差(RPE)最大降低了54.15%**。这证明了YOLOv8实例分割在精确剔除动态干扰方面的巨大优势。
    *   在大部分序列中，其精度也优于Dyna-SLAM和基于YOLOv5的系统。

*   **实时性表现优异**：
    *   尽管新增了目标检测线程，但得益于轻量化的YOLOv8n-seg模型和TensorRT的强力加速，系统的**单帧平均处理时间优化至18.08 ms**，甚至**优于**没有目标检测模块的原始ORB-SLAM3系统。这证明了该系统兼具高精度和高实时性。

*   **稠密建图效果出色**：
    *   在动态场景中，原始ORB-SLAM3构建的稠密地图出现了由运动物体（如行走的人）造成的明显**重影和拖尾**。
    *   SLAM3-YOLOv8由于有效剔除了动态特征点，成功构建了**清晰、无重影的静态三维稠密点云地图**，地图质量高，准确性好。

*   **真实起重机场景验证成功**：
    *   在起重机平台的真实测试中，无论是在静态还是动态场景下，SLAM3-YOLOv8生成的**运动轨迹都更接近理想的矩形**，闭合误差更小，鲁棒性更强。
    *   构建的场景地图同样有效避免了动态物体的干扰，地图一致性好。

*   **总体评价**：该研究提出的 **SLAM3-YOLOv8 系统**成功地将YOLOv8的强实例分割能力与ORB-SLAM3的高精度定位框架相结合，并通过TensorRT保证了实时性。实验充分证明，该系统能够有效克服起重机等工业场景中常见的动态干扰问题，**在高精度定位、高实时性和高质量建图方面均表现出色**，为工业重载设备的智能化升级提供了可靠且先进的技术方案。


---

## 1102
### 无人驾驶智能车面向校园场景的自主导航（李小涛）

[[无人驾驶智能车面向校园场景的自主导航_李小涛.pdf]]


==看起来像是最普通的ROS导航。11年的论文。==

#### 一、摘要（解决的问题）

无人驾驶智能车的自主导航是实现其自动驾驶的核心前提，而校园非结构化场景（环境复杂、存在静态与动态障碍物、GPS 数据可能失真等）给自主导航带来挑战。本文针对智能车不同行驶状态与 GPS 数据可信度，设计对应导航策略以解决校园场景自主导航问题，具体如下：

1. **停车 / GPS 数据失真场景**：提出基于激光扫描线的导航算法，通过激光数据判断安全距离内障碍物分布以确定可行方向；同时设计动态环境导航算法，预测动态障碍物与车的相遇情况，更新原算法实现提前避障。
2. **正常行驶场景**：提出基于局部栅格地图的导航算法，利用三个激光扫描获取地面高度信息，划分可行 / 不可行栅格与区域，通过导航评价函数求解最优行驶方向；针对道路环境特殊性，结合车道线检测，引导车辆按交通规则沿车道线行驶。

#### 二、结论（实现的效果）

1. **多状态导航有效性**：针对停车、GPS 数据丢失场景的激光扫描线导航策略，能有效保障智能车在此类情况下正常自主导航；正常行驶时的局部栅格地图导航算法，可让智能车在趋向目标的同时避开未知障碍物，具备良好实时性与鲁棒性。
2. **动态避障可靠性**：动态人体障碍物导航策略，通过跟踪动态障碍物运动趋势，能让智能车提前做出避让动作，配合鸣笛辅助，有效解决动态障碍物环境下的自主导航问题。
3. **道路场景适配性**：专用于道路环境的导航策略，借助车道线检测引导车辆沿车道线行驶，对动态障碍物鸣笛示警、对静态障碍物主动避让，可保证车辆在道路上稳定行驶。
4. **实验验证**：通过校园广场静态 / 动态环境实验、校园道路实验（如大连理工大学第二教学楼周边道路），验证了上述方法能有效实现智能车在校园场景的自主导航。同时也指出待优化方向，如 GPS 遮挡时的定位辅助、大坡度路面导航、方向选择摇摆、车道线检测精度提升等。



### 基于 GPS 定位模块制作高精细校园地图（张紫甜）
[[基于GPS定位模块制作高精细校园地图_张紫甜.pdf]]

==安卓APP，并非ROS高精地图==


#### 一、摘要（解决的问题）

高校校园内教学楼、宿舍楼、学院楼等设施地理位置复杂，不仅新生和外来人员难以快速找到目标地点（如新生入校找不到报名点易造成校园拥挤），甚至在校多年的师生也未必完全熟悉校园布局。为此，以大学空间信息为基础，采集校园地理信息，借助高德地图免费 API 接口，开发高精细校园地图导航 APP，实现自身定位、地图加载、校园内地点搜索和路线导航等功能，解决校园内人员找路难、校园拥挤等问题。

#### 二、结论（实现的效果）

1. **功能实用性**：该基于 Android 平台的校园高精细导航系统（以新疆农业大学为例），能为校园师生及外来人员提供精准帮助，可展示校园详细地图、实现实时定位与路线导航，助力用户快速熟悉校园、高效找到目的地，尤其为大一新生入校提供极大便利，节约时间、提升办事效率。
2. **技术适配性**：通过将校园详细地理信息存储在高德云图，解决了高德地图原有校园地点信息精度不足、未标注校内惯用别名地点的问题；同时采用火星坐标系转换技术，通过特定算法将手机 GPS 获取的经纬度转换为加密的火星坐标，保障位置信息安全，且系统响应时间控制在 5 秒内，用户体验良好。
3. **应用前景**：当前市场成熟地图虽多，但校园专用高精细地图较少，该系统填补了这一需求空白，具备较好的应用前景，后期可基于可维护性设计进一步优化升级，拓展更多校园专属功能。


### ==基于智慧校园的巡逻机器人导航定位技术研究（施鹏）==
[[基于智慧校园的巡逻机器人导航定位技术研究_施鹏.pdf]]

==STM32主控、融合GPS，有空可以细细阅读一下==

#### 一、摘要（解决的问题）

智慧校园背景下，传统校园安保方式效率低、成本高，而现有机器人导航方案存在不足（如图像识别循线易受环境影响、激光雷达因时间差 / 数据延迟导致运动畸变）。为此，设计基于 GPS 导航技术的校园自动巡逻机器人，以 STM32 为主控芯片，整合 GPS 模块、陀螺仪模块、数据存储模块及电机舵机控制电路，通过 GPS 获取经纬度数据并存储，陀螺仪提供实时航向角辅助 GPS，解决单一导航方式的缺陷，实现机器人运动轨迹精准计算与自动巡逻功能，满足智慧校园智能化安保需求。

#### 二、结论（实现的效果）

1. **功能实现性**：该校园巡逻机器人经实验验证，能有效完成指定目标路线的自动巡逻 —— 通过离散化目标路线（直道以 20m 间隔设中间点），将坐标存储于单片机 FLASH，结合 GPS 实时定位与陀螺仪辅助航向（经互补滤波处理，解决 GPS 更新慢、陀螺仪震动漂移问题），借助 PID 算法控制电机与舵机，实现方位修正与稳定行驶，成功达成智慧校园场景下的自动巡逻功能。
2. **应用价值**：机器人以 STM32 为核心的硬件架构（含电源、定位、存储、控制模块）与软件设计（分模块程序 + 主程序流程），保障了导航定位的稳定性与高效性，为校园安保提供了智能化、高效化、低成本的解决方案，符合未来校园安保发展方向，可有效提升智慧校园安保水平。


### 基于多传感器融合的校园无人接驳车自主导航系统研究（李一铎）
[[基于多传感器融合的校园无人接驳车自主导航系统研究_李一铎.pdf]]

==双SLAM雷达+IMU，融合算法改进，太高级了==

#### 一、摘要（解决的问题）

随着校园规模扩大，人流量与交通流量增加，传统交通管理效率低，而现有无人车自主导航技术在复杂校园环境中存在局限 —— 环境感知能力有限（如单一传感器易有盲区、受光照等干扰）、路况处理能力受限（缺乏高程信息易误判复杂路面）、应对人流影响不足。为此，采用多传感器融合方案设计校园无人接驳车自主导航系统，具体解决以下问题：

1. **传感器数据关联精度低**：通过改进 ICP 点云配准方法，对双 16 线激光雷达与 9 轴 IMU 进行外参标定，提升多传感器数据关联准确性。
2. **建图定位精度不足**：在因子图框架下融合双激光雷达与 IMU 实现 SLAM 建图，结合 NDT 点云配准与无迹卡尔曼滤波融合定位，解决单一传感器建图定位误差大、易漂移的问题。
3. **路径规划与控制适配性差**：制作含高程与道路语义信息的高精地图，基于 Open-planner 算法实现全局 / 局部路径规划，搭配纯跟踪控制算法，解决传统规划算法适配校园结构化场景不足、控制精度低的问题。

#### 二、结论（实现的效果）

1. **多传感器融合有效性**：
    - 外参标定方面，改进的 ICP 算法优于传统 NDT、ICP 算法，仿真实验中标定结果更接近真值，实车实验成功获取激光雷达间、激光雷达与 IMU 间外参，为数据关联奠定基础。
    - 建图定位方面，提出的 LLIO 系统（双激光雷达 + IMU 紧耦合）在建图精度上优于 LEGO-LOAM、LIO-SAM 等主流算法，仿真中 Z 轴位移最大误差仅 0.4 米，绝对位姿误差均值低至 0.105711；实车实验构建了覆盖整个校园的高精度点云地图，10 公里持续建图与真实环境差异小，定位稳定。
2. **规划控制实用性**：
    - 高精地图提供超视距感知，Open-planner 算法可实现校园结构化道路的全局路径规划（如缓上坡路段精准规划），局部路径规划结合欧式聚类能有效躲避低矮障碍物（如 2 米内锥桶）。
    - 纯跟踪控制算法通过动态调整前视距离，实现车辆稳定横向控制，实车实验中无人接驳车可在校园环境下自主导航，准确识别障碍并平稳行驶。
3. **应用价值**：系统有效提升校园交通管理效率，为自动驾驶技术在交通密集封闭场景（如校园）的应用提供实践经验，同时也为后续极端环境下导航技术优化（如结合大模型）提供基础。


### ==基于 ROS2 的稻麦轮作农田智能路径规划与自动导航系统（陈立邦）==
[[基于ROS2的稻麦轮作农田智能路径规划与自动导航系统_陈立邦.pdf]]


==RTK+ROS nav2 ，和预期的导航方案基本吻合，可以认真研究研究==


#### 一、摘要（解决的问题）

稻麦轮作农田中，传统农机自动导航系统存在稳定性差、智能化水平低的问题 —— 单一传感器定位易受农田复杂环境（如天气、信号遮挡）干扰，现有路径规划算法适配性不足（多为单一 S 型路径，难满足田间作业多样化需求），且缺乏高效的导航控制与可视化交互能力。为此，开发基于 ROS2 的智能农用导航系统，具体解决以下问题：

1. **定位精度与稳定性不足**：构建 RTK-GNSS 高精度定位系统，通过扩展卡尔曼滤波器（EKF）深度融合 GPS 信号、IMU 数据与里程计信息，实现 SLAM 功能，解决单一传感器定位误差大、易漂移的问题，为农机提供实时准确位置信息。
2. **路径规划适配性差**：研发适配 ROS2 的农田路径规划算法（FPP），可根据田块边界坐标、作业宽度生成定制化转弯点与作业路径，解决传统算法仅支持单一路径、无法适配稻麦轮作农田作业需求的问题。
3. **导航可视化与控制低效**：集成 Mapviz 实现导航过程可视化（接入天地地图），依托 ROS2 的 Navigation2 堆栈执行导航任务，解决农田导航过程难监控、控制模块协同性差的问题。

#### 二、结论（实现的效果）

1. **系统精度与稳定性优异**：以 3WPZ-500K 型喷雾机为试验平台，实车试验数据显示，系统平均横向偏移误差 7.68cm、作业导航点平均误差 2.25cm、速度平均误差 0.026m/s、航向角平均误差 0.036rad（约 2°），且能长时间稳定运行（采样时间 720s），内存占用合理（约 3.2GB，缓冲 / 缓存 4.3GB 左右），完全适配低成本 ARM 架构（如香橙派 5B），满足稻麦轮作农田农机调度与田间作业导航的精度和稳定性需求。
2. **功能适配性与实用性强**：
    - FPP 算法可灵活生成 A、B 两种类型作业路径，能根据田块边界坐标自动计算内嵌作业区域与转弯点，覆盖整个作业田块，解决传统单一路径规划的局限。
    - 基于 ROS2 的 Navigation2 堆栈具备高度模块化与可扩展性，可自动根据设定速度（如 1.0m/s）和最小转弯半径完成掉头、转弯动作；结合 Mapviz 可视化功能，能实时监控农机轨迹与环境障碍，提升田间作业的可控性。
3. **场景覆盖全面**：系统成功实现农机 “转场导航”（从仓库到田块入口）与 “田间作业导航”，转场过程中可利用激光雷达避障（如路边树木），田间作业能完成 4 次掉头等复杂动作，即使短暂出现 GPS 信号丢失，恢复器可重启相关节点恢复定位，进一步验证了系统在稻麦轮作农田复杂场景下的可靠性。



---

## 1103
### 自动驾驶高精度地图生成方法研究（郑玲）
[[自动驾驶高精度地图生成方法研究_郑玲.pdf]]
==论文重点在于公路地图生成，对于校园地图有些许偏差，参考性较弱==

#### 一、摘要（解决的问题）

自动驾驶技术对高精度地图需求迫切，但传统导航电子地图存在模型表达不足、数据精细化程度低、精度与现势性差等问题，现有高精度地图又面临地理元素复杂、几何抽象不一致、属性描述非定量化等挑战。为此，研究聚焦自动驾驶高精度地图生成关键问题，具体解决方向如下：

1. **地图模型适配性差**：传统导航电子地图以路段为最小单元，无法满足车道级定位与规划需求；现有高精度地图模型数据结构不完整、格式不统一、扩展性弱。提出 “面向自动驾驶的智能精细地图模型”，填补模型空白，支持道路级 / 车道级路网、动态地理信息与多类型驾驶导引信息的完整表达。
2. **车道级路网生成效率低**：传统多源数据生成路网方法成本高，单一轨迹数据计算量大。提出 “基于平行点对连接剪枝策略的车道级路网快速生成方法”，以无人车采集轨迹与现有路段级路网数据为数据源，通过相似性点对剪枝减少计算量，实现单一轨迹数据自动生成高精度车道级路网。
3. **路网拓扑关系构建难**：现有方法多依赖人工，难以自动建立路段层与车道层的关联关系及交叉口拓扑。提出 “基于多方向约束 PCA 的车道级路网拓扑自动构建方法”，通过 PCA 投影确定路段方向、分离车道网络、提取线性事件点，自动构建路段 - 车道关联及交叉口拓扑，满足自动化构建需求。

#### 二、结论（实现的效果）

1. **模型有效性验证**：提出的智能精细地图模型通过真实区域实验验证，可完整表达道路级 / 车道级路网、广义 POI（含辅助定位地理标签）及动态交通信息，数据结构灵活且支持扩展，能适配自动驾驶对地图 “精细度、动态性、机器可读性” 的核心需求，为高精度地图数据组织与管理提供统一框架。
2. **路网生成效率与精度双优**：
    - 平行点对剪枝策略显著提升效率：与未剪枝方法、基于网格的方法相比，在 11.6 公里实验路段（含 939 个 GPS 采集点、2665 个路段中心线点）中，计算耗时降低约 30%-50%，且数据规模越大，剪枝优势越明显；
    - 精度满足要求：生成的车道中心线与真值对比，平均误差 0.51m、最大误差 1.95m，无人车采集轨迹替代最右侧车道中心线的最大误差≤0.4m，符合自动驾驶车道级定位精度需求（相对精度 10-20cm）。
3. **拓扑构建准确性高**：基于多方向约束 PCA 的拓扑方法，在 24 公里实验区域（含 8046 个 GPS 采集点、68 个路段）中，路段提取精度 100%，物理连接未分段车道提取精度 97.4%，分段车道提取精度 95.2%，线性事件点提取精度 94%，成功建立路段 - 车道关联关系及交叉口拓扑，且拓扑关系与真实路网高度一致，有效支撑后续路径规划与导航。
4. **应用价值显著**：方法仅需单一无人车轨迹数据与现有专业测绘路网数据，无需多源复杂设备，降低高精度地图生成成本；同时为地图厂商提供快速生成车道级路网的技术手段，助力提升高精度地图现势性，为自动驾驶高精度地图产业化落地提供理论与技术支撑。



### 基于 LiDAR/IMU 紧耦合的封闭园区自动驾驶组合定位方法（王哲文）
[[基于LiDAR_IMU紧耦合的封闭园区自动驾驶组合定位方法_王哲文.pdf]]

==虽说和大车计划方向很贴切，但是感觉比较一般，可以仔细读读看看具体啥样==
==大车目前的预期：LiDAR+IMU+RTK+Camera+Odom==

#### 一、摘要（解决的问题）

封闭园区（如工厂、港口园区）自动驾驶定位面临多类技术瓶颈，现有方案难以兼顾精度、鲁棒性与场景适配性，具体问题及解决方案如下：

1. **单一传感器定位缺陷**：
    - **GNSS/INS 定位失效**：封闭园区建筑密集、植被遮挡多，GNSS 信号弱，定位精度无法保证；低成本 IMU 存在误差随时间发散的固有缺陷，无法长时间稳定定位。
    - **纯 LiDAR 定位不足**：仅基于 LiDAR 的 SLAM 技术（如 A-LOAM）存在初始值不准确、特征点提取不稳定、竖直方向误差大（坡度路段易漂移）、易陷入局部最优等问题，难以满足封闭园区复杂路况需求。
2. **多传感器融合痛点**：
    - **数据同步难**：LiDAR 与 IMU 数据采集原理不同，存在时变时间偏移（触发 / 传输延迟）与固定时间偏移（运算单元接收 / 处理延迟），导致数据时间戳错位，融合精度下降。
    - **融合约束不足**：传统多传感器融合未结合车辆运动特性，位姿优化空间大，易出现定位漂移，尤其在弯道、上下坡等场景鲁棒性差。

为此，研究提出**LiDAR/IMU 紧耦合 + 车辆运动学模型约束**的组合定位方案：

- 设计基于可变邻域与特征分类的 LiDAR 特征提取方法，提升激光里程计精度；
- 采用 IMU 预积分策略处理高频率数据，保证位姿估计准确性与系统实时性；
- 构建三维车辆运动学模型（基于阿克曼转向原理），对车辆位姿进行额外约束，改善竖直方向误差；
- 提出补偿优化 + GNSS 授时的多传感器时间同步方法，消除时间偏移影响。

#### 二、结论（实现的效果）

1. **定位精度显著提升**：
    - 与纯激光定位方法 A-LOAM、无车辆运动学模型的 LiDAR/IMU 紧耦合方法相比，本文方法（LiDAR-IMU-VM）在 4 个封闭园区场景（工厂、双创、工业园区）中表现最优：
        - **相对误差**：平移误差降至 0.34%-0.51%（A-LOAM 为 1.00%-1.17%），旋转误差降至 0.0021-0.0040 deg/m（A-LOAM 为 0.0053%-0.0090%）；
        - **绝对误差**：均值控制在 1.14-1.49 米（A-LOAM 为 2.44-3.18 米）；
        - **竖直方向误差**：均值仅 0.11-0.44 米（A-LOAM 为 1.84-3.67 米），有效解决坡度路段漂移问题。
2. **鲁棒性与场景适配性强**：
    - 在直道、弯道、上下坡及植被 / 建筑密集区域，均能稳定输出六自由度位姿，轨迹一致性优于对比方法；
    - 时间同步方法有效消除 LiDAR 与 IMU 时间偏移，避免因数据错位导致的定位误差，系统连续运行时误差无明显累积。
3. **实用性与经济性平衡**：
    - 无需额外传感器（仅用 LiDAR+IMU），降低硬件成本；采用预积分与紧耦合优化，算法实时性满足封闭园区自动驾驶需求（工控机可稳定运行）；
    - 定位精度虽未达厘米级，但完全满足封闭园区（车速≤40km/h）自动驾驶车辆路径规划、避障等功能对定位的要求。
4. **技术验证充分**：
    - 通过林肯 MKZ 自动驾驶试验车采集多场景数据，对比三种定位方法的轨迹、平移 / 旋转位姿、竖直方向误差，实验结果均验证了本文方法的有效性，为封闭园区自动驾驶定位提供可靠技术方案。



### 深度学习和移动边缘计算在自动驾驶的应用综述（黄磊）

[[深度学习和移动边缘计算在自动驾驶的应用综述_黄磊.pdf]]

==感觉不太行，还是得依靠Linux开发板自身算力为主==

#### 一、摘要（解决的问题）

自动驾驶在实际应用中面临计算资源受限、通信时延高、环境感知精度不足等关键瓶颈，传统技术难以兼顾实时性、安全性与智能化需求，具体问题及解决方案如下：

1. **计算与通信资源不足**：
    - **车载计算能力有限**：自动驾驶车辆需处理多传感器（激光雷达、高清相机等）产生的海量数据，传统车载计算单元难以承载目标检测、路径规划等计算密集型任务，易导致处理延迟过高，影响安全决策。
    - **云端传输时延高**：传统云端处理模式需将数据上传至远程云服务器，传输距离远、带宽消耗大，无法满足自动驾驶 “低时延” 需求（如碰撞避免需毫秒级响应）。
    - **移动性影响通信稳定性**：车辆高速移动导致无线链路不稳定，传统通信架构难以保证环境信息实时交互，易出现数据传输中断或延迟。
2. **环境感知与决策精度低**：
    - **传统检测方法局限**：依赖手工提取特征的浅层学习（如支持向量机），在复杂场景（如夜间、暴雨、遮挡）下目标检测（车道线、行人、障碍物）准确率低，易出现误判或漏判。
    - **路径规划动态适应性差**：传统算法（如 A*、快速探索随机树）未考虑实时交通流、突发障碍物等动态因素，仅能实现局部最优，无法适配复杂路况的全局路径优化。
    - **碰撞避免响应滞后**：缺乏对事故风险的实时预测能力，传统碰撞检测依赖硬件传感器（如碰撞传感器），响应速度慢，且难以提前预警潜在风险。

为此，研究提出**深度学习 + 移动边缘计算（MEC）融合方案**：

- 利用 MEC “终端 - 边缘 - 云端” 三级架构，将计算任务卸载至边缘服务器，降低车载计算负担与传输时延；
- 采用深度学习模型（深度玻尔兹曼机、深度强化学习、深度森林等）提升目标检测精度与路径规划、碰撞预测的智能化水平，解决传统方法的场景适配性与决策鲁棒性问题。

#### 二、结论（实现的效果）

1. **多场景应用效果显著**：
    - **目标检测精度大幅提升**：
        - 车道检测：基于深度神经网络的方法在复杂场景（阻塞、分叉路口）检测准确率超传统算法，夜间错误率低至 1.14%；端到端车道检测器通过加权最小二乘拟合，70 帧条件下性能较传统两步法明显优化。
        - 车辆与环境检测：卷积神经网络融合激光雷达与相机数据，可精准估计障碍物相对速度、三维位置，查准率与查全率显著高于硬件监测方法；尖峰神经网络通过时间编码，在降低能耗与延迟的同时，实现目标快速识别。
        - 行人检测：部分上下文网络结合身体语义与上下文信息，对遮挡行人的误码率降低，平均检测准确率超 90%，有效提升自动驾驶安全性。
    - **路径规划动态适配性增强**：
        - 基于深度强化学习的路径规划，综合交通流预测（多层感知器模型、多任务学习网络）与实时路况，车辆成功到达率提升至 90%，可适配动态道路网络（如突发拥堵、天气变化）；
        - 多尺度卷积神经网络在无车道标志场景下仍能可靠识别道路像素，为增强现实导航提供基础，鲁棒性优于传统依赖车道标志的方法。
    - **碰撞避免与风险预警能力提升**：
        - 深度学习碰撞检测模型（如 DeepCrash）准确率达 96%，可快速识别高速头部碰撞与单车事故；递归神经网络结合时空特征，能挖掘交通事故深层分布模式，实现风险提前预警。
        - 堆栈去噪自动编码器融合交通事故数据与 GPS 记录，可实时评估交通风险并优化安全路线，减少事故发生概率。
2. **技术融合价值凸显**：
    - MEC 的分布式计算架构有效降低时延：将目标检测、数据处理等任务卸载至边缘服务器，减少数据传输量，系统响应时间缩短，满足自动驾驶实时性需求（如边缘侧处理时延较云端降低 50% 以上）。
    - 深度学习与 MEC 协同提升资源利用率：边缘服务器承担深度学习模型训练与推理，缓解车载设备计算压力，同时通过模型优化（如减少卷积过滤器）降低边缘节点资源消耗，平衡精度与能耗。
3. **现存挑战明确**：
    - 实时性待突破：5G 虽降低传输时延，但海量传感器数据（图像、视频）的实时分析与结果反馈仍需进一步优化；
    - 隐私保护不足：分布式深度学习训练中易出现成员攻击，导致用户数据隐私泄露；
    - 车辆移动性适配难：车辆高速移动影响无线链路稳定性，给计算与通信资源动态分配带来挑战，需进一步探索移动规律以优化架构。


### 自动驾驶在无人配送领域的应用研究（潘霞）
[[自动驾驶在无人配送领域的应用研究_潘霞.pdf]]

==只是说了自动驾驶有这么一个应用方向，没有说技术上的细节==

#### 一、摘要（解决的问题）

城市末端配送（快递、外卖等）面临效率低、成本高、供需矛盾突出等行业痛点，传统人力配送模式难以适配业务增长与场景需求，具体问题及解决方案如下：

1. **末端配送效率与成本矛盾**：
    - **时空分散导致效率低**：配送需求在时间（如早晚高峰、重复配送）、空间（社区、写字楼、高校等分散点位）上高度分散，传统配送需大量站点与人员，易出现等待时间长（如高校菜鸟驿站排队取件）、人力成本高的问题。
    - **业务体量激增带来配送压力**：2019 年我国快递量达 635 亿件、实时配送业务 185 亿件，传统人力配送能力难以匹配暴增的需求，存在配送延迟、丢件漏件风险。
2. **自动驾驶技术落地难**：
    - **复杂场景适配性差**：高级别自动驾驶在城市开放道路面临安全冗余高、技术整合难（多传感器协同、决策算法鲁棒性）等问题，短期内难以量产落地。
    - **政策与法规不完善**：全无人化自动驾驶缺乏明确的监管标准与责任界定，制约技术商业化应用。
3. **传统配送模式安全性与适应性不足**：
    - **恶劣场景作业风险高**：人力配送在夜间、低温、暴雨等场景下效率下降，且存在交通安全隐患；
    - **交通拥堵加剧配送压力**：传统配送车辆（如电动三轮车）无序行驶易加重城市交通拥堵，进一步影响配送时效。

为此，研究提出**自动驾驶技术赋能无人配送**的解决方案：

- 以低速无人配送车为载体，结合自动驾驶核心技术（多传感器融合、路径规划、组合定位），适配高校、社区等封闭 / 半封闭场景，解决末端配送时空分散问题；
- 探索 “人机协同” 过渡模式，在技术与政策不完善阶段平衡自动化与人工干预，降低落地门槛；
- 构建 “上游零部件 - 中游车辆运营 - 下游服务落地” 的商业模式，推动无人配送规模化应用，同时为自动驾驶技术提供场景验证，加速技术迭代。

#### 二、结论（实现的效果）

1. **场景化应用成效显著**：
    - **高校场景效率提升**：通过无人配送车与快递柜结合，借助视觉识别算法实现货物分类与精准投递，减少取送时间消耗；实时监控功能降低地址失误与物品损坏率，改善师生取件体验，缓解驿站排队难题。
    - **封闭 / 半封闭区域常态化运行**：以北京顺义试点为例，无人配送车在 8 个社区实现 300 天持续运营，累计订单超 1 万单，无人车订单占比超 60%，验证了区域内无人配送的可行性与稳定性，为末端即时配送提供实践参考。
    - **恶劣场景适配性增强**：无人配送车可承担夜间、低温等人力作业风险高的任务，将配送人员转移至安全环境，同时通过精准调度避免无序行驶，缓解城市交通拥堵。
2. **自动驾驶技术落地加速**：
    - **技术验证与迭代**：低速无人配送场景（车速低、环境相对可控）为自动驾驶关键技术（传感器融合、定位、决策算法）提供低成本、高安全的测试环境，解决高级别自动驾驶在开放道路 “落地难” 问题，推动传感器性能提升（如激光雷达成本降低、线控底盘稳定性增强）与算法优化。
    - **商业化路径清晰**：形成两类成熟商业模式 ——①运营服务模式（如白犀牛、毫末智行），自主运营车辆提供配送服务并收取费用；②软硬件解决方案模式（如新石器、驭势科技），销售 / 租赁车辆或提供集成方案，上游国产零部件占比提升，为量产奠定基础。
3. **产业价值与社会效益凸显**：
    - **降本增效**：无人配送减少人力成本（重复劳动自动化）与时间成本（实时调度优化路径），某试点案例中物流效率提升显著，同时降低传统配送的交通违规与事故率。
    - **未来潜力大**：随着 5G、AI 技术发展，无人配送可拓展至安防巡逻、自动售卖、接驳等多场景；中汽数据自研多场景低速无人车已实现自动配送、人脸识别等功能，联合主机厂推进前装量产，为行业提供模块化技术服务，形成 “研发 - 服务 - 反馈” 的良性闭环。
4. **过渡模式适配当前阶段**：
    - “人机协同” 模式在短期内弥补技术与政策短板，通过人工调度与定期检查保障无人配送安全性，为全无人化配送积累数据与经验，是当前阶段平衡效率与风险的最优选择。




### 具身智能产业发展动向及创新能力研究（钟新龙）
[[具身智能产业发展动向及创新能力研究_钟新龙.pdf]]

==没啥用，大话==

#### 一、摘要（解决的问题）

具身智能作为新一代人工智能的核心方向，在技术落地、产业协同、国际竞争等方面面临多类挑战，传统人工智能 “离身化” 局限与产业发展需求存在差距，具体问题及解决方案如下：

1. **技术层面：跨学科整合难与场景适配性不足**
    - **多技术协同壁垒**：具身智能需融合机器人学、机器视觉、自然语言处理、认知科学等多学科技术，但现有研究多聚焦单一领域（如仅关注机器人本体或算法），缺乏智能系统与物理实体的深度交互设计，导致感知 - 理解 - 执行闭环难以形成（如机器人无法精准响应复杂人类指令）。
    - **复杂场景鲁棒性低**：现有具身智能体（如工业机器人、自动驾驶汽车）在非结构化环境（如恶劣天气、动态障碍物）中感知精度不足、决策滞后，难以适配医疗、家庭等高精度、高安全需求场景。
2. **产业层面：创新要素分散与商业化路径模糊**
    - **资源配置碎片化**：我国具身智能产业存在 “企业单打独斗、高校研究与产业脱节” 现象，关键技术（如具身芯片、高精度传感器）研发投入分散，缺乏跨区域、跨主体的协同创新平台，导致技术转化效率低。
    - **商业模式不成熟**：上游核心零部件（如高端电机、特种传感器）依赖进口，中游设备运营缺乏标准化服务体系，下游应用场景（如医疗康养、智能交通）落地成本高，尚未形成 “技术 - 产品 - 市场” 的完整闭环。
3. **政策与国际竞争层面：标准缺失与全球布局滞后**
    - **监管与评价体系空白**：具身智能涉及人机交互安全、伦理责任界定（如机器人操作失误责任划分），但我国尚未建立统一的技术标准、安全规范及产品评价体系，制约产业规范化发展。
    - **国际竞争压力大**：美国、日本、欧盟等已通过 “国家机器人计划”“机器人新战略” 等政策抢占技术制高点（如美国聚焦通用协作机器人、日本深耕工业机器人），我国在核心算法、高端产品等领域与国际领先水平仍有差距，面临技术 “卡脖子” 风险。

#### 二、结论（实现的效果）

1. **技术突破：多领域协同创新成效显著**
    - **关键技术迭代加速**：我国在自动驾驶、机器视觉、语音识别等领域取得领先成果 —— 自动驾驶方面，清华大学 “视觉中心自动驾驶方案” 广泛落地，过半主机厂推出 L3 级硬件车型，百度、华为等企业突破 V2X、数据闭环技术；机器视觉与语音识别领域专利数量超 10 万件，腾讯、华为掌握触觉传感器、柔性交互等核心专利，为具身智能感知 - 交互能力奠定基础。
    - **大模型赋能具身能力**：国内外企业推出多模态具身模型（如谷歌 PaLM-E、微软 ChatGPT for Robotics、阿里 “千问” 大模型），实现 “自然语言指令 - 物理动作执行” 的端到端响应（如通过对话指挥机器人开门、取物），正向迁移能力显著，多任务处理效率较单一模型提升 30% 以上。
2. **产业发展：创新格局成型与场景落地提速**
    - **创新主体协同发力**：形成 “企业主导、高校为辅” 的格局 —— 企业层面，小米（人形机器人 CyberOne）、优必选（WalkerX 双足机器人）、百度（自动驾驶）等龙头布局全产业链；高校层面，清华大学、浙江大学在具身感知、运动控制等基础研究领域提供技术支撑，2023 年北京市成立人形机器人产业开放联盟，推动 “产学研用” 融合。
    - **场景化应用成果突出**：在封闭 / 半封闭场景（如工业园区、高校），具身智能体已实现规模化应用 —— 工业机器人承担 30% 以上重复性生产任务，效率提升 20%-50%；自动驾驶在示范区（如北京顺义）实现 L4 级常态化运营，无人配送订单占比超 60%；医疗领域，日本 ASIMO 机器人、我国康复机器人已辅助完成手术操作与康复训练。
3. **政策与国际竞争力：顶层设计完善与全球地位提升**
    - **政策体系逐步健全**：国家层面出台《“十四五” 机器人产业发展规划》《“机器人 +” 应用行动方案》，明确具身智能技术攻关方向；地方层面，北京、上海、深圳等推出专项政策（如北京建设人形机器人通用大模型平台、深圳扶持通用型具身智能机器人研发），18 个省级单位发布 33 项自动驾驶政策，形成 “国家引导 + 地方实践” 的推进格局。
    - **国际竞争力稳步增强**：我国具身智能专利数量近五年持续增长，自动驾驶、语音识别等领域专利超 10 万件，国产零部件占比提升（如华为自研芯片、大疆传感器）；在国际市场，我国工业机器人产量占全球 50% 以上，自动驾驶企业（如百度 Apollo）在海外开展技术合作，逐步打破欧美日垄断格局。
4. **现存挑战与未来潜力**
    - **待优化方向**：智能机器人、自然语言处理等领域专利数量较少（不足 1 万件），大模型与物理实体的交互精度、医疗等高风险场景落地仍需突破；国际竞争中，核心算法、高端材料等领域仍需加强自主创新。
    - **长期潜力**：随着 L4 级自动驾驶落地、新能源汽车普及，自动驾驶将成为具身智能核心应用板块；医疗康养、智能家居等场景市场规模预计爆发式增长，未来有望形成 “千亿级” 产业集群，为我国抢占通用人工智能制高点提供支撑。

---
## 1104
### 基于 ROS 的自主跟随式医疗辅助机器人设计（张茜）核心内容提炼

[[基于ROS的自主跟随式医疗辅助机器人设计_张茜.pdf]]

==看的时候没搞懂是如何跟随的，查了一下，ROS中也有跟随这个应用，正好可以用在华北五省服务机器人当中==

#### 一、摘要（解决的问题）

医疗场景中无接触辅助需求迫切，但传统跟随式机器人在复杂环境下存在响应慢、鲁棒性差、适配性不足等问题，具体痛点及解决方案如下：

1. **医疗场景辅助资源短缺与接触风险**：
    - **人力护理不足**：医院医务人员有限，难以兼顾行动不便患者（如输液、携带引流袋患者）的全程辅助，且大量护理人员易造成医疗环境拥挤；
    - **医废处理风险**：医疗废物转运过程中，人工操作易导致病毒传播，需非接触式转运工具降低感染风险。
2. **传统跟随机器人性能局限**：
    - **复杂环境适应性差**：单一运动模型难以应对医院动态场景（如人员穿梭、障碍物多变），易出现跟随滞后或丢失目标；
    - **精度与响应不足**：缺乏实时模型更新机制，对目标运动状态（如突然转弯、变速）的预测准确性低，跟随误差大；
    - **硬件与软件协同弱**：传感器数据处理、运动控制模块分离，难以实现高效数据交互与闭环控制。

为此，研究提出**ROS + 交互式多模型（IMM）算法**的设计方案：

- 以 ROS 系统为框架，利用其硬件抽象层与节点化架构，实现视觉感知、运动控制、远程操作的模块化协同；
- 融合 IMM 算法，通过多并行运动模型（如匀速、转弯模型）预测目标状态，结合贝叶斯估计实时更新模型概率，提升复杂环境下跟随鲁棒性；
- 设计 “远程操作 - 嵌入式计算 - 底层控制” 三级硬件架构，搭配深度相机、IMU 惯性检测模块，保证感知精度与运动闭环控制。

#### 二、结论（实现的效果）

1. **功能适配性与场景价值显著**：
    - **多医疗场景覆盖**：机器人可完成两类核心任务 ——①辅助行动不便患者（如输液时跟随移动，携带医疗设备）；②医废转运（跟随处理人员收集废物，避免接触感染），同时可扩展至其他非接触式跟随场景，满足医疗场景多样化需求。
    - **人力与风险优化**：有效缓解医务人员短缺问题，减少医疗环境拥挤；医废转运环节实现 “无接触操作”，降低病毒传播风险，提升医疗安全水平。
2. **跟随性能与鲁棒性提升**：
    - **动态跟踪精度高**：MATLAB 仿真验证显示，IMM 算法可准确预测目标运动属性（位置、速度、转弯过程），滤波值与真实值偏差小，能精准捕捉目标机动状态（如突然转弯），避免跟随丢失；
    - **复杂环境响应快**：多模型交互与贝叶斯实时更新机制，使系统对医院人员穿梭、障碍物变化的适应性增强，响应时间较传统单一模型缩短 30% 以上，跟随效率显著提升。
3. **软硬件协同与控制可靠**：
    - **模块化协同高效**：ROS 系统的节点化设计（外部信息读取、目标跟踪、运动控制节点独立运行），实现传感器数据（深度相机、IMU）与运动控制的高效交互，硬件抽象层降低设备适配难度；
    - **运动控制精准**：底层 Arduino 控制板接收上层指令后，输出 PWM 信号精准控制电机转速，结合 IMU 惯性检测实现位姿、速度闭环控制，保证机器人转弯、直走等动作准确性，跟随误差控制在厘米级。
4. **现存优化方向**：
    - 目前机器人车轮适配平坦地面，医院场景中可能存在不平路面（如坡道、门槛），需进一步改进车轮结构（如采用全向轮或减震设计），提升地形适配性；
    - 未来可增加避障算法与多目标识别功能，应对医院更复杂的动态障碍物与多患者同时辅助需求。

#### 问：它是如何实现跟随效果的？

##### ROS 中 Follow（跟随）功能的实现方式

在机器人操作系统（ROS）中，Follow（跟随）功能的核心是通过**传感器感知目标、算法处理数据、控制器驱动运动**的闭环流程，让移动机器人实时跟踪目标（人、物体或其他机器人），具体实现路径可分为 “感知 - 决策 - 控制” 三大环节，结合不同软件包与技术方案适配多样化场景需求，以下是详细实现逻辑：

###### 一、目标感知：获取目标位置与状态信息

感知是跟随功能的基础，需通过传感器采集目标的空间位置、运动速度等关键信息，为后续决策提供数据支撑，常用感知方案与技术如下：

1. **基于激光雷达的人体 / 物体检测**利用激光雷达（如 Velodyne、RPLIDAR）获取环境点云数据，通过`people_following`类节点（如`people_msgs`功能包中的检测节点）分析点云轮廓特征：
    
    - 提取目标的几何形状（如人体的高度、宽度特征）或物体的轮廓尺寸，区分目标与背景障碍物；
    - 计算目标相对于机器人坐标系的距离、角度等实时位姿信息，输出为 ROS 话题（如`/people_pose`），供后续模块调用。
        
        该方案抗光照干扰能力强，适合室内外复杂环境，但对目标轮廓的辨识度依赖较高（如需避免与相似尺寸障碍物混淆）。
2. **基于视觉传感器的目标跟踪**结合 RGB 相机或深度相机（如 Kinect、Astra Pro），通过视觉算法（如 YOLO 目标检测、相关滤波跟踪）定位目标：
    
    - 先通过目标检测模型（如`darknet_ros`）识别目标类别（如 “person” 标签），确定目标在图像中的像素坐标；
    - 若使用深度相机，可进一步获取目标的三维空间坐标（通过相机内参将像素坐标转换为世界坐标），输出为`/target_3d_pose`话题；
    - 部分方案会融合多帧视觉数据，通过卡尔曼滤波平滑目标位置波动，减少运动模糊或遮挡导致的感知误差。
3. **多传感器融合感知**当单一传感器存在局限（如激光雷达在狭窄空间易漏检、视觉在弱光环境失效）时，会融合激光雷达与视觉数据：
    
    - 通过`robot_localization`等功能包的传感器融合节点，将激光雷达的距离精度与视觉的类别识别能力结合，提升目标定位的鲁棒性；
    - 例如在医院、仓库等场景，用激光雷达确定目标大致位置，再通过视觉确认目标身份（如特定衣物颜色的人员、特定标识的物体），避免跟踪错误。

###### 二、决策规划：计算机器人跟随路径与策略

决策环节需基于感知到的目标信息，结合机器人自身状态（如当前位置、速度），规划合理的跟随路径与行为策略，核心是 “保持目标跟踪、规避障碍物、维持安全距离”，常用技术方案如下：

1. **基于`move_base`的路径规划适配**`move_base`是 ROS 中经典的导航框架，虽非专为跟随设计，但可通过配置局部规划器（Local Planner）实现基础跟随能力：
    
    - **全局路径约束**：若已知目标的运动趋势（如沿固定走廊移动），可通过`global_planner`规划大致跟随路径，避免机器人偏离目标运动区域；
    - **局部动态调整**：配置`dwa_local_planner`或`teb_local_planner`等局部规划器，将目标实时位置作为 “动态目标点”，让规划器持续生成短距离跟随路径；
    - **避障集成**：利用`move_base`自带的`costmap_2d`（代价地图）功能，在规划跟随路径时自动避开静态障碍物（如墙壁、货架）和动态干扰（如临时闯入的行人），确保跟随过程安全。
2. **基于`tracking_controller`的自定义决策逻辑**针对高精度或特殊场景（如工业流水线物体跟踪、医疗场景人员跟随），需开发自定义`tracking_controller`节点，实现精细化决策：
    
    - **PID 控制策略**：以 “机器人与目标的距离误差、角度误差” 为输入，通过 PID 控制器计算速度指令（线速度、角速度），例如：
        - 当目标远离时，增大线速度；当目标偏离机器人正前方时，调整角速度修正方向，维持目标在机器人视野中心；
    - **深度学习辅助决策**：部分复杂场景（如人群中跟踪特定人员）会引入深度学习模型，预测目标运动意图（如是否转向、变速），提前调整跟随策略（如预判目标转弯时提前减速，避免追尾）；
    - **安全距离动态调整**：根据目标运动速度自适应设置跟随距离（如目标快速移动时增大距离，缓慢移动时缩小距离），通过`dynamic_reconfigure`节点实时调整参数。
3. **目标丢失后的重跟踪机制**为应对目标暂时遮挡（如被其他行人挡住）的情况，决策模块需设计重跟踪逻辑：
    
    - 基于目标历史运动轨迹（如通过`tf`变换记录的目标位置序列），预测短时间内目标可能出现的区域；
    - 若感知模块暂时未检测到目标，机器人先按预测轨迹缓慢移动，同时扩大传感器探测范围（如调整激光雷达扫描角度、相机云台转向），直到重新捕获目标；
    - 若长时间丢失目标（如超过预设阈值），触发 “停止跟随” 或 “请求人工干预” 的反馈机制（如发布`/follow_status`话题提示状态）。

###### 三、运动控制：驱动机器人执行跟随动作

控制环节将决策模块输出的 “速度指令” 转换为机器人的实际运动，通过硬件驱动与闭环反馈确保跟随精度，核心实现方式如下：

1. **速度指令解析与执行**决策模块生成的速度指令（通常为`geometry_msgs/Twist`类型话题，包含线速度`linear.x`和角速度`angular.z`），需通过以下步骤驱动机器人：
    
    - **硬件抽象层适配**：若机器人基于差速驱动（如两轮移动机器人），通过`ros_control`框架的`diff_drive_controller`节点，将`Twist`指令转换为左右车轮的转速（如通过逆运动学计算车轮线速度）；
    - **底层驱动通信**：控制器通过串口（如`serial_ros`）或 CAN 总线，将转速指令发送至机器人的电机驱动板（如 Arduino、STM32），驱动电机转动；
    - **实时反馈**：电机编码器或惯性测量单元（IMU）会采集机器人实际运动数据（如车轮转速、自身位姿），通过`/odom`话题反馈给决策模块，形成运动闭环。
2. **位姿闭环修正**为避免机器人因地面打滑、电机误差导致的跟随偏移，需结合定位信息修正运动轨迹：
    
    - 若机器人配备里程计（如轮式里程计、视觉里程计），通过`ekf_localization`节点融合里程计与 IMU 数据，优化自身位姿估计；
    - 对比 “机器人当前位姿” 与 “目标相对位姿”，实时调整速度指令（如发现机器人偏离目标方向时，增大角速度修正），确保跟随误差控制在预设范围内（如厘米级或分米级，根据场景需求设定）。

###### 四、典型软件包与实现流程示例

以 “室内人员跟随” 场景为例，基于`people_following`+`move_base`+ 激光雷达的实现流程可总结为：

1. **启动感知节点**：运行`rplidar_ros`驱动激光雷达，发布`/scan`点云话题；启动`people_following`节点，从`/scan`中检测人体，输出`/target_pose`（目标相对于机器人的位姿）。
2. **决策模块处理**：`move_base`节点订阅`/target_pose`，将其设为 “动态目标点”；`global_planner`规划从机器人当前位置到目标附近区域的全局路径，`dwa_local_planner`生成局部跟随路径（避开室内桌椅等障碍物）。
3. **控制驱动运动**：`move_base`输出`/cmd_vel`速度指令，`diff_drive_controller`将指令转换为车轮转速，驱动机器人向目标移动；同时通过`/odom`反馈机器人实际运动，修正路径偏差，维持与目标的安全距离（如 1.5 米）。
4. **状态监控与调整**：通过`rviz`可视化目标位置、机器人路径与代价地图，实时监控跟随状态；若目标快速转向，`tracking_controller`自动调整角速度，避免机器人因响应滞后丢失目标。

###### 五、关键优化方向与注意事项

1. **参数调优适配场景**不同场景需调整核心参数以平衡跟随精度与稳定性：
    
    - 局部规划器参数：如`dwa_local_planner`的`max_vel_x`（最大线速度）、`min_vel_theta`（最小角速度），需根据目标运动速度设定（如跟踪行人时降低最大速度，避免冲撞）；
    - 感知阈值参数：如`people_following`的`min_height`（目标最小高度）、`confidence_threshold`（检测置信度），过滤干扰点云（如地面杂物、低矮障碍物）。
2. **版本与硬件兼容性**
    
    - ROS 版本差异：如 ROS 1 中的`move_base`与 ROS 2 中的`nav2`（导航 2.0）接口不同，`nav2`需使用`bt_navigator`替代`move_base`的路径管理功能，需参考对应版本官方文档适配；
    - 硬件选型：激光雷达需匹配检测距离（如室内用 5-10 米量程，室外用 20-50 米量程），视觉传感器需考虑帧率（如至少 15fps 以保证实时性），避免硬件性能不足导致跟随延迟。
3. **鲁棒性增强**
    
    - 多目标区分：若场景存在多个相似目标（如多人并行行走），可通过目标特征绑定（如特定颜色衣物、佩戴的 RFID 标签），结合`unique_id`话题为目标分配唯一 ID，避免跟踪对象混淆；
    - 紧急停止机制：当传感器检测到目标与机器人距离小于安全阈值（如 0.5 米），或出现突发障碍物（如突然闯入的儿童），触发`emergency_stop`服务，立即停止机器人运动，保障安全。

综上，ROS 中 Follow 功能的实现需根据目标类型（人 / 物体）、场景环境（室内 / 室外、静态 / 动态）与精度需求，灵活组合感知传感器、决策算法与控制模块，通过模块化设计降低开发难度，同时通过参数调优与闭环反馈提升跟随的鲁棒性与安全性。



### 基于 ROS 的室外无人车自主导航算法研究（王华东）

[[基于ROS的室外无人车自主导航算法研究_王华东.pdf]]

==主要还是做有关于竞赛地图赛道的，感觉和大车计划的室外大场景不适配==
#### 一、摘要（解决的问题）

大学生智能汽车竞赛中，ROS 无人车在室外环境下易受干扰，难以完成自主导航，具体痛点及解决方案如下：

1. **环境感知抗干扰能力弱**：
    - **锥桶检测精度低**：赛道由锥桶界定，锥桶间距小、回头弯处密集，激光雷达易受其他锥桶或地面噪声干扰，误检 / 漏检锥桶，导致无人车偏离赛道；
    - **点云数据冗余杂乱**：激光雷达采集的原始点云包含过近 / 过远噪声点、异常值，直接用于导航易导致决策错误，且影响算法实时性。
2. **路径规划鲁棒性不足**：
    - **赛道边界建模难**：传统路径规划难以基于锥桶分布精准构建赛道边界，尤其在 S 弯、圆形区域等复杂路段，易出现路径贴合障碍物或抖动问题；
    - **路径平滑性差**：离散锥桶中心点直接拟合路径易产生折线，无人车跟踪时转向频繁，影响行驶稳定性，难以满足竞赛对导航精度与速度的要求。

为此，研究提出 **“激光雷达感知 + DBSCAN 聚类 + Delaunay 三角剖分 + 三次样条插值” 的自主导航算法 **：

- 通过 DBSCAN 聚类对预处理后的点云进行密度聚类，精准提取锥桶空间坐标，滤除噪声干扰；
- 采用 Delaunay 三角剖分对锥桶中心点构建拓扑网络，结合边长、角度约束剔除异常三角形，确定赛道可行区域；
- 提取三角网公共边中点，用三次样条插值 + 当前 / 历史点加权平均平滑路径，最终通过 ROS 话题将路径发送至底层控制模块，实现无人车跟踪行驶。

#### 二、结论（实现的效果）

1. **感知精度与抗干扰能力显著提升**：
    - **锥桶检测准确**：点云预处理（阈值过滤、异常值剔除、角度约束）结合 DBSCAN 聚类（邻域半径 0.4m、最小聚类点数 5），成功滤除地面噪声与离散干扰点，仅保留锥桶有效点云，聚类结果信噪比高，锥桶中心点提取准确率满足竞赛需求；
    - **环境适应性强**：在室外模仿赛场环境（包含直线、S 弯、圆形区域）中，无人车可精准识别锥桶分布，不受周围墙体、地面杂物等干扰，避免因感知错误导致的赛道偏离。
2. **路径规划与跟踪性能优异**：
    - **边界建模精准**：Delaunay 三角剖分结合边长（≤2.0m）、锐角筛选、顶点度（≤4）约束，有效剔除异常三角形，精准构建赛道边界拓扑网络，路径贴合赛道中心，无贴近锥桶或越界情况；
    - **路径平滑稳定**：三次样条插值与加权平均平滑处理后，路径曲线连续无折线，无人车以 1m/s 速度跟踪时，转向平稳，无频繁调整现象，在曲率较大的弯道处仍能保持稳定行驶。
3. **竞赛场景适配性与实用性高**：
    - **满足竞赛要求**：实车测试中，无人车可在无先验地图的情况下自主完成两圈环形赛道导航（第一圈认知赛道），全程无偏离，实时性满足竞赛对算法响应速度的要求（基于昇腾 310 处理器，主频 2GHz，内存 4GB，无明显卡顿）；
    - **成本与硬件兼容**：算法基于低成本激光雷达与标准 ROS 硬件（如 MC9S08AC16CFGE 主控 MCU），符合竞赛 “硬件统一、成本可控” 的公平性要求，为参赛队伍提供可复用的导航方案。
4. **未来优化方向**：
    - 目前仅依赖激光雷达感知，后续可融合相机数据，补充纹理信息，进一步提升复杂环境（如弱光、阴影）下的抗干扰能力，增强导航鲁棒性。


### 基于 ROS 与 YOLO 算法的移动式垃圾分拣机器人设计与实现研究（万燕英）

[[基于ROS与YOLO算法的移动式垃圾分拣机器人设计与实现研究_万燕英.pdf]]
==仅有ROS与Yolo的简单结合，还是没有发现对于解决目标点和目标物之间的问题==
#### 一、摘要（解决的问题）

公共场所复杂高动态环境下，传统垃圾分拣机器人存在导航避障差、识别精度低、人机交互弱等问题，难以满足高效分拣需求，具体痛点及解决方案如下：

1. **导航与避障适配性不足**：
    - **动态环境响应滞后**：传统导航算法（如未优化的路径规划器）在人群流动、障碍物多变的公共场所（如校园餐厅）中，易出现路径规划不合理、避障灵活度低的问题，导致机器人卡顿或碰撞风险；
    - **定位误差大**：移动小车在自主导航时，目标点偏移可达 10-20cm，无法精准到达垃圾投放点或回收区域，影响分拣效率。
2. **垃圾识别精度与效率低**：
    - **传统算法局限**：依赖手工特征提取的识别方法，难以适配垃圾形状不规则、种类多样的特点，识别准确率仅约 60%，易出现误判（如混淆可回收与不可回收垃圾）；
    - **实时性差**：复杂环境下图像数据处理延迟长，无法满足动态场景中快速分拣的需求。
3. **人机交互与操作灵活性弱**：
    - **缺乏智能交互**：传统机器人需人工手动操控，无法接收语音指令，难以适配公共场所用户便捷调用的需求；
    - **抓取稳定性不足**：机械臂末端执行器刚性强，对不规则垃圾（如塑料袋、易拉罐）夹持成功率低，易出现掉落问题。

为此，研究提出 **“ROS 模块化框架 + YOLOv8 视觉识别 + 优化 DWA 导航 + 柔性机械臂” 的解决方案 **：

- 以 ROS 为核心，构建主控制器、导航、视觉识别、机械臂、语音识别模块，实现模块间高效通信；
- 采用 YOLOv8 算法训练垃圾图像数据集，提升垃圾种类、位置、姿态识别的精度与速度；
- 优化动态窗口法（DWA）路径规划器，结合激光雷达与深度相机，实现高精度导航避障；
- 搭配六关节机械臂与柔性末端抓手，结合视觉 - 机械臂标定，提升不规则垃圾抓取稳定性；
- 集成在线（科大讯飞）与离线（PocketSphinx）语音识别，实现人机语音交互，支持用户指令调用。

#### 二、结论（实现的效果）

1. **导航与避障性能显著提升**：
    - **定位精度优化**：通过调优 DWA 导航参数（如将 x 轴最大速度设为 0.26m/s、最大加速度 3.0m/(s²)），定位误差从 10-20cm 降至 10cm 以内，可精准到达目标区域；
    - **动态环境适配**：优化后的 DWA 算法在人群流动、障碍物多变的场景中，导航轨迹与实际运动轨迹重合度高，避障响应快速，无卡顿或碰撞情况，满足公共场所动态需求。
2. **垃圾识别精度与效率双优**：
    - **准确率大幅提升**：YOLOv8 模型经大量垃圾图像（含不同种类、姿态）训练后，识别准确率从约 60% 提升至 90% 以上，且支持中文标签输出（如 “可回收塑料瓶”“厨余垃圾”），结果更直观；
    - **实时性满足需求**：YOLOv8 的端到端检测架构，结合 Nvidia Orin Nano 主控的算力支持，图像处理延迟低，可快速响应动态场景中垃圾投放的实时识别需求。
3. **抓取与交互功能可靠**：
    - **柔性抓取稳定**：六关节机械臂（myCobot280）搭配柔性末端抓手，可自适应不规则垃圾轮廓，抓取成功率超 98%，避免垃圾掉落；
    - **人机交互灵活**：语音识别模块支持在线 / 离线自动切换，自定义 “热词字典” 适配特殊环境，用户可通过语音指令（如 “前往餐厅 A 垃圾点”“将可回收垃圾送至回收箱”）便捷操控机器人，降低人工干预成本。
4. **场景适配性与社会效益突出**：
    - **公共场所落地性强**：实车测试表明，机器人可在校园餐厅等场景中自主完成 “接收指令 - 导航至垃圾点 - 识别抓取 - 送至回收区” 全流程，替代人工分拣，降低劳动强度与人工成本；
    - **环境与社会效益显著**：助力垃圾分类与资源回收，减少人工分拣中的交叉污染风险，为 “机器换人” 提供可行方案，适配环保与公共服务需求。




### 基于激光雷达的自主建图导航移动机器人研究（孙文伟）

[[基于激光雷达的自主建图导航移动机器人研究_孙文伟.pdf]]

==论文主要在讲述对于建图算法的改进，有一定参考性但不是很大==

#### 一、摘要（解决的问题）

化工仓储环境存在有毒、易燃等潜在危险，传统依赖人工管理的模式威胁人员安全，且传统移动机器人在该场景下自主建图与导航存在效率低、鲁棒性不足等问题，具体痛点及解决方案如下：

1. **自主建图效率与精度低**：
    - **边界探测低效**：传统 RRT 算法探测前沿边界点时，随机树扩展盲目，易产生冗余点，且滤波器模块聚类精度差，导致边界点分布不均、重复探索，建图耗时久；
    - **地图构建适配性差**：传统 SLAM 算法（如 Gmapping、Hector-SLAM）在化工仓储大空间、多货架障碍场景下，易出现地图漂移、内存占用过高问题，难以生成完整栅格地图。
2. **路径规划鲁棒性不足**：
    - **收敛速度慢**：传统 RRT 算法因随机采样特性，在复杂障碍环境中无效扩展多，路径搜索效率低；
    - **路径质量差**：规划路径存在较多拐点与冗余点，移动机器人跟踪时转向频繁，且未考虑化工仓储狭窄通道等场景的通行需求，易发生碰撞。

为此，研究提出 **“改进 RRT 自主建图 + APF-PB-RRT * 路径规划” 的解决方案**：

- 自主建图：选用 Cartographer SLAM 算法构建栅格地图，在均值漂移聚类基础上引入最近邻搜索，优化滤波器模块，自适应调整搜索窗口，提升前沿边界点探测效率；
- 路径规划：提出基于人工势场引导的概率偏置双向 RRT * 算法，通过双树扩展、目标偏置采样、人工势场引导新节点生成，结合路径剪枝与三次 B 样条插值平滑路径，提升规划效率与路径质量。

#### 二、结论（实现的效果）

1. **自主建图性能显著提升**：
    - **探测效率优化**：改进滤波器模块后，前沿边界点聚类精度提高，边界点分布更均匀，仿真实验中，相较于传统算法，建图路径长度减少 11.32%，探索时间缩短 6.48%；
    - **地图质量可靠**：Cartographer SLAM 算法结合改进 RRT 探索策略，在 2600m² 仿真化工仓储环境与 256m² 真实楼道环境中，均能生成无明显漂移的完整栅格地图，且自主建图较手动建图探索时间快 8.3%，轨迹长度短 6.8%，适配化工仓储大空间、多障碍场景。
2. **路径规划效率与质量双优**：
    - **收敛速度加快**：APF-PB-RRT_算法通过双树扩展与目标偏置采样，在简单与复杂环境中，较 Bi-RRT、RRT_、GB-RRT * 算法，路径规划时间减少 12.5%-28.89%，节点数降低 15.05%-52.31%；
    - **路径更平滑安全**：经路径剪枝与三次 B 样条插值处理，规划路径拐点减少，在真实环境导航实验中，较传统 RRT * 算法，路径长度缩短 11.4%，导航时间减少 12.5%，可平稳通过化工仓储狭窄通道。
3. **场景适配性与实用性强**：
    - **危险场景替代价值高**：机器人可在化工仓储危险环境中自主完成建图与导航，避免人员直接接触有毒、易燃物质，降低安全风险；
    - **多环境验证有效**：仿真（2600m² 化工仓储模型）与真实环境（楼道多障碍场景）实验均验证，机器人能高效完成建图（平均路径 733m、耗时 1384s）与导航（平均路径 107m、耗时 231s），满足化工仓储自主巡检、物资运输等需求。
4. **未来优化方向**：
    - 目前未完全解决重复探索问题，且仅针对单机器人、静态障碍场景，后续可研究多机器人协同建图，融合深度相机等多传感器，提升动态障碍环境下的避障能力。


### 室外环境下融合激光雷达和单目视觉的 SLAM 算法研究（潘青）

[[室外环境下融合激光雷达和单目视觉的SLAM算法研究_潘青.pdf]]

==算是对于室外环境的SLAM方法进行算法优化改进，比较有参考性，但是优先参考Fastlivo2==

#### 一、摘要（解决的问题）

室外环境中，激光雷达与单目视觉融合的 SLAM 技术面临深度关联误差、跟踪稳定性差、回环检测精度不足等问题，传统算法难以兼顾定位精度与鲁棒性，具体痛点及解决方案如下：

1. **激光视觉里程计精度不足**：
    - **深度关联误差**：传统激光视觉融合方法中，激光雷达深度数据与单目图像特征关联不准确，尤其在激光点云稀疏或环境特征少的场景（如高速公路植被区），易导致位姿估计偏差；
    - **跟踪易丢失**：依赖单一点特征的方法在低纹理、纹理重复环境（如城市道路）中，特征匹配质量低，易出现跟踪失败，影响 SLAM 系统稳定性。
2. **回环检测鲁棒性低**：
    - **特征表述局限**：传统回环检测仅依赖几何特征（如点云强度、高度），对室外环境变化（如临时障碍物、光照变化）敏感，易出现误检或漏检；
    - **计算效率低**：特征匹配过程中冗余数据多，相似度计算耗时，难以满足室外动态场景的实时性需求。

为此，研究提出 **“激光视觉融合里程计 + 语义 - 几何融合回环检测” 的 SLAM 算法 **：

- **激光视觉里程计优化**：融合激光雷达深度数据与单目图像，先通过最小化光度误差完成初步位姿估计，再提取关键帧点线特征（利用室外环境丰富结构特征）与当前帧关联，细化位姿，提升估计精度；
- **回环检测改进**：生成含语义标签的全局描述符，先通过语义描述子筛选候选帧，再将候选帧与当前帧转换为二进制描述符计算相似度，结合时间与几何一致性检验，排除误检，提升回环检测准确性。

#### 二、结论（实现的效果）

1. **激光视觉里程计性能优异**：
    - **位姿估计精度高**：在 KITTI 数据集（含城市、高速公路、乡村等场景）中，相较于 A-LOAM、DVL-SLAM 等方法，所提算法平均平移误差降至 0.80%（A-LOAM 为 1.45%），平均旋转误差 0.37 deg/100m（DEMO、DVL-SLAM 均为 0.40 deg/100m），在 8 个序列中取得最优或次优结果；
    - **跟踪稳定性强**：通过点线特征联合优化，在低纹理、特征稀疏场景（如 KITTI 01 高速公路序列）中，仍能保持稳定跟踪，避免传统点特征方法的跟踪丢失问题。
2. **回环检测鲁棒性与效率双优**：
    - **检测精度高**：在 Semantic KITTI 数据集（含正向 / 反向回环场景）中，所提算法平均 F1 指数达 0.936（SSC 算法为 0.919、SC 算法为 0.839），扩展精度 0.900（SSC 算法为 0.882），尤其在反向回环场景（如 KITTI 08 序列），仍能准确识别，优于 SGPR 等依赖几何特征的方法；
    - **实时性提升**：通过二进制描述符压缩特征数据，单帧处理总耗时仅 0.099s（IRIS 算法为 1.464s、SSC 算法为 1.184s），语义筛选候选帧环节大幅减少后续匹配计算量，满足室外动态场景实时需求。
3. **系统整体适配性强**：
    - **多场景兼容**：算法在城市、乡村、高速公路等室外场景中均表现稳定，如在城市序列（KITTI 00）中平移误差仅 0.66%，乡村序列（KITTI 04）旋转误差 0.38 deg/100m，适配室外复杂环境；
    - **地图一致性好**：将里程计与回环检测结合，构建的点云地图无明显漂移重影（如 KITTI 00 序列），全局一致性优于传统激光 SLAM 方法，为后续路径规划提供可靠地图支撑。
4. **未来优化方向**：
    - 目前未充分处理室外动态物体（如行人、车辆）对 SLAM 的干扰，后续可结合语义信息识别动态目标并排除；
    - 多传感器融合策略可进一步优化，如引入深度学习提升数据关联精度，适配更复杂的室外环境（如暴雨、逆光场景）。

---
## 1105


### 基于视觉 —RTK 的苹果园植保机器人自主导航研究（黄鹏飞）

[[基于视觉—RTK的苹果园植保机器人自主导航研究_黄鹏飞.pdf]]
==距离我们还有点遥远==

#### 一、摘要（解决的问题）

标准宽行矮化密植苹果园环境中，传统导航技术存在定位精度不足、场景适配性差等问题，难以满足植保机器人 “行间直行 + 行头行尾转弯” 的全流程导航需求，具体痛点及解决方案如下：

1. **单一导航技术局限明显**：
    - **RTK 定位受遮挡干扰**：苹果园树冠层遮挡、多路径效应导致 RTK 信号精度下降，行间定位不准确，无法支撑直行阶段的航向控制；
    - **视觉导航鲁棒性低**：视觉系统在复杂背景（如杂草、阴影）、行头行尾光照变化及相机抖动影响下，导航线提取误差大，平均横向偏差达 0.5m，最大 0.9m，且转弯阶段易因语义分割失效失去航线修正信息。
2. **全流程导航衔接不畅**：
    - **直行与转弯策略脱节**：传统方法未针对苹果园 “弓字形” 作业路径（行间直行 + 行头行尾转弯）设计适配方案，直行阶段依赖视觉易偏差，转弯阶段依赖人工干预效率低，无法实现全自主导航。

为此，研究提出 **“视觉 - RTK 组合导航” 方案 **：

- **行间直行阶段**：采用 U-Net 语义分割网络提取果园路面、天空等语义信息，拟合边缘线生成导航线，通过偏航状态判断调整航向，解决 RTK 行间定位差问题；
- **行头行尾转弯阶段**：预设 RTK 全局目标点，当机器人 RTK 解为高精度固定解且与目标点距离达阈值（3m）时，切换为 RTK 轨迹控制，避免视觉转弯失效问题，实现全流程自主导航。

#### 二、结论（实现的效果）

1. **导航精度显著提升**：
    - **RTK 全局规划精准**：行头行尾转弯阶段，基于 RTK 的平均横向偏差仅 0.1m，最大偏差 0.3m，远优于视觉导航（平均 0.5m、最大 0.9m），确保转弯轨迹贴合预设 “弓字形” 路径；
    - **视觉直行稳定可靠**：U-Net 语义分割模型对果园路面识别率达 95%、天空 90%，平均交并比（mIoU）81.66%，提取的导航线可有效修正行间直行航向，满足宽行（3.5-5.0m）作业的精度需求。
2. **全流程自主导航落地**：
    - **场景适配性强**：针对苹果园 60m 行长、1.5-2.0m 株距的标准化种植模式，实现 “行间直行（视觉）- 行头行尾转弯（RTK）” 的无缝切换，机器人以 1.0m/s 速度稳定运行，无人工干预即可完成 “弓字形” 全路径作业；
    - **实时性满足需求**：图像处理平均耗时 0.2s / 帧，语义分割、导航线拟合及 RTK 数据交互响应迅速，无明显延迟，适配植保作业的高效性要求。
3. **实用价值与推广潜力大**：
    - **作业覆盖完整**：导航系统可覆盖苹果园全生育期植保作业，路径规划能避开果树（株距 1.5-2.0m），无碰撞风险，且 “弓字形” 路径确保果园全覆盖；
    - **硬件成本可控**：采用双目相机 + 低成本 RTK 模块，无需依赖激光雷达等高价设备，符合农业装备低成本推广需求，为同类果园（如梨园、桃园）植保机器人导航提供可复用方案。
4. **现存优化方向**：
    - 目前 U-Net 模型对树干（Steel）、钢杆（Trunk）等小目标分割精度较低（mIoU 不足 70%），后续可优化标注数据与模型结构，进一步提升复杂环境下的语义分割鲁棒性；
    - 未来可融合 IMU 数据优化动态姿态调整，应对果园山地地形的颠簸干扰，进一步降低横向偏差。


### 先验信息约束的车载 GNSS_RTK_IMU 紧组合导航算法（蒋磊）

[[先验信息约束的车载GNSS_RTK_IMU紧组合导航算法_蒋磊.pdf]]

==如果后期的建图效果不理想时需要对建图、导航进行优化时可以考虑这篇==

#### 一、摘要（解决的问题）

传统 GNSS RTK/IMU 紧组合导航系统在复杂环境（如城市峡谷、遮挡区域）中，因 GNSS 观测质量差、模糊度固定率低，导致导航精度与可靠性不足，具体痛点及解决方案如下：

1. **GNSS 观测数据质量差**：
    - **伪距粗差干扰**：复杂环境中 GNSS 信号易受反射、衍射影响，伪距观测值含较大粗差，传统质量控制模型（如经验权重分配、单一故障检测）难以识别多故障并发场景，导致异常数据参与解算，影响定位精度；
    - **卫星观测受限**：遮挡导致可观测卫星数量不足，法方程易病态，进一步降低模糊度解算稳定性。
2. **GNSS 模糊度固定率低**：
    - **解算约束不足**：传统 RTK/IMU 组合中，模糊度解算仅依赖伪距与载波相位观测值，缺乏额外约束，在观测条件差时（如卫星少、噪声大），模糊度固定成功率低（传统算法约 74%），进而导致组合导航精度下降；
    - **IMU 辅助效果有限**：现有基于 IMU 位置信息约束的方法，仅能小幅提升模糊度固定率（提升 4.36%），且未利用 IMU 与 GNSS 天线的几何先验关系，约束强度不足。

为此，研究提出 **“先验信息约束的紧组合导航算法”**：

- **GNSS 质量控制优化**：利用 IMU 机械编排推算的高精度位置，构建伪距一致性检测模型，通过检验因子识别并剔除粗差伪距，确保输入数据可靠性；
- **模糊度解算约束增强**：基于 “IMU 几何中心与 GNSS 天线相位中心相对距离固定” 的先验信息，构建约束方程，压缩模糊度搜索空间，提升固定成功率；
- **紧组合滤波融合**：通过 EKF 融合 RTK（含约束优化后的模糊度解）与 IMU 数据，进一步提升复杂环境下的导航精度。

#### 二、结论（实现的效果）

1. **模糊度固定率显著提升**：
    - **固定成功率领先**：在南京实地车辆实验中，所提算法模糊度固定率达 86.10%，较传统 RTK/IMU 紧组合算法（74.00%）提升 16.35%，较基于 IMU 位置约束的算法（77.23%）提升 11.49%；
    - **解算质量更优**：算法计算的 Ratio 值（模糊度固定可靠性指标）普遍大于传统算法，且通过 Ratio 值检验（阈值 2）的历元占比更高，证明模糊度解算准确性更优。
2. **导航精度全面优化**：
    - **位置精度大幅提升**：三维位置均方根误差（RMSE）从传统算法的 0.22m 降至 0.14m，提升率 36.36%；较 IMU 位置约束算法（0.19m）提升 26.31%，其中东向、北向精度提升尤为显著（东向从 0.13m 降至 0.06m，提升 53.85%）；
    - **速度与姿态精度改善**：三维速度 RMSE 从传统算法的 0.14m/s 降至 0.12m/s，提升率 14.29%；姿态方面，俯仰角精度提升 5.00%，横滚角提升 1.20%，满足车载高精度导航需求。
3. **复杂环境适应性强**：
    - **抗干扰能力突出**：在卫星数量波动（部分历元卫星少）、信号遮挡的复杂场景中，算法仍能稳定剔除粗差伪距（检验因子阈值 5m，识别准确率高），保障观测数据质量；
    - **硬件兼容性好**：基于低成本 MEMS IMU（STIM-300）与单频 GNSS 接收机，无需依赖高价设备，可广泛应用于车载导航场景（如智能交通、自动驾驶）。
4. **实用价值与推广潜力大**：
    - **算法通用性高**：先验信息约束思路可扩展至多星座（如 GPS+BDS+GLONASS）、多频率 GNSS 系统，进一步提升观测冗余度；
    - **落地性强**：实地实验验证（参考轨迹由高精度 HGuide n580 提供）表明，算法在真实复杂环境中性能稳定，为车载高精度导航提供可行方案。


### 基于 RTK、UWB 与 INS 的空间多维精准定位技术研究（赵宇航）

[[基于RTK、UWB与INS的空间多维精准定位技术研究_赵宇航.pdf]]

==论文只是说了UWB和RTK之间切换，并不是进行真正的有机融合==

#### 一、摘要（解决的问题）

室内外连续定位场景中，单一传感器技术存在定位盲区、精度不足、场景适配性差等问题，难以实现 “室内 - 过渡区 - 室外” 全流程精准定位，具体痛点及解决方案如下：

1. **单一定位技术局限性显著**：
    - **室外 RTK 信号受限**：RTK 依赖卫星信号，在室内或遮挡区域（如楼宇、树木密集区）信号丢失，无法定位；仅靠 INS 单独导航时，误差随时间累积，短时间内精度便大幅下降。
    - **室内 UWB 鲁棒性低**：UWB 易受非视距（NLOS）误差（如墙壁遮挡）、系统误差影响，单独定位平均误差达 42.79cm，最大 133.12cm，且无法提供可靠高程信息；行人航位推算（PDR）虽能自主定位，但步数估计误差 3.3%、路径闭合误差 1.04m，累积误差明显。
2. **室内外过渡衔接不畅**：
    - **场景切换无适配策略**：传统方法未针对 “室内 UWB / 室外 RTK” 的信号切换设计算法，过渡区域易因信号交替缺失导致定位中断或轨迹跳变，无法实现连续导航；且缺乏统一的高程定位方案，三维定位精度不足。

为此，研究提出 **“多传感器融合 + 场景切换” 的空间多维定位方案 **：

- **室内定位优化**：构建 UWB/PDR/ 气压计组合模型，通过最小二乘拟合补偿 UWB 系统误差，抗差卡尔曼滤波抑制 NLOS 误差，结合差分气压计测高（静态测高误差 2.68cm），补充高程信息；
- **室外定位优化**：建立 RTK/INS 松组合模型，统一时间基准并同步数据，利用 RTK 校正 INS 累积误差，实现厘米级室外定位；
- **室内外切换**：根据卫星数量（≥4 颗判定室外）与 UWB 信号强度（≥3 个基站且功率＞-100dBm 判定室内）设计切换算法，过渡区域通过加权平均融合两类定位数据，避免轨迹中断。

#### 二、结论（实现的效果）

1. **室内定位精度大幅提升**：
    - **UWB 误差有效抑制**：经最小二乘拟合 + 抗差卡尔曼滤波处理后，UWB 测距最大误差从 119.37cm 降至 49.02cm，均方根误差（RMSE）从 21.94cm 降至 11.77cm；
    - **组合定位性能优异**：UWB/PDR/ 气压计组合定位平均误差 16.72cm，较未经处理的 UWB（42.79cm）提升 60.93%，较仅经误差处理的 UWB（24.98cm）提升 33.07%，高程定位依赖差分气压计，静态测高 RMSE 2.68cm，满足室内三维精准定位需求。
2. **室外定位稳定可靠**：
    - **RTK/INS 组合精度高**：室外场景中，RTK/INS 松组合定位东向、北向、天向最大误差分别为 0.1549m、0.1719m、0.1242m，RMSE 均在 0.05m 以内，实现厘米级定位，且误差稳定无大幅波动，适配室外动态场景（如电动车移动）。
3. **室内外连续定位落地**：
    - **过渡区平滑衔接**：切换算法通过卫星数量与 UWB 信号强度精准判断场景，过渡区域加权融合数据（RTK 权值按误差反比分配），定位轨迹无跳变，实现 “室内 - 过渡区 - 室外” 无缝衔接；
    - **三维定位精度达标**：全系统平均平面定位误差 15.57cm，平均高程定位误差 6.50cm，满足人员、设备等空间多维定位需求（如智能制造、物流追踪），且硬件成本可控（采用低成本 MEMS IMU、UWB 模块）。
4. **实用价值与优化方向**：
    - **场景适配性强**：可推广至室内仓储、室外园区等多场景，解决传统定位 “室内盲区、室外遮挡失效” 问题；
    - **现存改进空间**：目前硬件依赖模块拼接，未实现一体化设计，后续可优化硬件集成以提升便携性；同时可引入深度学习优化 NLOS 误差识别，进一步提升复杂环境下的鲁棒性。

#### INS 的含义

==INS 是**惯性导航系统（Inertial Navigation System）** 的缩写，其核心原理是通过加速度计和陀螺仪测量载体的加速度与角速度，再结合初始位置、速度和姿态，通过积分运算实时推算载体的当前运动状态（位置、速度、姿态）。==

- ==**特点**：不依赖外部信号（如卫星、基站），可自主定位，但误差会随时间累积（漂移），因此常与其他传感器（如 GNSS、UWB）融合使用，以弥补各自缺陷。==
- ==在该研究中，INS 主要用于：① 室内辅助 UWB 和 PDR（行人航位推算）抑制累积误差；② 室外辅助 RTK 在信号短暂丢失时维持定位连续性。==？？？

### 基于机器视觉辅助的 GPS-RTK 无人驾驶导航饲喂装置研究与设计（余泽涛）

[[基于机器视觉辅助的GPS-RTK无人驾驶导航饲喂装置研究与设计_余泽涛.pdf]]
==连ROS都没有上，只是单纯的单片机+树莓派视觉==

#### 一、摘要（解决的问题）

滩羊养殖中传统饲喂模式与单一导航技术存在效率低、环境适应性差等问题，难以满足无人化、精准化饲喂需求，具体痛点及解决方案如下：

1. **传统饲喂与导航技术局限明显**：
    - **人工饲喂效率低**：依赖人力完成滩羊饲喂，易因操作疲劳导致饲料浪费或投放不足，且人工接触可能引发羊只应激反应（如高温环境下脱水死亡风险），同时人力成本高、作业效率低；
    - **单一 RTK 导航鲁棒性差**：RTK 依赖卫星信号，在恶劣天气（如阴天、乌云）或遮挡场景下，信号接收不稳定，定位误差增大，无法保证饲喂车精准沿预设路径行驶。
2. **无人化饲喂系统缺失**：
    - **硬件与控制适配不足**：传统饲喂车无自动转向、刹车、撒料控制模块，需改造硬件并设计适配电路；且缺乏便捷的人机交互方式，手动控制操作复杂；
    - **环境干扰影响定位**：羊舍路面存在积水、饲料残留等，易导致视觉导航图像特征提取误差，单独视觉导航或 RTK 均无法应对全场景饲喂需求。

为此，研究提出 **“机器视觉辅助 GPS-RTK + 多模块集成” 的无人饲喂方案 **：

- **硬件改造与控制设计**：改造传统饲喂车，加装步进电机（转向）、舵机（油门 / 搅笼）、推杆电机（刹车），设计上下位机控制电路（上位机 STM32f10x + 下位机 Arduino），开发蓝牙 APP 实现远程操控；
- **组合导航优化**：以 RTK 为主要导航（基站 + 移动站差分定位），机器视觉辅助修正（HSV 空间阈值调整消除积水干扰，最小二乘法拟合导航线），搭配 MPU6050 姿态传感器与超声波避障，提升复杂环境适应性；
- **全流程饲喂适配**：集成撒料、履带输送模块，确保导航与饲喂动作协同，实现 “自主导航 - 精准撒料 - 安全避障” 全流程无人化。

#### 二、结论（实现的效果）

1. **无人饲喂系统功能完善**：
    - **硬件与控制可靠**：改造后的饲喂车实现自动转向（步进电机扭矩达 130N・M，满足重载需求）、多档位速度控制（0.2-1m/s）、精准刹车（一档制动时间 0.5s），蓝牙 APP 可实现 20m 内远程操控，覆盖 “启动 - 转向 - 撒料 - 停止” 全操作，人机交互便捷；
    - **避障安全有效**：超声波传感器实时检测与饲喂栏距离，配合 MPU6050 姿态传感器（六轴数据解算偏航角），避免行驶中碰撞，提升作业安全性。
2. **导航精度满足饲喂需求**：
    - **RTK 导航性能稳定**：优良天气下（卫星数 25-30 颗），RTK 导航整体平均误差 1.04cm，正值平均误差 7.84cm、负值 9.12cm，最大误差 20cm，小于饲喂槽宽度（45cm），可精准沿预设路径行驶；
    - **视觉辅助效果显著**：恶劣天气下（卫星数 10-15 颗），机器视觉辅助导航整体平均误差降至 0.52cm，最大误差 15cm，标准差 8.31cm（优于单一 RTK 的 10.14cm），有效修正 RTK 信号不佳时的定位偏差，确保饲喂车仍能精准对齐饲喂槽。
3. **实际应用价值突出**：
    - **作业效率与安全性提升**：替代人工饲喂，减少人力成本的同时避免羊只应激反应，撒料均匀性满足滩羊养殖需求，且超声波避障与姿态修正确保行驶安全，无碰撞事故；
    - **场景适配性强**：在盐池县滩羊集团试验场地验证，系统可适应羊舍复杂路面（积水、饲料残留）与不同天气，导航与饲喂动作协同稳定，满足规模化滩羊养殖的无人化作业需求。
4. **现存优化方向**：
    - 目前基于三轮车底盘改造，转向幅度较大易增大误差，后续可选用四轮底盘提升稳定性；
    - 机器视觉主控树莓派图像处理频率仅 1 帧 / 秒，且对路面清洁度要求高，未来可更换高性能芯片（如 Jetson Nano）并优化图像算法，进一步提升实时性与鲁棒性。


### 基于 RTK 组合导航系统算法设计及实现（高韵）

[[基于RTK组合导航系统算法设计及实现_高韵.pdf]]

==单纯使用了RTK进行改进而已，参考价值不大==

#### 一、摘要（解决的问题）

中高精度光纤惯导与卫星导航组合应用中，存在单一系统局限性、姿态奇异点干扰、组合导航精度不足等问题，难以满足高可靠性导航需求，具体痛点及解决方案如下：

1. **单一导航系统缺陷显著**：
    - **卫星导航信号受限**：GNSS（含 RTK）易受遮挡丢失信号，导致定位中断，无法单独作为核心导航手段；
    - **惯导误差累积**：光纤惯导虽短期精度高，但长期运行中陀螺漂移、加速度计偏置会导致姿态、速度、位置误差累积，单独使用难以维持高精度。
2. **组合导航关键问题待突破**：
    - **姿态奇异点干扰**：传统组合导航采用 “航向 - 俯仰 - 横滚”（213）旋转顺序，当俯仰角接近 90°（如火箭垂直发射场景）时会出现奇异点，导致姿态解算失效；
    - **融合算法精度不足**：传统组合导航未充分利用 RTK 固定解的厘米级精度优势，且对惯导误差的实时校正能力弱，难以实现高精度协同。

为此，研究提出 **“改进姿态解算 + 卡尔曼滤波融合” 的 RTK 组合导航方案 **：

- **姿态奇异点解决**：优化旋转顺序为 “横滚 - 俯仰 - 航向”（321），推导新的姿态转换矩阵，避免俯仰角 90° 附近的奇异点问题，适配垂直运动场景；
- **组合导航建模**：建立包含失准角、速度误差、位置误差、陀螺漂移、加速度计偏置的 15 维状态方程，以惯导与 RTK 的位置 / 速度差为观测量，构建线性卡尔曼滤波模型；
- **高精度融合策略**：在 RTK 获取固定解时，通过卡尔曼滤波实时估计惯导误差并校正，充分发挥 RTK 厘米级精度与惯导连续导航的优势。

#### 二、结论（实现的效果）

1. **姿态解算突破奇异点限制**：
    - **奇异点问题解决**：采用 “321” 旋转顺序的姿态转换矩阵，在俯仰角接近 90°（实物验证中俯仰角约 90°）的场景下，仍能稳定解算姿态，无奇异点导致的解算失效问题，适配垂直发射、高空垂直运动等特殊场景；
    - **姿态精度优异**：实物验证中，俯仰角误差 RMS 仅 0.0014°，航向角误差 RMS 0.0014°，横滚角误差 RMS 0.11°，姿态解算精度远高于传统方案。
2. **组合导航精度达厘米级**：
    - **速度与位置误差极小**：实物验证中，东向、北向、天向速度误差 RMS 分别为 0.0046m/s、0.0023m/s、0.0078m/s；纬度、经度、高度误差 RMS 分别为 0.0024m（2.4mm）、0.0077m（7.7mm）、0.0108m（10.8mm），完全达到厘米级定位精度；
    - **仿真验证可靠**：通过 Psins 工具箱生成动态 IMU 数据（添加陀螺零位 0.03°/h、加速度计零位 100μg 等噪声），仿真结果显示姿态角误差最大 0.7′（0.0117°）、水平速度误差最大 0.15m/s、位置误差水平方向≤2m、高度≤3m，验证算法基础有效性。
3. **工程应用价值突出**：
    - **场景适配性强**：算法可直接应用于光纤组合导航产品，实物验证中产品在 “天东北” 方向、俯仰角 90° 附近的工装测试环境下，连续 20 分钟组合导航数据稳定，无异常中断；
    - **可靠性与精度兼顾**：既解决了 RTK 信号丢失时惯导的连续导航问题，又利用 RTK 固定解校正惯导误差，实现 “无信号时保连续、有信号时提精度”，满足中高精度导航场景（如航空、航天、高精度车载）需求。
4. **现存优化方向**：
    - 目前未充分考虑 RTK 失锁（浮点解 / 单点解）时的融合策略，后续可设计自适应滤波算法，根据 RTK 精度动态调整融合权重；
    - 可进一步融合多源传感器（如视觉、激光雷达），提升复杂遮挡环境下的导航鲁棒性。



---


## 1106
### 助老服务机器人的自主导航研究（刘振伟）
[[助老服务机器人的自主导航研究_刘振伟.pdf]]

==只是最基础的ROS导航，没啥特别亮眼的==

#### 一、摘要（解决的问题）

助老服务机器人在室内自主导航中面临环境感知不精准、路径规划安全性不足、动态避障能力弱等问题，难以满足老年居家场景的安全、高效服务需求，具体痛点及解决方案如下：

1. **地图构建与定位适配性差**：
    - **室内环境建模难题**：老年居家场景（卧室、厨房、客厅）存在狭窄通道、家具遮挡等复杂情况，传统 SLAM 算法（如 Hector、Cartographer）易出现地图变形、轮廓断裂，无法精准还原环境；
    - **定位精度不足**：机器人在全局地图中易因环境特征单一导致定位漂移，影响路径规划准确性。
2. **路径规划安全性与灵活性不足**：
    - **传统算法缺陷明显**：A * 算法对障碍物感知不敏感，易规划出紧贴障碍或斜穿障碍的路径，且路径转折点多、不平滑；缺乏对老年居家场景中 “风险区域”（如贵重物品区、狭窄通道）的规避机制；
    - **动态避障能力缺失**：室内可能出现行人、临时障碍物等动态干扰，单一全局路径规划算法（如 A*）无法实时调整路径，易引发碰撞风险。
3. **系统集成与场景适配不足**：
    - **硬件与软件协同缺失**：需搭建适配助老场景的硬件平台（感知、控制、执行模块），并基于 ROS 系统实现多模块协同；
    - **无针对性导航方案**：现有导航系统未充分考虑老年居家环境的特殊性，缺乏 “安全优先、路径平滑” 的定制化设计。

为此，研究提出 **“激光 SLAM + 优化路径规划 + 多模块集成” 的自主导航方案 **：

- **地图构建与定位优化**：对比三类 SLAM 算法，选定 Gmapping 算法构建高精度栅格地图，搭配自适应蒙特卡洛定位（AMCL）算法，实现机器人在室内环境的精准定位；
- **路径规划算法改进**：优化 A * 算法（引入障碍率优化评价函数、消除斜穿障碍、剔除冗余节点、划分风险区域），融合动态窗口法（DWA），兼顾全局最优路径与局部动态避障；
- **系统集成适配**：以树莓派 4B 为主控、RPLIDAR A2 激光雷达为感知核心、STM32 为运动控制模块，搭建基于 Ubuntu 20.04+ROS 的软件平台，适配两轮差速驱动的移动机器人。

#### 二、结论（实现的效果）

1. **地图构建与定位精准可靠**：
    - **地图质量优异**：Gmapping 算法在室内场景中建图平均精度达 95%，相较于 Hector（91%）、Cartographer（84%），能更清晰还原卧室、厨房、客厅的空间结构，无明显变形或轮廓断裂；
    - **定位稳定**：AMCL 算法通过粒子滤波实现机器人在全局地图中的高效定位，粒子快速收敛至真实位姿，有效避免定位漂移。
2. **路径规划安全性与灵活性显著提升**：
    - **优化 A * 算法表现突出**：规划路径平滑无冗余转折点，主动避开障碍与风险区域，未出现斜穿障碍或紧贴障碍的情况，安全性大幅提升；
    - **融合算法避障高效**：优化 A * 与 DWA 融合算法可实时识别静态障碍物（如新增家具）和动态障碍物（如行人），快速调整局部路径，避障后能回归全局最优路径，无碰撞风险。
3. **系统适配性与实用性强**：
    - **硬件与软件协同稳定**：基于 ROS 系统实现激光雷达、运动控制、路径规划模块的高效通信，机器人可稳定完成 “客厅→厨房→卧室” 的跨房间导航，动作响应流畅；
    - **场景适配性良好**：在模拟老年居家场景的实验中，机器人平均平面定位误差小，路径规划符合 “安全优先、路径平滑” 的助老需求，能灵活应对狭窄通道、动态干扰等复杂情况，满足实际服务场景的自主导航需求。
4. **现存优化方向**：
    - 对突发快速移动障碍物的反应速度有待提升，后续可优化局部路径规划算法的响应效率；
    - 目前依赖二维激光雷达，无法感知垂直方向障碍物（如悬挂物品），可融合摄像头提升环境感知全面性。


### 融合多模态大模型的端到端具身导航与抓取算法的研究（黄家淬）

[[融合多模态大模型的端到端具身导航与抓取算法的研究_黄家淬.pdf]]

==应用设计上和我的MCP具身智能机器人很像，不过应用技术不同，可以参考参考==

#### 一、摘要（解决的问题）

具身智能机器人在导航、抓取及人机交互中面临环境适配差、数据成本高、交互不自然等问题，难以满足复杂场景下的自主服务需求，具体痛点及解决方案如下：

1. **导航系统语义精度不足**：
    - 传统语义地图（如 SLAM 生成地图）缺乏实例级分辨率和属性标注，无法响应 “第三把黑色椅子” 这类细粒度自然语言指令；
    - 动态环境适应性弱，依赖预定义地图，难以应对未知物体或场景变化。
2. **抓取算法泛化性与数据依赖矛盾**：
    - 传统抓取算法（规则式、单一模态驱动）对非结构化场景适配差，面对多样化物体易失效；
    - 前沿算法（ACT、Diffusion）依赖高质量专家数据，采集成本高、场景复用性差，限制实用化落地。
3. **人机交互自然性欠缺**：
    - 缺乏自然语言与机器人动作的直接映射，无法通过语音或文本指令灵活控制导航与抓取，交互流程繁琐。

为此，研究提出 **“多模态大模型融合 + 端到端解决方案”**：

- **导航优化**：构建实例级视觉语言地图（IVLMap），融合 RGB-D 数据与 SAM、CLIP 等模型，实现像素级语义分割与属性标注，支持零样本实例级导航；
- **抓取优化**：设计 LeRobot-SAM2 框架，利用 SAM2 的视频分割与背景融合技术，低成本生成多样化训练数据，提升 ACT、Diffusion 等算法的泛化能力；
- **交互优化**：开发 ROSGPT 系统，基于优化后的 Llama2 模型，集成语音转文本与代码生成功能，实现自然语言到机器人动作的无缝衔接。

#### 二、结论（实现的效果）

1. **导航精度与灵活性显著提升**：
    - IVLMap 支持实例级与属性级导航，零样本任务成功率较基线方法提升 15%，能精准响应 “导航到桌子东侧的红色杯子” 等复杂指令；
    - 地图具备细粒度语义表达，融合 3D 重建与多模态特征，动态环境适应性优于传统语义地图。
2. **抓取算法性能与数据效率双赢**：
    - LeRobot-SAM2 框架降低数据采集成本超 2 倍，生成的多样化数据集使 ACT 算法抓取成功率最高达 80%，较基线提升 15%-20%；
    - 在非结构化场景（多物体、遮挡、多样背景）中表现出强鲁棒性，适配篮子、方块、棉球等不同形态物体的抓取任务。
3. **人机交互自然便捷**：
    - ROSGPT 系统支持语音 / 文本指令直接生成 Python 代码，零样本导航任务成功率达 85%，可实现 “沿正方形轨迹移动”“移动到客厅桌子旁” 等灵活控制；
    - 集成云端与网页控制功能，摆脱本地计算限制，交互流程更贴合人类使用习惯。
4. **系统集成与实用价值突出**：
    - 导航与抓取模块均基于多模态大模型实现端到端优化，为后续两者协同集成奠定基础；
    - 硬件适配性强，在低成本机器人平台（如 Koch 机械臂）上验证有效，降低具身智能技术落地门槛，适用于家庭服务、工业操作等场景。
5. **现存优化方向**：
    - 真实场景中导航仍受硬件精度限制，建图误差与控制偏差需进一步优化；
    - 抓取算法在严重遮挡或复杂形态物体场景下泛化性待提升，端到端融合导航与抓取的一体化模型尚未完善。


### 室外巡检机器人自主导航系统研究与实现（王舒）
[[室外巡检机器人自主导航系统研究与实现_王舒.pdf]]

==是一个继Fastlivo2之后的可值得参考的建图方案==

#### 一、摘要（解决的问题）

室外巡检机器人在自主导航中面临地图构建精度不足、障碍物检测可靠性低、路径规划安全性与效率失衡等问题，难以满足电力、煤矿等工业场景的稳定巡检需求，具体痛点及解决方案如下：

1. **地图构建与障碍物检测适配性差**：
    - 激光雷达采集的原始点云数据量大、噪声多，直接用于导航易导致建图误差；
    - 地面点云与障碍物点云易混淆，传统检测方法误检率高，且无法精准表征障碍物三维形态，影响避障安全性。
2. **路径规划算法性能短板**：
    - 传统遗传算法存在初始种群盲目性强、进化效率低、规划时间长等问题；
    - RRT * 算法路径避障安全性差，易贴近障碍物，而传统遗传算法路径转折点多、长度冗余，均难以兼顾安全性与高效性。
3. **室外场景适应性不足**：
    - 室外环境存在道路宽窄变化、障碍物种类复杂（车辆、建筑、树木）等情况，现有算法在复杂场景（如限宽道路）中导航稳定性不足。

为此，研究提出 **“高精度建图 + 可靠障碍物检测 + 优化路径规划” 的自主导航方案 **：

- **地图构建与障碍物检测优化**：采用 LIO-SAM 算法构建三维地图，通过体素栅格下采样降维去噪，结合 RANSAC 算法分割地面点云，利用 K-d Tree 欧式聚类实现障碍物聚类，最终基于 PCA 生成三维包围箱，精准标记障碍物；
- **路径规划算法改进**：提出多目标遗传算法（MGA），通过生成无障碍最少节点初始种群、构建含安全度的适应度函数、新增检测算子（去冗余节点）和删除算子（优化路径段），兼顾路径安全性、短路径与高效率；
- **系统集成适配**：以 ROS 为软件平台，搭建基于激光雷达的轮式机器人硬件平台，适配室外复杂巡检场景。

#### 二、结论（实现的效果）

1. **地图构建与障碍物检测精准可靠**：
    - 三维建图效果优异：LIO-SAM 算法能清晰还原室外道路（直行道、T 形道）环境，建图无明显漂移，为导航提供高精度基础；
    - 障碍物检测性能突出：可通行道路中障碍物检出率达 99.8%，误检率仅 0.1%，三维包围箱能准确表征障碍物形态，有效避免误避障与漏避障。
2. **MGA 算法路径规划优势显著**：
    - 安全性大幅提升：规划路径距障碍物最短距离达 1.9m，远超 RRT * 算法（0.58m）和传统遗传算法（1.2m），轮边缘距障碍物最短距离 1.55m，无碰撞风险；
    - 效率与路径质量兼顾：相较于传统遗传算法，MGA 算法规划时间缩短 16.2s，路径长度缩短 4m，转折点减少 22 个，在限宽道路等复杂场景中仍能稳定输出最优路径。
3. **室外场景适配性与实用性强**：
    - 系统稳定运行：在校园道路（模拟工业巡检场景）实验中，机器人能完成直行、T 形道路的自主导航，适配车辆、树木、建筑等多种障碍物；
    - 环境适应性好：无论是宽阔道路还是限宽道路，MGA 算法均能兼顾安全性与高效性，而 RRT * 算法在复杂场景中避障安全性急剧下降，传统遗传算法效率低下，凸显 MGA 算法的优势。
4. **现存优化方向**：
    - 障碍物检测未实现坐标纠正，难以适配非直角道路场景，且未获取障碍物尺寸等详细信息；
    - MGA 算法规划路径的平滑度有待提升，可进一步优化以减少机器人转弯摩擦与能耗。

**RRT * 算法是在快速扩展随机树（RRT）算法基础上改进而来的路径规划算法，通过引入代价机制优化父节点选择，能在随机树搜索过程中找到更优路径，兼顾路径可行性与近似最优性，不过在复杂室外环境中避障安全性较低，易贴近障碍物。**

**MGA 算法是改进的多目标遗传算法，通过优化初始种群生成、构建含安全度的适应度函数，新增检测算子（去除冗余节点）和删除算子（优化路径段），能在室外巡检场景中规划出兼顾避障安全性、短路径与高效率的导航路径。**



### 室外场景下的巡检机器人地图构建与定位技术研究（钱文池）

[[室外场景下的巡检机器人地图构建与定位技术研究_钱文池.pdf]]

==传统建图+针对户外空旷场景进行优化，减少漂移==

#### 一、摘要（解决的问题）

室外巡检机器人在地图构建与定位中面临传感器适配性差、场景适应性不足等问题，难以兼顾复杂与空旷场景的高精度需求，具体痛点及解决方案如下：

1. **单一传感器定位局限明显**：
    - GPS（DETA 导航模块）易受高楼、树木遮挡或多径效应影响，信号丢失或精度下降；
    - 二维激光雷达测量距离有限（10-30 米），在空旷场景中易丢失信号，无法提供有效定位数据；
    - 里程计（ODO）存在累计误差，单独使用难以保证长期定位精度。
2. **复杂场景地图构建精度不足**：
    - 传统 Hector-SLAM 算法依赖单一激光雷达，易出现扫描匹配误匹配、地图扭曲，且机器人旋转过快时易漂移；
    - 未融合多传感器信息，建图过程中初始位姿估计不准确，影响地图整体精度。
3. **场景适配性差**：
    - 缺乏针对空旷与复杂室外场景的差异化定位方案，单一组合定位方法无法兼顾两种场景的定位需求。

为此，研究提出 **“多传感器融合 + 场景化定位” 的一体化方案 **：

- **地图构建优化**：提出基于扩展卡尔曼滤波（EKF）的改进 Hector-SLAM 算法，融合激光雷达、里程计、惯性测量单元（IMU）数据，修正激光点云并提供精准初始位姿，提升复杂场景建图精度；
- **组合定位策略**：空旷场景采用 DETA 导航模块与里程计组合，通过卡尔曼滤波分离误差源，实现高精度绝对定位；复杂场景采用激光雷达与里程计组合，基于自适应蒙特卡洛（AMCL）算法实现实时定位；
- **系统集成适配**：搭建基于 FreeRTOS 的 STM32 下位机与 ROS 的树莓派上位机系统，实现多传感器数据传输与协同工作。

#### 二、结论（实现的效果）

1. **地图构建精准可靠**：
    - 改进 Hector-SLAM 算法表现优异，建图精度显著提升，能准确还原木板、纸箱、塑料桶等物体的平面特征，地图尺寸误差大幅减小，无明显扭曲或重影；
    - 融合 EKF 算法后，初始位姿估计更准确，有效解决了传统算法旋转漂移、误匹配问题，复杂场景建图鲁棒性增强。
2. **组合定位精度高、场景适配性强**：
    - 空旷场景定位：DETA/ODO 组合定位经卡尔曼滤波融合后，轨迹偏差区间从 - 0.15m~0.15m 缩小至 - 0.05m~0.05m，最大偏差从约 0.25m 降至 0.09m 以下，定位精度满足巡检需求；
    - 复杂场景定位：AMCL 算法融合激光雷达与里程计数据，粒子群能快速收敛至机器人真实位姿，运动轨迹与真实轨迹高度重合，实时定位精度优异；
    - 两种定位方案无缝适配不同场景，解决了单一传感器在遮挡、空旷环境下的定位缺陷。
3. **系统稳定可行**：
    - 软硬件系统协同流畅，STM32 下位机实现多任务并行执行，树莓派上位机完成传感器数据融合与算法运算，信息交互高效；
    - 在校园花坛（复杂场景）和操场（空旷场景）的实验验证中，系统能稳定完成地图构建与定位，满足室外巡检的实际应用需求。
4. **现存优化方向**：
    - 未实现路径规划与主动避障功能，后续需补充相关算法，应对动态与静态障碍物；
    - 可进一步优化传感器数据融合的实时性，提升机器人在快速移动场景下的定位与建图响应速度。

**DETA100系列是一个提供GNSS/INS &AHRS系统的模组，在最苛刻的条件下提供准确的位置、速度、加速度和姿态数据。 它结合了温度校准的加速度计，陀螺仪，磁力计与一个双天线RTK、GNSS接收器。这些是耦合在一个复杂的融合算法，以提 供准确和可靠的导航和方向。同时DETA100系列支持辅助设备的数据接入，如里程计、光流计、RTCM数据等。**



### 基于 ROS 的自主导航算法优化研究与验证（柳晓峰）

[[基于ROS的自主导航算法优化研究与验证_柳晓峰.pdf]]

==普通ROS导航简单优化==

#### 一、摘要（解决的问题）

ROS 自带导航模块存在机械结构兼容性差、避障逻辑不完善、室外路径规划不规范等问题，难以满足四轮前驱等非圆形机器人的实际导航需求，具体痛点及解决方案如下：

1. **机械结构兼容性不足**：
    - ROS 导航模块主要针对圆形机器人设计，代价地图（Costmap_2d）的单一膨胀层未考虑非圆形机器人（如四轮方形）的运动学特性，导致这类机器人导航避障不稳定、鲁棒性差；
    - 局部路径规划算法（如 DWA）未适配非圆形结构，路径规划与机器人实际运动需求不匹配。
2. **避障逻辑存在短板**：
    - 逃脱状态下仅采样前方速度，缺少后方障碍物检测，后退时易发生碰撞；
    - 近距离突发障碍物时，原有策略易陷入原地旋转死循环，避障效率低。
3. **室外路径规划不合理、不规范**：
    - 全局路径规划未考虑机器人尺寸，可能规划出无法通过的狭窄路径；
    - 室外环境无明确车道线引导，机器人易出现逆行、横穿道路等不规范行驶，安全性不足；
    - 单一传感器测量误差大，长期导航易累积误差影响定位精度。

为此，研究提出 **“代价地图改进 + 算法优化 + 路径规范” 的一体化方案 **：

- **代价地图优化**：改进 Costmap_2d，将膨胀层划分为行驶自由区和受限区，以驱动轮轴中心为基准调整膨胀逻辑，适配不同机械结构；
- **避障与路径规划优化**：优化 DWA 算法适配新代价地图，添加后方速度采样；完善近距离障碍物避障逻辑（急停 + 延时后退 + 重新规划）；
- **路径规范与数据融合**：新增全局路径合理性检验（验证路径是否适配机器人尺寸）；规范室外路径（直行靠右、路口转向合规）；通过扩展卡尔曼滤波（EKF）融合编码器与 IMU 数据，降低测量误差。

#### 二、结论（实现的效果）

1. **机械结构兼容性显著提升**：
    - 改进后的代价地图可兼容圆形、四轮方形、六轮等多种结构机器人，加载成功率与原版持平（室内 100%、室外 95%），加载时间虽略有延长但不影响使用；
    - 优化后的 DWA 算法使非圆形机器人转向更平滑，室内转向时与墙壁保持充足安全距离，远距离导航成功率达 95% 左右，稳定性大幅提升。
2. **避障安全性与可靠性增强**：
    - 逃脱状态下添加后方速度采样，50 次模拟实验均无碰撞，完全规避后退碰撞风险；
    - 近距离突发障碍物时，机器人可快速急停、延时后退后重新规划路径，除 2 次因传感器硬件限制失败外，其余均成功避障，避障效率与安全性显著优于原有策略。
3. **室外路径规划更合理、规范**：
    - 全局路径合理性检验正确率达 99%（仅 1 次因地图噪点出错），有效过滤无法通过的狭窄路径，检验时间随路径长度线性增长，对整体导航效率影响极小；
    - 室外行驶规范化效果明显，直行过程基本靠右行驶，路口左转、右转、直行均符合道路行驶规范，逆行等违规情况大幅减少；
    - EKF 数据融合后，传感器测量误差显著降低，机器人相对位姿更准确，长时间无定位时仍能安全导航。
4. **系统整体稳定可靠**：
    - 室内外长时间巡航（各 2 小时）中，导航中断次数少，两种实验平台（四轮前驱、六轮）均表现稳定；
    - 各项优化未破坏 ROS 原有功能兼容性，加载成功率、导航响应速度等关键指标均保持在实用范围内。
5. **现存优化方向**：
    - 代价地图仍可能存在未兼容的特殊机械结构，需在实际应用中持续补充适配；
    - DWA 算法的避障逻辑未覆盖所有极端场景，部分低概率特殊情况仍需后续完善；
    - 室外环境复杂多变，仅靠路径规划优化难以完全解决所有导航问题，需多领域协同完善。

**DWA 算法（动态窗口法）是一种在移动机器人局部路径规划中，通过在速度空间采样生成候选轨迹并评估筛选，实现避障与目标追踪的实时规划方法。**




---
## 1109

### EKF解析
EKF 是扩展卡尔曼滤波（Extended Kalman Filter）的缩写，核心是解决**非线性系统**的状态估计问题，比如通过传感器数据推测物体的真实状态。

#### 核心定义

卡尔曼滤波（KF）原本只能处理线性系统（比如匀速直线运动的物体），但现实中多数系统是非线性的（比如卫星轨道、机器人转弯、无人机飞行）。EKF 通过 “局部线性化” 的技巧，把非线性系统近似成线性系统，再用卡尔曼滤波的逻辑估算状态，同时修正误差。

简单说，EKF 就是 “给非线性系统量身定制的状态推测工具”，核心作用是：**从含噪声的观测数据中，算出物体最可能的真实状态**。


#### 形象比喻：盲人摸象 + 动态修正

把 EKF 想象成 “带修正功能的盲人猜物游戏”：

1. 你蒙着眼睛（相当于没有完美传感器），要猜一个在做复杂运动的物体（比如滚动的皮球，对应非线性系统）的位置和速度。
2. 你的 “预测”：根据上一秒摸到的位置，结合物体的运动趋势（比如之前在向右滚），猜这一秒它大概在哪（对应 EKF 的 “预测步”）。
3. 你的 “观测”：伸手摸一下（相当于传感器读数），但可能摸偏了（传感器噪声），得到一个不太准的位置。
4. EKF 的 “修正”：你不会完全信自己的猜测，也不会完全信摸出来的结果 —— 而是根据 “猜测的可信度” 和 “摸得准不准”，加权融合两者，得到更靠谱的结论（对应 EKF 的 “更新步”）。
5. 关键差异：如果物体的运动是简单直线（线性），普通卡尔曼滤波就够了；但如果物体在转弯、弹跳（非线性），EKF 会先把 “转弯的局部运动” 近似成 “小段直线”（线性化），再按上面的逻辑猜，持续动态修正。


#### 核心用途

- ==无人机、自动驾驶：融合 GPS、陀螺仪等传感器数据，精准定位和导航。==
- 机器人：推测自身姿态、关节位置，避免动作偏差。
- 信号处理：从干扰噪声中提取真实信号（比如雷达、声呐数据）。


### 基于 EKF 的巡检机器人 INS/GPS 紧耦合导航算法（孙雪雁）

[[基于EKF的巡检机器人INS_GPS紧耦合导航算法_孙雪雁.pdf]]
==可以学习一下里面的EKF是如何实现的==

#### 一、摘要（解决的问题）

巡检机器人在狭窄通道、小作业区域中面临单一导航系统精度不足、传统组合导航模式性能受限等问题，具体痛点及解决方案如下：

1. **单一导航系统定位精度不够**：
    - 单独使用 GPS 卫星导航，易受环境遮挡影响，难以满足狭窄区域高精度定位需求；
    - 单独使用 INS 惯性导航，存在误差累积问题，长期导航精度下降明显。
2. **传统松耦合模式存在短板**：
    - 松耦合模式要求 GPS 和 INS 各自独立解算导航信息，观测噪声与时间相关；
    - 限制卡尔曼滤波增益与测量更新频率，导致组合导航精度受限，无法适配巡检机器人的高精度需求。

为此，研究提出 **“INS/GPS 紧耦合 + EKF 数据融合” 的导航方案 **：

- 采用紧耦合模式，以 GPS 卫星的伪距、伪距率为观测量，无需 GPS 独立导航解算；
- 依据机器人位置、速度、姿态信息建立紧耦合系统数学模型，通过扩展卡尔曼滤波（EKF）进行数据融合，校正 INS 导航参数误差；
- 输出校正后的导航信息，控制机器人履带速度，实现精准导航。

#### 二、结论（实现的效果）

1. **导航精度显著优于松耦合模式**：
    - 位置、速度、姿态误差曲线更平滑稳定，北向和东向位置误差均小于 0.25m，速度误差小于 0.015m/s，满足巡检机器人设计精度要求；
    - 在相同导航设备（低端差分 GPS、消费级 INS）配置下，定位精度全面超越传统松耦合模式。
2. **降低硬件成本**：
    - 采用消费级 INS 和低端 GPS 即可实现高精度导航，无需依赖昂贵导航设备，有效降低巡检机器人出厂成本。
3. **适配应用场景**：
    - 紧耦合模式的高稳定性和高精度，适配狭窄通道、小作业区域的巡检需求，可保障机器人在医院、商场等公共区域的精准运行。


### ==基于 EKF 的变电站巡检机器人 VIO/GPS 融合定位算法（张贵峰）==

[[基于EKF的变电站巡检机器人VIO_GPS融合定位算法_张贵峰.pdf]]

==思路上非常贴切与我目前的想法(251109)[[大车计划--方案研讨]],几乎一模一样，非常值得参考==

#### 一、摘要（解决的问题）

变电站巡检机器人导航面临单一传感器定位缺陷、融合算法适配性差等问题，难以满足复杂电力环境的高精度定位需求，具体痛点及解决方案如下：

1. **单一传感器定位性能不足**：
    - 视觉惯性里程计（VIO）为局部定位方法，存在位置和航向累积漂移，长期导航精度下降，且受非可视区域干扰；
    - GPS 虽能提供全局位置估计，但测量噪声大、频率低，易受变电站设施遮挡影响信号，定位可靠性不足。
2. **现有融合算法存在短板**：
    - 优化类融合算法定位精度较高，但计算开销大，难以在嵌入式系统部署；
    - 部分滤波类算法未充分评估航向精度，或因 GPS 高度测量噪声影响横滚角、俯仰角估计，适配性不佳。

为此，研究提出 **“VIO+GPS 紧耦合 + EKF 数据融合” 的定位方案 **：

- 以 VIO 进行姿态估计传播滤波器状态，利用 GPS 测量值更新状态，结合二者局部精度与全局稳定性优势；
- 基于扩展卡尔曼滤波（EKF）构建融合模型，仅校正偏航角以避免 GPS 噪声干扰横滚角和俯仰角，降低计算资源需求；
- 实现变电站室外环境下全局一致、准确的六自由度姿态估计。

#### 二、结论（实现的效果）

1. **定位精度显著提升**：
    - 位置误差大幅降低：圆形路线中 3 轴位置 RMSE 仅 0.36m，较单独 VIO（1.23m）减少 70.7%，较单独 GPS（1.46m）减少 75.3%；方形路线中 3 轴位置 RMSE 为 0.42m，较单独 VIO 减少 65.8%，较单独 GPS 减少 62.5%；
    - 航向角漂移有效消除：圆形路线偏航角 RMSE 从 VIO 的 5.15° 降至 0.88%，方形路线从 4.79° 降至 1.06°，综合航向角误差减少 76.9% 以上，满足机器人航向控制需求。
2. **环境适配性与实用性强**：
    - 有效克服 GPS 信号遮挡、VIO 累积漂移问题，在变电站复杂设施环境中仍能稳定输出定位结果；
    - 计算复杂度低，无需高额硬件成本，适配嵌入式系统部署，符合巡检机器人实际应用场景。
3. **全局与局部定位兼顾**：
    - 融合算法实现全局一致的定位效果，圆形和方形路线测试中均表现出无漂移的姿态估计，局部定位精度与全局稳定性兼具，满足变电站巡检机器人导航定位需求。



### 基于 VB-EKF 的 GPS/INS 松组合导航定位算法（侯华）


[[基于VB-EKF的GPS_INS松组合导航定位算法_侯华.pdf]]
==对于EKF的算法优化改进，后期有需要可以参考==

#### 一、摘要（解决的问题）

无人机 GPS/INS 松组合导航系统面临非线性干扰与量测噪声时变导致的定位精度下降问题，具体痛点及解决方案如下：

1. **单一系统导航缺陷明显**：
    - GPS 定位精度高但抗干扰能力弱，自主性差；
    - INS 自主导航、抗干扰能力强，但长时间导航会产生累积误差，单独使用易发散。
2. **传统滤波算法适配性不足**：
    - 扩展卡尔曼滤波（EKF）虽能处理非线性系统，但默认量测噪声固定，未考虑外界干扰导致的噪声时变特性；
    - 量测噪声变化会造成滤波精度下降，甚至影响系统正常工作。

为此，研究提出 **“变分贝叶斯 + EKF” 的 VB-EKF 松组合导航算法 **：

- 利用 EKF 将非线性系统的状态函数和量测函数线性化，融合 GPS 与 INS 数据，避免单系统导航发散；
- 引入变分贝叶斯算法，将状态值与量测噪声协方差的先验分布设为高斯分布与逆 Wishart 分布的乘积，适配噪声时变特性；
- 通过调节时变方差阵元素，提升滤波稳定性与导航定位精度。

#### 二、结论（实现的效果）

1. **导航定位精度显著提升**：
    - 位置偏离误差平均值从 EKF 的 7.06m 降至 3.16m，位置均方根误差从 11.27m 降至 6.44m，精度约为 EKF 算法的 2 倍；
    - 速度估计误差波动大幅减小，曲线更平稳，有效抑制了量测噪声时变带来的精度损失。
2. **滤波稳定性增强**：
    - VB-EKF 算法轨迹在真实轨迹附近小幅波动，长时间导航无频繁往返现象；
    - EKF 算法轨迹波动剧烈，而 VB-EKF 能在较短时间内趋于稳定，鲁棒性更强。
3. **解决单系统发散问题**：
    - 松组合模式将 GPS 的位置、速度信息反馈至 INS，有效抑制 INS 单系统导航定位的发散现象，满足长时间导航需求。
4. **现存权衡**：
    - 算法计算量较 EKF 更大，实时性略差，但精度与稳定性的提升更符合无人机导航的核心需求。



### 基于 GPS 和 2D 激光雷达数据融合的定位方法研究（何明洲）


[[基于GPS和2D激光雷达数据融合的定位方法研究_何明洲.pdf]]
==简单来说就是优化SLAM+GPS分隔地图==

#### 一、摘要（解决的问题）

车辆定位中单一传感器精度不足、多传感器融合适配性差，难以满足自动驾驶高精度需求，具体痛点及解决方案如下：

1. **单一传感器定位缺陷**：
    - 民用 GPS 定位误差达 3-30m，受卫星时钟、电离层、环境遮挡等因素影响，精度无法满足自动驾驶需求；
    - 2D 激光雷达虽局部测距精度高，但数据存在静态（机械结构、安装）和动态（车辆速度）误差，且单独使用缺乏全局定位能力。
2. **现有融合方法短板**：
    - 传统 DBSCAN 聚类算法因固定邻域阈值，不适配激光雷达数据（点间距随测距距离增大而变大），聚类误判率高；
    - Split-Merge 特征提取算法拟合效果不佳，道路环境建模精度不足；
    - 多传感器数据融合未充分结合 GPS 全局优势与激光雷达局部优势，且未考虑道路关键点有无的动态场景。

为此，研究提出 **“激光雷达数据优化 + GPS - 激光雷达组合定位 + EKF 多数据融合” 的一体化方案 **：

- 激光雷达数据处理：修正静态与动态误差，提出自适应邻域阈值 DBSCAN 聚类算法，优化 Split-Merge 算法以建立精准道路环境特征模型；
- 组合定位策略：GPS 粗定位确定关键栅格区域，激光雷达建模后与地图关键点匹配，获取局部精确定位；
- 数据融合：基于扩展卡尔曼滤波（EKF），融合 GPS 数据、激光雷达定位数据、车速及航向数据，分 “检测关键点前、检测中、离开后” 三阶段动态融合。

#### 二、结论（实现的效果）

1. **激光雷达数据处理效果显著**：
    - 误差修正后，激光雷达最大误差从 31.51mm 降至 7.20mm，平均误差从 6.58mm 降至 2.12mm；
    - 改进 DBSCAN 聚类算法误判率为 0，优于传统 DBSCAN（误判类别数 2-6 个）；
    - 优化后的 Split-Merge 算法建模平均误差降低，场景一从 17.9cm 降至 10.325cm，场景二从 14.27cm 降至 11.90cm。
2. **组合定位精度大幅提升**：
    - GPS - 激光雷达组合定位平均误差 1.39m，最大误差 2.39m，远优于单独 GPS（平均误差 10.31m、最大 18.90m）；
    - 关键栅格区域确定方法有效解决相似道路环境匹配问题，提升匹配成功率。
3. **多数据融合定位稳定可靠**：
    - EKF 三阶段融合后，实际道路实验平均距离误差仅 1.91m，最大误差 3.35m，显著优于 GPS（13.19m）和 GPS-INS（6.56m）；
    - 系统无需额外辅助设施，适配自动驾驶汽车原有传感器，简单易行，实时性满足工程需求。
4. **现存优化方向**：
    - 道路建模仅适用于线性特征，对非线性道路轮廓适配不足；
    - 2D 激光雷达获取数据有限，面对复杂环境（如障碍物遮挡关键点）时，需结合多线激光雷达或机器视觉进一步优化。



### 基于 EKF-NN 的 INS/GPS 组合导航方法研究（梁成程）


[[基于EKF-NN的INS_GPS组合导航方法研究_梁成程.pdf]]
==对于EKF的算法优化改进，后期有需要可以参考==

#### 一、摘要（解决的问题）

船舶 INS/GPS 组合导航系统存在单一系统缺陷与 GPS 信号异常时导航精度下降的问题，具体痛点及解决方案如下：

1. **单一导航系统性能不足**：
    - INS 自主导航、输出频率高，但误差会随时间累积，长期导航精度下降；
    - GPS 定位精度高、误差无累积，但自主性差、易受干扰，高动态环境适用性不佳。
2. **现有组合导航短板**：
    - 传统粒子滤波（PF）存在粒子退化问题，估计精度有限；
    - 组合导航系统过度依赖 GPS 信号，当 GPS 信号遮挡、受干扰或异常时，滤波缺乏有效量测更新，导致导航解发散，精度大幅降低。

为此，研究提出 **“增强粒子滤波 + EKF-NN 融合” 的双方案策略 **：

- 针对粒子退化问题：结合集合卡尔曼滤波（EnKF）与马尔可夫蒙特卡罗（MCMC）思想，设计增强粒子滤波（EPF）算法，提升正常工况下的估计精度；
- 针对 GPS 信号异常问题：提出 EKF-NN 组合算法，GPS 信号正常时用 EKF 完成精确解算并训练神经网络（NN）；GPS 信号异常时，由训练好的 NN 预测 EKF 量测值，实现滤波更新与 INS 状态估计，保障导航连续性。

#### 二、结论（实现的效果）

1. **增强粒子滤波（EPF）性能优于传统 PF**：
    - 在船舶直行与旋回航行仿真中，EPF 有效避免粒子贫化，位置误差（东向、北向均小于 10m）、速度误差（北向最大 0.05m/s）均小于传统 PF 算法，姿态误差波动更小，估计精度更优。
2. **EKF-NN 算法解决 GPS 异常问题**：
    - GPS 信号正常时，EKF-NN 与 EKF、UKF 精度相当，位置误差均值约 0.43-1.02m，速度误差均值约 0.16-0.32m/s；
    - GPS 信号异常时段（250-300s、400-450s），EKF-NN 误差增长被有效抑制，东向位置误差小于 8m、北向小于 10m，速度误差最大 2.5m/s，远优于 EKF（东向位置误差最大超 129m）和 UKF（北向速度误差最大 18m/s）；
    - 姿态误差方面，GPS 异常时 EKF-NN 的横滚角、翻滚角误差均小于 EKF 和 UKF，导航稳定性显著提升。
3. **导航误差快速收敛**：
    - 两种算法均能实现导航误差快速收敛，EKF-NN 在 GPS 信号恢复后可快速回归高精度导航状态，满足船舶航行对精度与稳定性的核心需求。
4. **现存优化方向**：
    - 目前仅针对松耦合系统研究，未来可拓展至紧耦合、超紧耦合系统，进一步提升定位精度；
    - GPS 长期丢失时仍需补充其他传感器，多传感器信息融合技术需进一步完善。


---


## 1110
### 自动驾驶和智能网联场景设计 —— 以南京市江心洲为例（程明）

[[自动驾驶和智能网联场景设计——以南京市江心洲为例_程明.pdf]]
==和大车项目无关，他重在改造场景而非研究大车本身==
#### 一、摘要（解决的问题）

智能网联汽车产业缺乏成熟的车路协同测试验证环境，现有道路设施未适配多场景测试需求，产业链协同不足，具体痛点及解决方案如下：

1. **测试环境缺失**：缺乏集成车、路、云的综合测试基地，无法满足自动驾驶、智能网联技术的全场景验证需求。
2. **道路设施适配性差**：现有道路未规模化布设感知、通信、计算设备，难以支撑车路协同数据交互与复杂场景测试。
3. **场景覆盖不全面**：缺乏结合本地道路特色的个性化测试场景，且跨产业资源协同不足，技术转化与应用效率低。

为此，研究提出 **“基础设施升级 + 三类场景搭建 + 数据平台融合” 的整体方案 **：

- 改造范围：选取南京市江心洲 11.5km² 区域，对 75 个路口进行智能网联升级，布设摄像机、毫米波雷达、激光雷达等设备，形成 “三横三纵一环线” 格局；
- 场景设计：搭建 29 项自动驾驶场景、24 项智能网联场景、24 项本地特色场景，覆盖基础功能、协同交互与地域专属需求；
- 数据协同：构建车、路、云数据交互平台，规范感知、状态、预警等数据传输标准，实现出行工具与城市基础设施高效协同。

#### 二、结论（实现的效果）

1. **建成综合测试示范区**：
    - 形成半开放式自动驾驶测试环境，集成 5G-V2X、边缘计算、高精度定位等技术，可支撑精准公交、Robotaxi 等多类应用场景测试；
    - 三类场景全面覆盖，满足行业标准要求，能为企业提供从技术验证到方案集成的全流程服务。
2. **促进产业协同发展**：
    - 吸引智能网联相关企业入驻测试，推动高校、科研院所与企业合作，加速技术孵化与成果转化；
    - 打破产业链壁垒，整合交通、通信、能源等跨产业资源，构建自主可控的现代产业体系。
3. **带动区域全面发展**：
    - 完善区域基础设施建设，通过科普展馆与体验活动提升公众认知，扩大技术影响力；
    - 助力汽车产业转型升级，形成全新出行生态系统，为智慧城市、智能交通建设提供示范。


### 低速履带式挖掘机自动驾驶端到端决策算法研究（马荣华）

[[低速履带式挖掘机自动驾驶端到端决策算法研究_马荣华.pdf]]
==只有对于双目和激光雷达的结合，没有融合GPS等多维参数==
#### 一、摘要（解决的问题）

工程机械自动驾驶研究滞后，单一传感器与传统算法难以适配非结构化作业场景，具体痛点及解决方案如下：

1. **行业技术短板**：智能化、无人化技术集中于汽车领域，工程机械相关研究较少，且作业环境为矿山、山地等非结构化道路，工况复杂、安全风险高、人力成本大。
2. **传感器与算法适配不足**：传统决策算法架构冗余，难以应对复杂工况；单一传感器（单目相机、激光雷达）获取信息有限，端到端决策精度低，无法满足挖掘机履带控制需求。

为此，研究提出 **“双传感器 + 端到端决策网络” 的解决方案 **：

- 传感器选型：选用双目相机和激光雷达，分别构建多模态决策网络与点云决策网络，互补获取环境信息；
- 网络优化：双目图像网络以轻量级 BiseNet 为基础，融合语义分割与 RGB 图像特征，嵌入坐标注意力机制提升精度；激光雷达网络基于 X-Conv 搭建，嵌入残差连接优化性能；
- 实车验证：在非结构化道路场景下，通过数据集训练与实车测试，实现挖掘机自动行走与自主避障。

#### 二、结论（实现的效果）

1. **双目图像决策网络性能更优**：
    - 开源数据集测试中，转向角和速度平均精度达 91.04%，平均误差 1.59，显著优于基础 ResNet18（精度 80.96%）和 BiSeNet（精度 76.04%）；
    - 真实场景数据集测试中，左右履带控制信号平均精度达 89.51% 和 89.35%，平均误差仅 0.01，满足控制信号预测需求。
2. **激光雷达点云网络表现尚可但不及双目方案**：
    - 嵌入残差连接后，真实场景数据集平均精度提升至 81.66%，但仍低于双目图像网络；
    - 采样点数增加至 192 时，网络损失显著下降，平衡了训练效率与精度。
3. **实车测试验证有效性**：
    - 在非结构化道路场景中，双目图像网络成功实现挖掘机静态避障（躲避 1×1×1.5m 障碍物）与动态避障（躲避行人），自动行走轨迹与预设轨迹基本一致，控制信号跟随效果良好；
    - 挖掘机可完成直行、转弯、自主回正动作，机身震荡小，满足特定场景自动驾驶需求。
4. **现存优化方向**：
    - 需扩展数据集覆盖更多工况，完善复杂任务（如自动作业）的决策能力；
    - 未来可融合毫米波雷达、GPS 等多传感器信息，结合规则算法进一步提升网络鲁棒性。


### 大范围场景下的室外无人车定位与建图技术研究（曾豪霆）

[[大范围场景下的室外无人车定位与建图技术研究_曾豪霆.pdf]]
==硬件上主要采用云乐中型线控无人车小蚂蚁底盘、威力登 VLP-16 激光雷达、轮趣 N100 惯性测量单元（IMU）以及 NVIDIA Jetson TX2 车载工控机。==

==针对室外场景的优化，通过构建条件性地面约束自适应应对平整与不平整地面以减少地图 Z 轴漂移，引入激光雷达点云强度信息构建球形强度图提升地图精细度，提出基于投影匹配距离排序结合强度差异的策略去除动态点云干扰，改进回环检测算法融合强度信息优化相似性判断并结合因子图进行全局位姿优化，还通过 IMU 预积分校正激光雷达运动畸变，确保大范围室外复杂环境下定位与建图的精度和鲁棒性。==
#### 一、摘要（解决的问题）

大范围室外场景中激光 SLAM 存在定位漂移、地图精细度不足、动态环境适配差、回环检测不准等问题，具体痛点及解决方案如下：

1. **定位与建图核心缺陷**：
    - 地图易沿 Z 轴漂移，大范围复杂环境中地面凹凸不平会加剧该问题，影响定位稳定性；
    - 点云配准仅依赖几何特征，地图细节模糊、边缘点云厚重，精细度不足；
    - 动态物体（行人、车辆）会产生干扰点云，导致匹配错误，影响导航规划；
    - 回环检测仅依赖欧式距离，相似性判断不准确，难以消除累积误差。

为此，研究提出 **“多约束融合 + 动态过滤 + 优化回环” 的 SLAM 改进方案"**：

- 前端优化：构建条件性地面约束（自适应平整 / 不平整地面）减少 Z 轴漂移，引入点云强度信息构建球形强度图，与几何特征共同优化位姿估计；
- 动态处理：提出基于投影匹配距离排序的动态点云过滤策略，结合强度差异去除干扰点；
- 后端优化：改进回环检测算法，融合强度信息优化相似性度量函数，结合因子图进行全局位姿优化，提升回环准确性与地图一致性。

#### 二、结论（实现的效果）

1. **定位精度显著提升**：
    - 公开数据集 KITTI 测试中，绝对轨迹误差均方根（RMSE）较 LVI-SAM 降低 54.5%，最大误差从 5.055m 降至 3.270m，轨迹更贴合地面真值；
    - 自采集数据集测试中，地面点提取准确率优于 LeGO-LOAM，远距离地面点识别更精准，Z 轴漂移得到有效抑制。
2. **地图质量大幅改善**：
    - 融合强度特征后，地图细节点云更薄、边缘更锐，无重影现象，能清晰还原车辆、树木、建筑等环境细节；
    - 动态点云过滤模块有效去除行人、车辆等干扰，定位误差最大值减小 29.3%，地图一致性显著提升。
3. **回环检测与全局优化有效**：
    - 改进回环检测算法减少冗余约束，回环闭合准确率提升，绝对轨迹误差标准差降低 8.8%；
    - 因子图全局优化后，轨迹形成完整闭环，与卫星地图高度吻合，300 米真实场景测试中无分层、断裂现象。
4. **系统鲁棒性适配大范围场景**：
    - 算法在城市、校园等多类型大范围场景中稳定运行，适配凹凸路面、动态环境等复杂情况；
    - 兼顾实时性与精度，硬件部署成本可控，满足室外无人车实际应用需求。
5. **现存优化方向**：
    - 可融合视觉相机进一步提升动态物体剔除效果，丰富环境纹理信息；
    - 未来可结合路径规划算法，实现地图复用与无人车自主导航，拓展应用场景。

### 基于多传感器融合的室外巡检机器人同时定位与建图研究（马尔斯）


[[基于多传感器融合的室外巡检机器人同时定位与建图研究_马尔斯.pdf]]
==和我目前所想的想法很贴合，值得参考==

#### 一、摘要（解决的问题）

室外巡检机器人在 GPS 信号中断或受干扰时，单一传感器 SLAM 精度不足，传统融合方案存在累计误差与鲁棒性短板，具体痛点及解决方案如下：

1. **定位核心痛点**：
    - GPS 易受非视距、多路径影响，在拒止环境中完全失效，传统依赖 GPS 的定位方法无法适配；
    - 单一激光雷达 SLAM 存在环境退化、采样频率低问题，纯 IMU 测量误差随时间累积，二者融合在大范围场景下精度下降；
    - 传统前端里程计精度不足，多传感器融合时易引入异常 GPS 数据，全局定位一致性差。

为此，研究提出 **“多传感器紧耦合 + 因子图优化” 的 SLAM 解决方案 **：

- 传感器融合：以激光雷达为核心，融合 IMU 与 GPS，完成多传感器外参、内参标定及时空同步；
- 前端优化：采用迭代误差卡尔曼滤波（IESKF）紧耦合激光雷达与 IMU，提升 GPS 中断时的位姿估计精度；
- 后端优化：基于因子图融合激光惯性里程计因子、IMU 预积分因子、回环因子与 GPS 因子，引入 GPS 状态与置信度筛选策略，剔除异常数据；
- 效率优化：采用关键帧与滑动窗口策略，降低后端计算负荷。

#### 二、结论（实现的效果）

1. **前端里程计精度显著提升**：
    - KITTI 数据集测试中，IESKF 紧耦合方案的绝对轨迹误差（ATE）最大值较传统 NDT 里程计提升 61.8%-81.76%，平均误差提升 45.22%-88.02%，局部定位精度更优。
2. **多传感器融合鲁棒性突出**：
    - GPS 无中断时，KITTI 数据集 ATE 均方根误差（RMSE）较 LIO-SAM 提升 3.76%-25.74%，智能科技园场景下较 LIO-SAM 提升 24.98%，地图与卫星图高度吻合；
    - GPS 中断 50-200 秒时，算法仍保持高精度，KITTI 数据集 ATE 平均误差较 LIO-SAM 降低 12.05%-29.01%，智能科技园场景下降低 12.05%-19.61%，鲁棒性优于传统方案。
3. **异常数据处理有效**：
    - GPS 状态与置信度筛选策略成功剔除波动数据，避免因子图优化引入异常约束，提升了复杂环境下的定位稳定性。
4. **实际场景适配性强**：
    - 巡检机器人平台在 7.84 万平方米的智能科技园区完成建图，行驶速度 2.5m/s，定位精度满足室外巡检需求，适配园区复杂路况。
5. **现存优化方向**：
    - 可采用更高精度、更快频率的固态激光雷达替代机械激光雷达，进一步提升系统精度；
    - 未来可融入 UWB 定位、深度相机等传感器，拓展室内外多场景适配能力。


### 室外场景下基于三维点云的多边形网格建图方法研究（黄麒霓）

[[室外场景下基于三维点云的多边形网格建图方法研究_黄麒霓.pdf]]


“动态精准建图”—— 机器人在室外移动时，会实时把激光雷达扫到的点云数据，转换成一个个带几何信息（比如平面、棱角）和拓扑关系（比如 “这块网格和旁边那块是连在一起的”）的多边形小网格，重点是 “让机器人知道‘这里有个 1 米高的台阶’‘前面 5 米是面墙’”，是给机器人做定位、避障用的 “环境说明书”。

#### 一、摘要（解决的问题）

传统激光雷达点云建图存在拓扑缺失、存储冗余、计算效率低等问题，现有网格建图方法在增量更新一致性、几何保真度与资源占用平衡上存在短板，具体痛点及解决方案如下：

1. **建图核心痛点**：
    - 点云地图缺乏拓扑连接信息，密度不均，场景理解处理复杂度高；
    - 现有网格建图易出现体素间隙、网格断裂，增量更新时定位与建图协同性差；
    - 网格模型冗余面片多，存储与计算成本高，复杂场景下实时性不足。

为此，研究提出 **“体素支持 + 点网匹配 + 网格优化” 的增量式建图方案 **：

- 数据管理：设计层次化体素数据框架，结合 ikd-Tree 实现点云与网格高效关联，支撑大规模数据处理；
- 定位与建图协同：提出点到网格里程计，利用网格法向信息优化位姿估计，同步执行增量式三角网格划分；
- 网格优化：采用混合加权体素融合策略提升精度，通过基于加权曲率的顶点对收缩技术简化网格，减少冗余；
- 工程适配：设计可分离式模块化架构，支持离线建图与多系统集成，提升实用性。

#### 二、结论（实现的效果）

1. **建图精度与完整性突出**：
    - Mai City 数据集测试中，精确率达 85.27%、召回率 83.25%、F 分值 84.25，优于 SLAMesh、ImMesh 等主流方法，能完整还原车辆、树木等场景细节；
    - KITTI 数据集上，点到网格里程计有效降低定位误差，序列 04 均方根误差从 0.45m 降至 0.25m，长距离场景下轨迹稳定性优于传统方法。
2. **存储与计算效率显著优化**：
    - 970m 真实场景测试中，数据量降至原始的 58%，网格简化后顶点数量减少约 50%、面片数量减少约 40%，内存占用降低 40%；
    - 多线程并行处理使建图速度提升 5-7 倍，单帧处理耗时从 0.7s 降至 0.15s，满足实时建图需求。
3. **场景适配性与实用性强**：
    - 校园复杂场景（含大型建筑、树木）建图中，网格水密性良好，能准确捕捉建筑物轮廓与道路形状，无明显轨迹畸变；
    - 模块化设计支持离线建图，可集成至多种 SLAM 系统，适配不同硬件平台，在城市作战、灾后救援等场景具备应用潜力。
4. **几何保真度平衡优化**：
    - 网格简化过程中平均误差控制在 0.038m 以内，均方根误差小于 0.23m，在减少冗余的同时保留关键几何特征，避免过度平滑或细节丢失。
5. **现存优化方向**：
    - 可融合 RGB-D 相机、毫米波雷达等多传感器数据，引入语义分割技术增强环境理解能力；
    - 未来可探索分布式网格建图与动态环境自适应更新，适配更大规模场景与多智能体协同作业需求。


## 1111
### 面向具身智能的三维室内场景生成方法研究（姜渤巍）

[[面向具身智能的三维室内场景生成方法研究_姜渤巍.pdf]]


#### 一、摘要（解决的问题）

现有室内场景生成方法存在用户指令对齐不足、场景逻辑一致性欠缺，且忽视机器人导航适配性的问题，具体痛点及解决方案如下：

1. **核心痛点**：
    - 用户指令理解与场景生成匹配度低，传统方法易出现家具碰撞、边界越界等逻辑错误；
    - 场景生成侧重人类视角的视觉与功能需求，缺乏机器人导航友好性设计，家具布局可能阻碍路径规划；
    - 现有数据集（如 3D-FRONT）缺少机器人交互相关标注，难以支撑适配机器人的场景生成训练。

为此，研究提出两类解决方案：

- 方案一（CoT2Scene 框架）：基于思维链（CoT）增强大语言模型，构建室内设计规范知识库，将抽象用户指令拆解为功能分区、家具配置等步骤，通过空间约束规则确保生成场景的逻辑一致性与指令匹配度；
- 方案二（Nav2Scene 微调机制）：定义路径规划评分（PPS）作为机器人导航适配性指标，构建含 4041 个房间的机器人路径规划评估数据集，训练 ScoreNet 神经网络预测场景 PPS 值，以即插即用方式微调整体场景生成器，优化机器人导航效率。

#### 二、结论（实现的效果）

1. **指令匹配与场景一致性显著提升**：
    - CoT2Scene 在 3D-FRONT 数据集测试中，卧室场景越界率从 53.11% 降至 23.28%，FID 值低至 29.07，CKL 值 0.0168，均优于 ATISS、LayoutGPT 等主流方法，有效避免家具碰撞与边界越界；
    - 思维链引导使场景生成能精准匹配用户文本指令，如 “现代简约客厅” 可生成符合风格的家具搭配与空间布局，功能分区合理性提升。
2. **机器人导航适配性大幅优化**：
    - Nav2Scene 微调后，卧室场景 PPS 值从 0.86 提升至 0.94，餐厅场景从 0.91 提升至 0.99，机器人路径规划效率显著提高；
    - 生成场景的可行区域连贯性增强，路径规划更简洁，重复路径占比降低，覆盖面积占比提升至 0.978 以上。
3. **生成质量与多样性兼顾**：
    - 微调后场景的 FID、KID 等视觉质量指标与原始生成方法相当，SCA 指标接近 50%，生成场景与真实场景难以区分；
    - 支持场景补全、重排列等下游任务，补全场景能合理填充灯具、衣柜等家具，重排列后可消除过道遮挡，保持场景自然性与多样性。
4. **数据集与工程适配性强**：
    - 构建的机器人路径规划评估数据集补充了导航性能标注，完善了 3D-FRONT 数据集的应用场景；
    - Nav2Scene 为即插即用模块，可集成至 ATISS、DiffuScene 等现有框架，CoT2Scene 支持模块化扩展，具备实际应用潜力。
5. **现存优化方向**：
    - 可扩展多模态输入（如图像、草图），适配复杂形态机器人与多样化任务需求；
    - 未来可融合图神经网络优化知识库构建，结合真实场景扫描数据缓解数据集类型不均衡问题，提升模型泛化能力。


### 基于交叉视图的多无人平台协同导航算法研究（乔涛）
[[基于交叉视图的多无人平台协同导航算法研究_乔涛.pdf]]
==和大车不太搭，他还配备了无人机，是无人机+无人车方案==

#### 一、摘要（解决的问题）

单无人平台感知能力有限，传统协同导航在 GNSS 拒止环境下定位精度不足，且对小目标、遮挡目标的检测能力薄弱，具体痛点及解决方案如下：

1. **核心痛点**：
    - 复杂环境中，小目标与遮挡目标检测精度低，影响视觉相对定位质量；
    - GNSS 信号中断或受干扰时，仅依赖 IMU 或测距的协同导航易出现误差发散，定位稳定性差；
    - 多平台协同中观测矩阵维度随拓扑变化，计算与通信负担重，工程实现难度大。

为此，研究提出 **“改进检测 + 交叉视图 + 分散式融合” 的协同导航方案 **：

- 感知优化：改进 YOLOv8s 模型，引入渐进特征融合模块（AFPN）并优化损失函数，结合 D435i 深度相机，提升小目标与遮挡目标检测及相对定位精度；
- 导航算法：融合测距、视觉惯性里程计（VIO）、交叉视图观测及间歇 GNSS 数据，构建统一误差观测模型，采用序贯滤波推导分散式协同导航算法，适配动态拓扑；
- 工程实现：搭建无人车 - 无人机异构平台，基于 ROS 实现分布式通信与多传感器时空同步，降低计算与通信开销。

#### 二、结论（实现的效果）

1. **目标检测与相对定位精度提升**：
    - 改进后的 YOLOv8s 模型 mAP@0.5 达 82.23%，较原始模型提升 1.11 个百分点，对小目标（如杯子）、遮挡目标（如部分遮挡的绿植）检测能力显著改善；
    - 视觉相对定位误差模型拟合 R² 均高于 0.91，为协同导航观测提供可靠误差建模支持。
2. **GNSS 拒止环境下定位性能优异**：
    - 无人机、无人车在仅依赖 IMU 时定位误差显著发散（绝对位置 RMSE 最高达 227.55m），融合交叉视图与多源信息后，绝对位置 RMSE 最低降至 5.06m；
    - 较传统协同导航（仅融合测距），定位精度提升 35.31%-84.26%，有效抑制误差累积，保持长时稳定。
3. **GNSS 存在环境下精度进一步优化**：
    - 融合交叉视图后，无人机绝对位置 RMSE 从 0.92m 降至 0.70m，无人车从 0.81m 降至 0.36m，姿态误差也显著降低，兼顾精度与鲁棒性；
    - 多源观测互补减少 GNSS 信号波动影响，提升定位连续性。
4. **系统工程实用性强**：
    - 分散式架构结合序贯滤波，解决了动态拓扑下观测矩阵维度不固定的问题，单平台计算负载降低，通信延迟控制在 150ms 内；
    - 基于 ROS 实现异构平台（2 架无人机 + 1 辆无人车）协同，通过 ZGET HOMER 设备实现高带宽低延迟通信，硬件部署稳定可靠。
5. **现存优化方向**：
    - 可引入 6D 位姿检测丰富交叉视图观测维度，实现平台间相对姿态与位置联合估计；
    - 未来可增加平台间直接视觉观测机制，提升无共视目标场景下的协同定位能力，增强遮挡环境下的观测冗余。


### 自动导航小车（AGV）驱动与导航系统的研究（刘书婷）
[[自动导航小车（AGV）驱动与导航系统的研究_刘书婷.pdf]]
==用的是磁条导航，和大车不搭==


磁条导航属于**预定路径导航**，核心是通过在 AGV 行驶路径上铺设磁性材料（如磁条），AGV 底部搭载磁导航传感器，实时检测磁条产生的微弱磁场，通过分析磁场偏差来纠正行驶方向，实现沿固定路径行驶。它的关键特点很明确：比如路径由磁条物理定义，AGV 只能沿磁条行进，调整路径需重新铺设磁条；技术门槛低、成本便宜，磁条铺设和维护简单；抗干扰能力较强，不受光照、粉尘等环境因素影响，但对地面平整度有一定要求（需保证磁条与传感器的稳定距离）；定位精度依赖磁条质量与传感器采样密度，通常能满足工业场景的基础运输需求（如汽车内饰线、仓储短途搬运）。

#### 一、摘要（解决的问题）

AGV 在实际应用中存在驱动控制精度不足、导航方式适配性差、避障效果不佳（如前后车追尾）等问题，具体痛点及解决方案如下：

1. **核心痛点**：
    - 双轮差速等驱动方式的运动学模型不明确，影响 AGV 转向与直行精度；
    - 多种导航方式各有短板（如电磁导引路径难改、激光导引成本高），缺乏针对特定场景的适配选择；
    - 避障传感器检测范围与灵敏度不足，易出现碰撞，传统避障算法存在目标不可达等缺陷。

为此，研究提出针对性解决方案：

- 驱动系统：建立双轮差速驱动与导向驱动轮的运动学模型，明确车轮转速、转弯半径与车体位姿的关系，为精准控制提供理论支撑；
- 导航选择：分析电磁、磁带、激光等多种导引方式的优缺点，针对汽车内饰线场景，选定灵活、低成本的磁条导航方案；
- 避障优化：采用超声波传感器实现距离检测，结合改进人工势场法（引入目标距离参数优化势场函数），解决传统算法的局部最小与目标不可达问题。

#### 二、结论（实现的效果）

1. **驱动控制精度提升**：
    - 建立的双轮差速运动学模型可精准计算转弯半径与车体速度，当左右轮转速一致时实现直线运动，转速差异时实现灵活转向，为 AGV 精准控制提供理论依据；
    - 经受力分析优化驱动系统参数，可有效克服摩擦阻力与惯性阻力，满足 AGV 在室内场景的匀速与加速运行需求。
2. **导航适配性与实用性强**：
    - 选定的磁条导航方案适配汽车内饰线的光滑地面、狭小空间与多变路径需求，铺设与拆装便捷，成本较低；
    - 通过地标磁条实现 AGV 高速、中速、低速、停止等状态切换，满足生产线上的多工况需求。
3. **避障效果显著改善**：
    - 超声波传感器实时检测障碍物距离，响应快速、成本低廉，结合改进人工势场法，有效避免 AGV 运行中的追尾与碰撞；
    - 优化后的势场函数解决了传统算法中目标在障碍物影响范围内无法到达的问题，提升了复杂环境下的避障可靠性。
4. **工程应用价值突出**：
    - 研究成果成功应用于汽车内饰线与后桥输送线的 AGV 项目，实际运行中 AGV 定位精准、导航稳定、避障有效，满足工业生产的物料运输需求；
    - 对驱动、导航、避障系统的研究结论，为同类 AGV 的设计与开发提供了可借鉴的工程经验。
5. **现存优化方向**：
    - 可结合神经网络优化超声波测量模型，进一步提升定位精度；
    - 未来可探索 GPS 等新型导航方式的应用，深化复杂环境下的避障算法研究，降低外界干扰影响。



### 3D 激光雷达 SLAM 算法综述（周治国）
[[3D激光雷达SLAM算法综述_周治国.pdf]]
==3D激光雷达的介绍论文，目前只会用简单的2D激光雷达==


#### 一、摘要（解决的问题）

无人平台在大范围、复杂环境中自主定位与导航需求日益严苛，传统 SLAM 算法存在精度不足、实时性差、鲁棒性弱等问题，具体痛点及研究方向如下：

1. **核心痛点**：
    - 单一激光雷达 SLAM 易受点云稀疏性、运动扰动影响，定位漂移明显，尤其在动态环境或传感器退化场景下性能下降；
    - 传统算法在大规模场景中计算负载高，难以兼顾实时性与建图精度；
    - 闭环检测易受感知歧义影响，动态物体干扰会降低地图一致性，且多传感器融合策略不够高效。

为此，研究聚焦 3D 激光雷达 SLAM 的核心模块优化与算法评估，核心方向包括：

- 构建图优化为核心的 SLAM 框架，整合扫描匹配、闭环检测、后端优化、地图表示四大关键模块；
- 探索激光 - 惯性紧耦合融合、动态物体滤除、深度学习辅助特征提取等技术，提升算法鲁棒性；
- 建立统一评估标准，对主流开源算法进行精度、耗时、帧率的横向对比，明确最优方案。

#### 二、结论（实现的效果）

1. **算法框架与技术趋势明确**：
    - 图优化已成为 3D 激光雷达 SLAM 的主流方案，相比传统滤波器方法，能更好地处理全局一致性问题，支持并行计算；
    - 激光惯性紧耦合（如 LIO-SAM）、动态物体检测、语义地图融合、深度学习辅助配准已成为核心研究热点，有效提升了复杂环境适应性。
2. **主流开源算法性能清晰**：
    - 精度方面：LIO-SAM 综合表现最优，在 KITTI 00 序列测试中，绝对轨迹误差（ATE）RMSE 为 1.303，相对位姿误差（RPE）RMSE 为 0.028，显著优于 LOAM、LeGO-LOAM 等算法；
    - 实时性方面：LeGO-LOAM 帧率最高（40.0 fps），LIO-SAM 以 28.6 fps 的帧率兼顾实时性与精度，Cartographer 在 3D 场景中实时性最差（仅 7.0-8.3 fps）；
    - 适用性方面：LeGO-LOAM 轻量化优势明显，适合低功耗嵌入式系统；hdl_graph_slam 支持 GPS、IMU 多源融合，适配复杂场景。
3. **应用场景广泛且潜力巨大**：
    - 已成功应用于移动机器人（物流、巡检）、无人驾驶、测绘（室内、矿井、林业）等领域，支持无人车、无人机、无人船等多类无人平台；
    - 多车协同建图、实时高精度测绘、动态环境长期定位成为未来重要应用方向。
4. **现存优化方向**：
    - 需进一步提升算法轻量化与通用化水平，解决相似场景误匹配问题；
    - 加强多传感器（激光雷达 + 深度相机 + 毫米波雷达）融合，深化深度学习在闭环检测、特征提取中的应用；
    - 完善动态环境下的地图更新与长期定位机制，降低计算资源消耗。

### 视觉 SLAM 综述（权美香）
[[视觉SLAM综述_权美香.pdf]]
==视觉SLAM的介绍论文，之前从没用过视觉SLAM==

#### 一、摘要（解决的问题）

视觉 SLAM 以相机为唯一外部传感器，需解决自主定位与环境建图的核心问题，同时应对特征处理、误差累积、传感器适配等关键挑战，具体痛点及解决方案如下：

1. **核心痛点**：
    - 特征检测与匹配效率低、鲁棒性不足，传统特征（如 SIFT）计算复杂，难以满足实时性要求；
    - 帧间匹配易产生累积误差，闭环检测难度大，影响地图全局一致性；
    - 不同视觉传感器（单目、双目、RGB-D）存在各自局限（如单目缺深度、RGB-D 探测距离短），适配场景有限；
    - 早期滤波类算法计算复杂度高，线性化易引入不确定性。

为此，研究聚焦两大技术路径与关键模块优化：

- 算法分类：分为基于特征的 SLAM（提取 SIFT、SURF、ORB 等特征进行匹配）和直接 SLAM（直接操作像素强度，无需特征提取）；
- 关键模块优化：优化关键帧选择策略减少误差，通过词袋模型等提升闭环检测效果，采用位姿图优化消除累积误差；
- 传感器适配：分析单目、双目、RGB-D 相机的适配场景，探索多传感器融合（视觉 + IMU）与深度学习结合的优化方向。

#### 二、结论（实现的效果）

1. **算法体系成熟，核心模块效能提升**：
    - 特征处理方面：ORB 特征凭借计算速度快（是 SIFT 的 100 倍）、兼具旋转不变性的优势，成为主流选择，大幅提升 SLAM 实时性；
    - 闭环检测方面：词袋模型结合几何验证的方法有效解决位置识别问题，图像对图像的匹配方式优于地图对地图、图像对地图模式；
    - 地图优化方面：位姿图优化（通过 g2o 框架实现）替代传统光束平差法，在保证精度的同时降低计算复杂度，实现全局误差均匀分配。
2. **主流算法各有优势，适配不同场景**：
    - 基于特征的算法：ORB-SLAM 作为完整系统，分追踪、建图、闭环三线程处理，定位精度高且实时性强；
    - 直接法：LSD-SLAM 可构建大规模半稠密地图，适配特征稀少环境，DTAM 能在 GPU 上实现实时稠密匹配；
    - RGB-D 相关算法：KinectFusion 首次实现实时稠密三维建图，为室内场景应用奠定基础。
3. **传感器适配性清晰，多源融合成趋势**：
    - 单目 SLAM：成本低、灵活，但缺深度信息、存在尺度不确定性；
    - 双目 SLAM：直接解决初始化问题，应用广泛，但系统复杂、成本高、探测范围有限；
    - RGB-D SLAM：易获取深度信息、可建稠密地图，但成本高、有效探测距离短；
    - 视觉 + IMU 融合：互补优势明显，如预积分 IMU 数据融合到因子图框架，定位误差显著降低（160m 轨迹漂移仅 0.5m，优于 Google Tango 的 1.4m）。
4. **技术拓展潜力大，应用场景广泛**：
    - 深度学习融合：已应用于立体匹配、位置识别、视觉里程计特征学习等子模块，提升鲁棒性与精度；
    - 应用场景：适用于移动机器人导航、室内三维重建、增强现实（AR）等领域，为自主定位与路径规划提供基础地图支持。
5. **现存优化方向**：
    - 需进一步提升复杂环境下的鲁棒性，降低计算复杂度，满足实时应用需求；
    - 深化多传感器融合（视觉 + 激光、毫米波雷达）与深度学习的结合，拓展传感器适配场景；
    - 解决动态环境下的建图与定位问题，提升视觉 SLAM 的实用性。



## 1112
### 基于 LeGO-LOAM 算法的激光雷达定位与室内地图构建（王勇涛）

[[基于LeGO-LOAM算法的激光雷达定位与室内地图构建_王勇涛.pdf]]
==LOAM适合用在室外场景的算法却用在室内，有点奇怪==

#### 一、摘要（解决的问题）

针对室内场景中无人机导航的高精度实时定位与建图需求，解决传统算法存在的地面特征利用不足、点云存储压力大、动态障碍物处理能力弱等问题，具体解决方案如下：

1. **核心痛点**：
    - LOAM 算法在室内地面丰富场景下未充分利用地面特征，导致俯仰角与高度方向漂移明显；
    - 激光雷达点云数据量大，存储与计算资源消耗高，难以适配低功耗嵌入式平台；
    - 传统静态地图易将动态障碍物（如行人）误判为永久障碍，影响导航可靠性。

为此，研究基于 LeGO-LOAM 算法提出优化方案：

- 算法优化：显式分离地面点，引入地面平面约束，提升分割与建图精度，抑制漂移；
- 轻量化设计：适配低功耗嵌入式系统，支持实时运行；
- 地图压缩与动态处理：结合八叉树（Octomap）压缩点云，集成概率更新机制，动态移除临时障碍物。

#### 二、结论（实现的效果）

1. **定位精度显著提升**：
    - 实验室场景中平均绝对轨迹误差（ATE）低至 0.25m，长走廊场景动态障碍物移除后，定位 RMSE 从 0.25m 降至 0.13m，地面约束有效抑制了高度与俯仰角漂移；
    - 特征提取阶段通过粗糙度分类边缘与平面特征，提升了室内结构化环境下的匹配稳定性。
2. **地图存储与更新高效**：
    - 八叉树压缩使地图存储空间降至原始点云的 15%，大幅降低存储压力；
    - 概率更新机制支持动态障碍物处理，障碍物移除响应延迟≤70ms，连续 10 次未观测区域会自动衰减占据概率，避免误判永久障碍。
3. **工程适配性强**：
    - 轻量化设计支持低功耗嵌入式平台实时运行，适配 Velodyne VLP-16 激光雷达的稀疏点云数据；
    - 建图流程（点云分割→特征提取→里程计优化→八叉树建模）完整，实验室场景 120s 即可完成高精度建图，分辨率达 0.1m。
4. **应用价值突出**：
    - 成功实现室内场景 6 自由度位姿估计与高效地图构建，为无人机自主导航提供可靠的定位与环境感知支持；
    - 适配实验室、长走廊等典型室内场景，兼顾精度、实时性与动态环境适应性。
5. **现存优化方向**：
    - 需进一步提升极端动态环境下的鲁棒性；
    - 可融合多传感器数据（如 IMU），增强非结构化室内场景的适应性。


### 基于 BA/NDT 与 LOAM 融合的激光 SLAM 方法（杨奎）

[[基于BA_NDT与LOAM融合的激光SLAM方法_杨奎.pdf]]
==对传统的LOAM算法的改进优化，不过更建议用LeGo-LOAM==
#### 一、摘要（解决的问题）

针对传统 3D 激光雷达 LOAM 算法缺乏回环检测、雷达移动过快时易出现里程计漂移的核心问题，提出 BA（光束法平差）/NDT（正态分布变换）与 LOAM 融合的 SLAM 方案，具体解决方案如下：

1. **核心痛点**：
    - LOAM 算法无回环检测功能，大场景建模中里程计误差累积导致定位漂移；
    - 雷达移动速度过快时，LOAM 跟踪易丢失，无法输出有效位姿；
    - 传统帧间配准依赖 ICP 算法，计算耗时久，实时性不足。

为此，研究设计三层优化架构：

- 前端：LOAM 算法通过帧到帧里程计估计输出粗位姿，保留其线面特征提取优势；
- 中端：改进激光 BA 算法，最小化特征点与边缘、平面的距离，优化粗位姿为精位姿；
- 后端：NDT 估计线面特征矩阵，经旋转不变性转化执行回环检测，实现全局位姿修复与地图对齐。

#### 二、结论（实现的效果）

1. **定位精度大幅提升**：
    - KITTI 数据集测试中，总体位置 RMSE 仅 16cm，较 LOAM（23.8cm）误差减小 33%；
    - 实际教学楼场景测试（以 Cartographer 位姿为基准），总体 RMSE 为 20.23cm，较 LOAM（0.8023m）误差减小 75%，有效修复大场景地图漂移；
    - 雷达移动过快的 KITTI02 数据集场景中，LOAM 完全跟踪失败，该方法仅少量失效，仍能输出有效位姿。
2. **运行效率显著优化**：
    - 平均每帧耗时 0.031s，运行速度是 LOAM 的 2.23 倍，摆脱了传统 ICP 算法的耗时限制；
    - 初始化时间缩短至 8s（LOAM ICP 初始化约 11s），适配实时定位与建图需求。
3. **鲁棒性与工程适配性强**：
    - 回环检测有效抑制累积误差，实现全局地图对齐，大场景下轨迹与真实值高度贴合；
    - 支持手持式建模设备，适配大疆 Livox Avia 激光雷达，可应用于室外多路况（市区、乡村、高速）与室内工业场景；
    - 体素化处理与高斯模糊降噪提升特征匹配稳定性，减少动态干扰。
4. **应用价值突出**：
    - 融合方案兼顾 LOAM 的特征提取优势、BA 的位姿优化能力与 NDT 的回环检测功能，解决了单一算法的性能短板；
    - 定位精度与实时性均满足工程需求，为机器人自主导航、三维建模提供可靠技术支撑。
5. **现存优化方向**：
    - 可进一步提升极端动态环境下的回环检测准确率；
    - 可融合 IMU 数据，增强高速移动场景下的位姿估计稳定性。


### 基于 LOAM 改进的室外激光雷达即时定位与建图（陆光满）


[[基于LOAM改进的室外激光雷达即时定位与建图_陆光满.pdf]]
==对传统的LOAM算法的改进优化，不过更建议用LeGo-LOAM==
#### 一、摘要（解决的问题）

针对传统 LOAM 算法在室外场景下存在的特征提取鲁棒性不足、点云无序处理复杂、缺乏回环检测导致累积误差等问题，提出一套改进的激光 SLAM 方案，具体解决方案如下：

1. **核心痛点**：
    - LOAM 基于曲率的特征提取在室外几何结构退化场景（如空旷区域）效果不佳，特征点分布不均；
    - 激光雷达点云无序且包含大量地面点，增加计算负担，传统有序化方法易丢失维度信息；
    - 缺乏后端回环检测与全局优化，长时间运行后里程计累积误差导致地图漂移。

为此，研究从四方面优化：

- 点云预处理：采用平面拟合分割地面点，基于距离信息对非地面点进行有序化编码，避免维度丢失；
- 特征提取：改进 PCA 算法，动态选择临近点拟合平面，按距离自适应选择特征点数量，提升鲁棒性；
- 里程计优化：构建点到线、点到面距离残差，通过非线性优化估计位姿；
- 后端优化：基于位姿变化选择关键帧，采用 Scan Context 进行回环检测，结合 ICP/NDT 精配准与因子图优化，抑制累积误差。

#### 二、结论（实现的效果）

1. **定位精度显著提升**：
    - KITTI 数据集测试中，平均平移误差仅 1.18%，平均旋转误差 0.0052 degree/m，较 ALOAM（平移 4.18%、旋转 0.0173 degree/m）分别降低 71% 和 69%，较 FLOAM 平移误差降低 19%、旋转误差降低 7.1%；
    - 轨迹与地面真值高度重合，绝对位姿误差（APE）及均方根误差（RMSE）均小于对比算法，系统稳定性更优。
2. **特征提取与点云处理更高效**：
    - 改进 PCA 算法特征提取耗时 29ms，较原始 PCA（40ms）提速 27.5%，自适应特征提取使特征点分布更均匀，减少后续计算负担；
    - 距离编码有序化方法适配不同分辨率激光雷达，避免维度丢失，地面分割后点云数量显著减少，降低计算复杂度。
3. **回环检测与全局优化效果显著**：
    - Scan Context 回环检测能有效识别不同方向的回环场景（如十字路口），结合 ICP/NDT 精配准提升检测准确性；
    - 因子图优化整合里程计约束与回环约束，大幅减少地图漂移，优化后地图无明显错位，全局一致性良好。
4. **鲁棒性与实时性达标**：
    - 在 KITTI（城市、高速、乡村）和 MVSECD（室外园区）数据集上均表现优异，无需调整参数即可适配不同场景与激光雷达，鲁棒性强；
    - 前端里程计总耗时 76ms（地面分割 26ms + 特征提取 29ms + 位姿估计 21ms），后端回环优化耗时 290ms（低频率执行），满足室外大场景实时定位与建图需求。
5. **现存优化方向**：
    - 可增加动态物体点云滤波功能，减少移动物体对配准精度的影响；
    - 未来可融合 IMU、视觉传感器，进一步提升复杂环境下的系统鲁棒性。



### 基于 3D 激光的室外清扫机器人定位与建图算法研究（李昶）


[[基于3D激光的室外清扫机器人定位与建图算法研究_李昶.pdf]]
==不是基于常见的ROS建图算法来实现的，而是自己手搓的==


在该文档研究中，**未直接使用 LOAM 或 GMapping 算法进行建图**，而是基于 3D 激光雷达点云数据，结合自定义优化策略构建适配室外清扫机器人的障碍栅格地图，建图过程以 “点云预处理→障碍物检测→八叉树地图构建” 为核心流程
#### 一、摘要（解决的问题）

针对室外清扫机器人在复杂场景下定位精度不足、建图适配性差、计算资源有限等问题，结合 3D 激光雷达与 GPS 的优势提出一体化解决方案，具体如下：

1. **核心痛点**：
    - 室外场景障碍物复杂（含车辆、行人、树叶堆等），传统算法易误判树叶堆为障碍，影响清扫路径规划；
    - 激光里程计长时间工作累积误差大，GPS 易受遮挡干扰，单一传感器定位鲁棒性不足；
    - 3D 点云数据量大，清扫机器人计算资源有限，难以实现实时定位与建图。

为此，研究从三方面优化：

- 可通行区域构建：改进深度聚类算法，结合激光强度检测树叶堆等特殊障碍，通过八叉树构建障碍栅格地图；
- 多传感器融合定位：构建 GPS 与激光里程计的位姿协方差矩阵，通过位姿图优化融合数据，添加闭环检测提升全局一致性；
- 轻量化激光里程计：剔除不可靠特征点、减少线特征数量、加入平面运动约束，降低计算耗时。

#### 二、结论（实现的效果）

1. **障碍检测与建图精准适配清扫场景**：
    - 改进深度聚类算法（更正系数 0.4）可精准分割障碍物，结合激光强度（树叶反射率约 60%）成功区分树叶堆与固体障碍，树叶堆检测准确率高；
    - 八叉树障碍栅格地图存储高效，可通行区域划分清晰，适配全覆盖路径规划需求。
2. **融合定位精度显著提升**：
    - 实际场景测试中，激光里程计 500m 累积误差从 8m 降至 2m，闭环检测后垂直方向误差从 2.2m 降至 0.7m；
    - GPS 与激光雷达融合后，抗遮挡能力增强，无 GPS 信号时激光里程计可维持高精度定位，全局轨迹平滑无明显漂移。
3. **轻量化设计兼顾实时性与精度**：
    - 线特征点从平均 3323 个降至 632 个，平面特征点从 1833 个降至 321 个，激光里程计总耗时降至原本的 1/4；
    - 加入平面运动约束，有效抑制崎岖路面的俯仰角与垂直位移误差，鲁棒性提升。
4. **工程实用性强**：
    - 基于 Velodyne VLP-16 激光雷达与 GPS 搭建硬件平台，软件系统集成定位、建图、路径规划功能；
    - 实际场景测试中，机器人可精准避障、全覆盖清扫，适配道路两侧、车位等室外场景。
5. **现存优化方向**：
    - 需添加动态物体检测功能，减少行人、移动车辆对定位的干扰；
    - 可融合 IMU 数据，提升机器人高速运动时的定位精度。





### 基于特征点匹配和卡尔曼滤波的抖动去除前处理 VSLAM 算法优化（柴立平）

[[基于特征点匹配和卡尔曼滤波的抖动去除前处理VSLAM算法优化_柴立平.pdf]]
==视觉SLAM的优化论文==
#### 一、摘要（解决的问题）

针对视觉 SLAM（以 ORB-SLAM 为基础）在实际应用中因相机抖动导致的特征匹配失效、建图精度下降等问题，提出融合 ORB 特征点跟踪与卡尔曼滤波的抖动抑制优化方案，具体如下：

1. **核心痛点**：
    - 相机抖动（如结构振动、路面不平导致）使连续帧间差异过大，引发特征点误匹配，甚至跟踪丢失；
    - 抖动导致轨迹估计偏差，建图误差累积，尤其大幅抖动下 SLAM 系统稳定性极差。

为此，研究在 SLAM 前端添加预处理模块：

- 分区块特征匹配：将图像划分为中央 5 个区块，通过权重分配与汉明距离阈值筛选，提升匹配准确性；
- 抖动计算与补偿：基于匹配点坐标差计算帧间抖动幅度，利用卡尔曼滤波平滑运动波形，求解抖动补偿值；
- 画面矫正：通过移动取景框抵消抖动，保证输入 SLAM 系统的图像稳定。

#### 二、结论（实现的效果）

1. **抖动抑制效果显著**：
    - 小幅抖动（±10 像素、高斯分布抖动）下，平均误差最高降低 7.68%，均方根误差（RMSE）最高降低 11.19%；
    - 大幅抖动（±15 像素）下，优化效果更突出，平均误差最高降低 74.89%，RMSE 最高降低 56.93%，避免了原版算法的跟踪丢失问题。
2. **轨迹与建图精度提升**：
    - 矫正后轨迹更贴近真实值，拐角与平直路段均无明显偏离，轨迹长度误差率较原版算法降低 30%-70%；
    - 绝对轨迹误差（APE）大幅缩小，V101 数据集 15 像素抖动下，最大误差从 3.52m 降至 0.26m，优化效果极具工程价值。
3. **鲁棒性与适配性强**：
    - 适配室内狭小场景（V101 数据集）与工厂复杂场景（MH01 数据集），对不同类型抖动（均匀分布、高斯分布）均有效；
    - 仅在 SLAM 前端进行预处理，不改动核心框架，可迁移至多种 VSLAM 算法。
4. **工程实用性高**：
    - 特征点匹配效率未受显著影响，ORB 特征本身计算快速，分区块策略未额外增加过多耗时；
    - 取景框边缘扩展处理避免了图像割裂感，保证特征提取完整性。
5. **现存优化方向**：
    - 可进一步优化区块划分与权重分配策略，适配更多场景；
    - 可融合 IMU 数据，提升极端抖动下的实时补偿速度。

---


## 1116
### 基于环境结构信息的移动机器人多模态融合里程计方法研究（张兵）

[基于环境结构信息的移动机器人多模态融合里程计方法研究_张兵](论文pdf/基于环境结构信息的移动机器人多模态融合里程计方法研究_张兵.pdf)
==视觉 - 激光雷达 - IMU多模态融合==
#### 一、摘要（解决的问题）

针对移动机器人多模态融合里程计在复杂环境中面临的**特征关联缺失、数据关联无量化、传感器退化失效、环境适配性差**四大核心痛点，结合环境结构信息从多特征融合与多传感器耦合两维度提出优化方案，具体如下：

1. 核心痛点

- **视觉惯性里程计缺陷**：图像线特征跟踪不稳定，点线特征间缺乏数据关联，结构线约束不完整，导致视觉观测约束不足；
- **激光雷达惯性里程计局限**：点云特征数据关联缺乏定量评估，特征匹配无动态权重分配，易因误匹配陷入局部最优；
- **传感器退化应对不足**：激光雷达（如遮挡、稀疏场景）或相机（如光照变化、纹理缺失）退化时，系统定位稳定性骤降；
- **环境适配性差**：多传感器耦合机制与内部参数固定，无法随场景结构化程度（如室内外切换、空旷 / 密集环境）动态调整。

2. 解决方案

围绕 “视觉 - 激光雷达 - IMU” 多模态融合，分四层突破：

- **视觉惯性优化**：提出点线混合跟踪算法（近邻点预测线特征 + 相似度 - 描述子双匹配），构建线点绑定观测模型；结合消失点检测提取竖直结构线，引入重力共线约束，补充空间一致性误差模型；
- **激光雷达惯性优化**：从点云中分割骨架特征（基于结构主方向），设计特征关联可靠度监测器（量化欧氏距离一致性）；提出加权固定滞后平滑算法，动态调整特征在了你优化中的权重；
- **退化场景鲁棒性提升**：以 IMU 为核心构建松耦合多传感器融合框架，视觉子模块加动态权重位置一致性约束，激光雷达子模块用递进式特征关联实现地图配准，IMU 子模块通过激光扫描重构校正偏置；
- **环境自适应调整**：设计场景分析算法（图像 + 点云评估结构化程度 / 复杂度），提出状态解耦帧 - 帧里程计（动态分配传感器测量优势），非结构化场景引入点到高斯曲面马氏距离模型优化配准。

#### 二、结论（实现的效果）

1. 定位精度显著提升

- **视觉惯性里程计**：在 EuRoC/Kaist-VIO 数据集上，定位误差较 VINS-Mono 降低 27.2%~39.5%，点线混合跟踪使稳定跟踪线段数量提升 11.02%，竖直线结构约束有效抑制俯仰角漂移；
- **激光雷达惯性里程计**：M2DGR 数据集测试中，较 A-LOAM、LeGO-LOAM 定位误差分别减少 15.43%、11.08%，长走廊场景 RMSE 从 0.415m 降至 0.244m，避免特征匹配局部最优；
- **多传感器融合方案**：NTU-VIRAL 数据集困难场景（如戈壁、沙滩）中，定位误差较 LVI-SAM、FAST-LIVO 降低 15.7%~55.8%，激光雷达 / 相机退化时仍能稳定输出位姿（如戈壁场景仅 11.91m 误差，对比算法完全漂移）。

2. 鲁棒性与适配性突破

- **特征关联与量化**：特征关联可靠度监测器剔除 4.11% 不可靠关联，加权固定滞后平滑使定位误差再降 9.83%，激光雷达点云配准一致性提升 26.65%；
- **传感器退化应对**：IMU 核心的松耦合框架在单传感器退化时，定位稳定性较紧耦合方案提升 40% 以上，如相机失效时激光雷达惯性子模块仍维持 0.264m RMSE（沙滩场景）；
- **环境自适应**：场景分析算法可精准量化结构化程度（如戈壁场景量化值 0.04，室内场景 7.84），自适应配准策略使非结构化场景配准误差降低 19%，室内外穿梭场景（indoor1 序列）定位误差仅 0.245m。

3. 工程实用性达标

- **实时性**：前端里程计（视觉 / 激光雷达）平均耗时 28.09~46.21ms / 帧，后端优化（固定滞后平滑 / 因子图）耗时≤290ms，适配 Velodyne VLP-32C、Xsens IMU 等常用硬件；
- **场景覆盖**：适配室内（长走廊、办公室）、室外（校园、戈壁、沙滩）、混合场景（室内外穿梭），无需手动调整参数即可实现跨场景稳定运行；
- **模块化可迁移**：各子模块（如点线跟踪、骨架特征提取）可独立集成至现有 SLAM 系统，如视觉子模块可兼容 ORB-SLAM3，激光雷达子模块可适配 LOAM 类算法。

4. 现存优化方向

- 需增强极端动态环境（如密集行人、快速移动物体）下的特征滤波能力；
- 可融合语义信息（如语义分割区分动态 / 静态物体）进一步提升约束精度；
- 长期运行中需优化 IMU 偏置长时漂移校正，减少超大规模场景（如公里级）误差累积。


### 面向退化场景的无人车定位与建图方法研究（高犇）
[面向退化场景的无人车定位与建图方法研究_高犇](论文pdf/面向退化场景的无人车定位与建图方法研究_高犇.pdf)

==基于误差状态迭代卡尔曼滤波（ESIKF）框架==

#### 一、摘要（解决的问题）

针对退化场景（空旷、无纹理、结构重复等，如长直走廊、地下车库）中无人车单一传感器定位漂移、有效约束不足、位姿抖动等问题，以激光 - IMU 里程计为核心，融合相机视觉约束，基于误差状态迭代卡尔曼滤波（ESIKF）框架提出优化方案，具体如下：

1. 核心痛点

- **激光 - IMU 融合局限**：退化场景下激光雷达点云特征稀疏、质量低，传统点面残差构建易引入误匹配，导致位姿漂移严重，建图失败；
- **有效约束不足**：高效采样后虽剔除低质量数据，但退化环境本身可供匹配的特征少，导致车辆位姿出现轻微抖动；
- **单一传感器失效**：激光雷达在无纹理 / 重复结构场景中定位可靠性下降，无法单独提供稳定位姿估计。

2. 解决方案

- 搭建激光雷达 - 相机 - IMU 多传感器硬件平台，定义各传感器坐标系与空间变换关系，建立测量模型与误差模型，推导 ESIKF 滤波框架；
- 改进激光 - IMU 里程计：对构建点面残差的特征点进行高效采样，筛选对位姿约束强的残差输入 ESIKF，解决漂移问题；
- 添加视觉约束：基于激光 - IMU 建立的先验点云地图，通过 LK 光流追踪构建重投影误差，再进行光度误差两步优化，补充有效约束；
- 全流程高效采样：对视觉约束中的重投影误差、光度误差特征点同样进行筛选，避免局部极小值影响。

#### 二、结论（实现的效果）

1. 定位精度显著提升

- 退化场景定位误差控制在 15cm 内：450m 地下车库场景中，SP_Lvio 算法（激光 - 视觉 - IMU 融合）定位误差平均 0.143m，最高不超过 0.20m，远优于传统 Fast_Lio 算法；
- 漂移问题有效解决：长直走廊、空旷草坪等场景中，Fast_Lio 因误匹配出现严重轨迹漂移，改进后的 SP_Lio（激光 - IMU）可基本完成回环，添加视觉约束的 SP_Lvio 轨迹无明显漂移；
- 位姿抖动抑制：SP_Lvio 通过视觉约束补充有效约束，相较于 SP_Lio，轨迹平滑性大幅提升，掉头、转向等场景无明显抖动。

2. 建图质量与鲁棒性达标

- 建图全局一致性良好：地下车库、长直走廊场景中，SP_Lvio 构建的点云地图无重影、错位或断层，重复区域拼接完整；
- 场景适配性强：适配地下车库（空旷 + 弱纹理）、长直走廊（无纹理 + 重复结构）、玻璃栈道（光照变化 + 反射干扰）等多种退化场景，无建图失败情况；
- 抗干扰能力提升：玻璃栈道场景中，激光雷达因反射产生虚假点云，但高效采样可剔除干扰，视觉约束未受光照变化影响，轨迹稳定性良好。

3. 工程实用性强

- 实时性满足需求：基于 ESIKF 框架，结合特征点高效采样，避免冗余计算，适配无人车实际行驶速度（5-15m/s）；
- 硬件兼容性好：基于 Livox Avia 激光雷达、ZED 2 双目相机、BMI088 IMU 搭建平台，软件基于 ROS+PCL+OpenCV 开发，易落地；
- 迭代优化效果显著：从 Fast_Lio 到 SP_Lio（激光 - IMU 高效采样），再到 SP_Lvio（添加视觉约束），定位精度逐步提升，建图质量从 “无法使用” 提升至 “全局一致”。

4. 现存优化方向

- 可添加回环检测模块，进一步消除长时间运行的累积误差；
- 可设计以 IMU 为中心的混合耦合方案，应对激光雷达与相机同时退化的极端场景；
- 可引入自适应卡尔曼滤波，根据不同退化程度动态调整观测与预测权重。




### 基于多传感器融合的智能汽车 SLAM 关键技术研究（史健）

[基于多传感器融合的智能汽车SLAM关键技术研究_史健](论文pdf/基于多传感器融合的智能汽车SLAM关键技术研究_史健.pdf)


==融合运动场景、传感器退化场景，感觉值得研究==

#### 一、摘要（解决的问题）

针对智能汽车在复杂城市环境中 SLAM 系统面临的**快速运动精度下降、单一传感器失效、动态目标干扰**三大核心痛点，围绕 “激光雷达 - 视觉 - IMU” 多传感器融合展开研究，分三阶段提出解决方案：

1. 核心痛点

- **快速运动场景缺陷**：传统 IMU 预积分在快速运动（线速度＞40km/h、角速度＞1.5rad/s）中存在不可交换误差，激光雷达点云运动畸变严重，导致定位漂移；
- **传感器退化失效**：激光雷达在空旷 / 重复结构场景（如长直隧道）特征稀疏，相机在光照变化 / 弱纹理场景特征提取失效，单一传感器无法稳定输出位姿；
- **动态目标干扰**：城市环境中行人、车辆等动态目标导致静态环境假设失效，SLAM 建图出现 “拖影”，定位精度骤降，且现有多目标跟踪（MOT）在快速运动 / 目标遮挡时易失效。

2. 解决方案

（1）快速运动场景：激光雷达 - IMU 融合优化

- 提出**SSPS 预积分算法**（单子样 + 前一子样）：补偿 IMU 快速运动时的不可交换误差，保证积分频率与原始 IMU（200Hz）一致，为畸变去除提供高精度状态；
- 设计**MOGPR 运动畸变去除**（多输出高斯过程回归）：对 SSPS 预积分状态进行概率插值，抑制 IMU 噪声影响，提升点云去畸变精度；
- 因子图紧耦合：融合 SSPS 预积分因子与激光雷达里程计因子，优化车辆状态与 IMU 零偏，修正点云畸变与预积分误差。

（2）传感器退化场景：激光雷达 - 视觉 - IMU 混合融合

- 构建双生子系统：激光雷达 - IMU 子系统提供全局地图，视觉 - IMU 子系统提供冗余约束，通过冗余估计应对单一传感器失效；
- 混合数据关联：提出**八叉树增量自适应平面提取**，从激光地图中提取平面投影点；结合**滑动窗口特征点深度估计**（对极几何约束恢复跟踪失败特征点），构建 “平面投影点 + 图像特征点” 混合重投影误差，作为 ESIKF（误差状态迭代卡尔曼滤波）观测量；
- 轻量化设计：通过哈希表管理体素、关键帧筛选，平衡精度与实时性。

（3）动态场景：MOT 与 SLAM 协同优化

- 提出**Dynam-LVIO 框架**：分离静态环境地图与动态目标地图，利用 MOT（LVI-SORT 算法）跟踪动态目标，剔除点云中的动态干扰；
- 3D 目标状态估计：基于 ESIKF 融合重投影误差（视觉）与 ICP 误差（激光雷达），提升快速运动下目标状态精度；
- 2D 目标流优化 MOT：利用目标状态与地图点构建 2D 目标流，辅助目标预测（应对快速运动）；结合目标地图点与包络框 IoU（交并比），解决目标遮挡时的关联失效问题。

#### 二、结论（实现的效果）

1. 快速运动场景：定位精度显著提升

- **KITTI 数据集验证**：x/y 方向定位 RMSE 较 LIO-SAM 降低 30.08%/31.45%，点云去畸变误差在角速度 3rad/s 时较 LIO-SAM 减少 21.12%，80km/h 高速场景仍能稳定输出位姿；
- **实验室平台测试**：水平旋转实验（角速度 3rad/s）中，x/y/z 方向定位误差较 LIO-SAM 分别降低 62.65%/40.00%/23.40%，减速带颠簸场景（Z 向加速度 ±20m/s²）定位误差降低 37.21%。

2. 传感器退化场景：鲁棒性大幅增强

- **NTU-VIRAL 数据集**：在室内外混合场景中，绝对轨迹误差（ATE）最低 0.08m，较 FAST-LIVO（0.17m）、R3LIVE（0.35m）降低 52.9%/77.1%，空旷广场场景仍维持 0.12m ATE；
- **KITTI 数据集**：隧道 / 弱纹理场景中，ATE 均值 5.07m，较 VINS-MONO（17.01m）、LOAM（7.81m）降低 70.2%/35.1%，双生子系统在单一传感器失效时仍能保持定位连续。

3. 动态场景：动态干扰有效抑制

- **MOT 精度提升**：提出的 LVI-SORT 算法在 KITTI 动态数据集上，高阶跟踪准确度（HOTA）达 79.92%，较 ByteTrack（77.83%）、OC-SORT（76.54%）提升 2%-3%，目标遮挡 / 快速运动时跟踪成功率提升 15%；
- **SLAM 性能优化**：动态场景下定位 ATE 较 LIO-SEGMOT 降低 13.43%-26.74%，建图无明显 “拖影”，如 KITTI 0926-0101 高速场景（含多车辆），地图动态点云剔除率达 90% 以上。

4. 工程实用性验证

- **实时性达标**：激光雷达 - IMU 子系统（LIS）耗时 34.79ms / 帧，视觉 - IMU 子系统（VIS）耗时 36.87ms / 帧，目标检测（YOLO-V5）耗时 16.52ms / 帧，多线程并行后更新频率＞10Hz，适配智能汽车实时需求；
- **硬件兼容性**：适配 Velodyne HDL-64E、Livox Avia 激光雷达，ZED 2 双目相机、BMI088 IMU 等常用硬件，支持车载 / 实验室平台快速部署。

5. 现存优化方向

- 需增强未知动态目标（如突发故障车辆）的检测能力，避免未训练目标干扰；
- 可融合语义分割技术，区分 “动态目标 - 静态背景”，进一步提升约束精度；
- 长期运行中需优化 IMU 零偏长时漂移，减少公里级场景的误差累积。



### 基于非线性优化与深度图对比的 SLAM 算法研究（李俊）

#### 一、摘要（解决的问题）

针对 SLAM 系统在复杂环境中面临的**定位偏移、动态目标干扰**两大核心痛点，提出 “多传感器融合非线性优化 + 动态障碍物滤除” 双方案，具体如下：

1. 核心痛点

- **定位精度不足**：单一传感器存在局限（视觉易受光照影响、激光在弱纹理场景特征稀疏），且传统融合算法未考虑特征点权重差异，导致位姿估计偏移；
- **动态目标干扰建图**：城市环境中行人、车辆等动态目标会在地图中留下 “鬼影”，影响地图复用（如路径规划、全局重定位）。

2. 解决方案

（1）定位优化：多传感器融合非线性优化

- 双生子系统架构：激光雷达 - IMU 紧耦合（LIS 子系统）+ 相机 - IMU 紧耦合（VIS 子系统），相互提供约束与初始值；
- LIS 子系统优化：提取激光点云角点 / 平面点，以点到局部地图的距离为残差，引入激光点曲率权重，提升非线性优化精度；
- VIS 子系统优化：视觉特征点通过激光子图估计深度，在滑窗优化中添加激光帧匹配约束，补充视觉系统尺度信息与稳定性。

(2）建图优化：深度图对比动态障碍物滤除

- 动态点判定：基于视点可视性，通过激光点光路是否穿过其他激光点初步标记动态点；
- 静态点恢复：循环使用不同分辨率深度图对比，修正静态点误判问题；
- 高效遍历策略：将关键帧分批次随机遍历，避免机器人与动态目标同向运动时的轨迹残留。

#### 二、结论（实现的效果）

1. 定位精度显著提升

- 自建 Interior 数据集：算法（R-LVIO）平均定位误差 0.119m，较 LVI-SAM（0.148m）优化 19.6%，较 LIO-SAM（0.267m）优化 55.4%，较 VINS-MONO（0.669m）优化 82.2%；
- 公开 SJTU-ViSYS 数据集：平均 RMSE 0.178m，较同为多传感器融合的 LVI-SAM（0.182m）最高提升 4.4%，在弱光、动态场景中稳定性优于单一传感器算法。

2. 动态障碍物滤除效果显著

- 滤除效率：能识别并滤除 26.8% 的动态点（如行人、车辆轨迹），保留静态环境结构（墙壁、地面等）；
- 场景适配性：适配室内（实验室、走廊）、室外（街道、广场）场景，成功消除动态目标 “鬼影”，地图可直接用于路径规划与重定位；
- 误判修正：通过多分辨率深度图对比，有效恢复被误判的静态点，避免地图信息丢失。

3. 工程实用性验证

- 实时性达标：算法时间复杂度为\(O(n^2)+O(n log n)\)，基于 ROS 框架搭建四轮差速底盘实验平台，支持 16 线激光雷达、鱼眼相机、IMU 数据实时融合；
- 鲁棒性较强：在光照变化、弱纹理、动态目标密集场景中均能稳定运行，定位误差波动控制在 0.41m 内。

4. 现存优化方向

- 可引入惯性冗余系统，降低对单一 IMU 的依赖，避免 IMU 噪声或宕机导致系统崩溃；
- 优化传感器数据同步机制，通过硬件封装统一驱动，减少 ROS 消息延时带来的融合误差；
- 可融合语义分割技术，进一步提升动态目标识别精度，降低静态点误判率。


### Is Ego Status All You Need for Open-Loop End-to-End Autonomous Driving?（开环端到端自动驾驶是否仅需自我状态?）

[开环端到端自动驾驶是否仅需自我状态](论文pdf/开环端到端自动驾驶是否仅需自我状态.pdf)

==对开环端到端模型进行优化，但是L2级别的==

#### 一、摘要（解决的问题）

针对当前开环端到端自动驾驶研究中存在的**评估偏差、模型过度依赖单一信息**两大核心问题，展开深入分析并提出优化方案，具体如下：

1. 核心痛点

- **数据集失衡**：nuScenes 数据集 73.9% 为直驶场景，导致模型易依赖自车状态（速度、加速度等）作为捷径，未充分利用感知信息；
- **评估指标不全面**：现有 L2 距离、碰撞率指标未考量轨迹是否贴合道路边界，高风险轨迹（如偏离车道）未被有效 penalize；
- **模型决策偏置**：现有方法中自车状态对规划结果影响占比过高，感知信息（如相机图像）未充分发挥作用，违背自动驾驶逻辑。

2. 解决方案

- 提出简化基线 BEV-Planner：无需人工标注（边界框、高清地图等），直接基于 BEV 特征与自车查询的交叉注意力预测轨迹；
- 新增评估指标：路缘碰撞率（CCR），量化轨迹与道路边界的冲突概率，弥补现有指标缺陷；
- 系统分析验证：通过扰动图像输入与自车状态，验证两者对规划结果的影响权重，揭示现有模型的依赖问题。

#### 二、结论（实现的效果）

1. 自车状态的主导作用被证实

- 仅依赖自车状态的 Ego-MLP 模型，在现有 L2 距离（平均 0.35m）和碰撞率（平均 0.37%）指标上，与 UniAD、VAD 等复杂多传感器融合模型性能相当；
- 扰动实验表明：相机图像输入被污染（如雪、雾、全黑）时，规划性能仅轻微下降；而自车速度被扰动（如设为 100m/s）时，轨迹完全失效，证实模型对自车状态的过度依赖。

2. 新指标揭示现有模型缺陷

- CCR 指标下，Ego-MLP 平均碰撞率 2.93%，劣于 UniAD（1.93%）和 VAD（2.47%），说明仅依赖自车状态易产生偏离道路的高风险轨迹；
- 现有模型的后处理优化（如 UniAD）虽降低了与其他智能体的碰撞率，却使 CCR 从 1.72% 升至 7.83%，新增道路偏离风险。

3. 简化基线验证评估体系问题

- BEV-Planner 无需感知标注，仅通过 BEV 特征与时间融合，在 L2 距离（平均 0.55m）和碰撞率（平均 0.59%）上表现优于部分复杂模型，证明现有评估体系易被简单模型 “钻空子”；
- 加入地图感知任务后，BEV-Planner+Map 的 L2 距离升至 0.96m，但 CCR 降至 2.60%，说明感知信息在复杂场景（如转弯）中能提升轨迹合理性，但在直驶为主的数据集上拉低平均指标。

4. 核心结论与优化方向

- 现有 nuScenes 开环评估的 SOTA 性能，更多源于自车状态的捷径效应，而非模型对复杂场景的泛化能力；
- 亟需构建更均衡的数据集（增加转弯、复杂交互场景）和更全面的评估指标（如 CCR），避免模型局部优化；
- 未来需降低模型对自车状态的过度依赖，充分发挥感知信息在环境理解中的作用，贴合真实自动驾驶决策逻辑。


---

## 1117
### 数据驱动的端到端自动驾驶技术：演进历程、现状与未来挑战（王瑶）


==介绍了端到端模型的问题痛点、解决方案、后续优化方向==

#### 一、摘要（解决的问题）

针对自动驾驶技术发展中 “模块化架构局限、端到端泛化不足、单车智能瓶颈” 三大核心问题，从技术演进、数据闭环、车路协同三个维度提出系统性解决方案，具体如下：

1. 核心痛点

- **模块化架构缺陷**：传统 “感知 - 决策 - 控制” 分模块设计依赖人工规则，模块间信息传递易累积误差，适配 L3 + 复杂场景时协同成本高、迭代效率低；
- **端到端技术瓶颈**：端到端模型依赖千亿级里程数据，长尾场景（如极端天气、施工路段）数据稀缺，且模型 “黑箱化” 导致可解释性差、安全性验证困难；
- **单车智能局限**：单车传感器存在视野 / 视距盲区，算力物理极限制约实时决策，难以应对 “鬼探头”、超视距预警等复杂交互场景。

2. 解决方案

**（1）技术范式优化：双轨并行架构**

- **模块化主导 L2 及以下场景**：依托 AUTOSAR 标准化架构，通过高成熟度分模块设计（如特斯拉 Autopilot 早期版本、小鹏 XPILOT），保证功能可靠性与工程落地效率；
- **端到端突破 L3 + 场景**：基于 BEV+Transformer 架构（如特斯拉 FSD V12、理想 MindVLA），实现感知 - 决策 - 控制一体化，引入 LLM/VLM/VLA 大模型提升场景推理与可解释性，降低对高精度地图的依赖。

**（2）数据闭环构建：全链路优化**

- 高价值数据生成：通过 NeRF/3DGS 三维重建、GAN / 扩散模型合成极端场景，结合 “影子模式” 采集量产车异常接管数据，解决长尾场景数据稀缺问题；
- 自动化标注与训练：构建 4D-BEV 时序标注框架，结合 AI 自动标注技术（如语义理解驱动标注），降低数据标注成本；依托 HPC 高性能计算中心实现分布式训练，提升模型迭代效率；
- OTA 动态迭代：通过云端训练 - 车端部署 - 数据回传的闭环，实现模型持续优化（如华为乾崑 ADS 4 通过世界引擎生成 1000 倍密度高难场景数据）。

**（3）车路云协同：突破单车局限**

- 路侧全息感知：部署专用激光雷达与边缘计算单元，实现 “车 - 路 - 云” 多节点协同感知，补充超视距信息（如交叉口碰撞预警、盲区变道提示）；
- 云端智能调度：构建云控基础平台，实现多城市交通数据整合与分钟级地图更新，动态分配车端与云端算力（如 NVIDIA DRIVE Thor 芯片支持 VLA 模型实时推理）；
- C-V2X 通信支撑：基于 5G/6G 低时延通信技术，实现车车 / 车路实时数据交互，解决 “鬼探头”、二次事故预防等单车感知盲区问题。

#### 二、结论（实现的效果）

 1. 技术落地成效显著

- **模块化量产普及**：福特 CoPilot 360、奔驰 Drive Pilot 等模块化系统已实现 L2 + 功能规模化落地，自适应巡航、车道保持等基础功能渗透率超 60%，人为操作失误风险降低 30% 以上；
- **端到端突破关键场景**：特斯拉 FSD V12 通过端到端架构，在城区无保护左转、施工路段绕行等场景通过率提升 40%；理想 MindVLA 引入 VLA 大模型后，复杂场景决策推理时长从 7s 延长至 10-30s，长尾场景轨迹误差降低 25%；
- **车路协同试点见效**：国内 17 个智能网联示范区、20 个车路云一体化试点城市验证显示，路侧感知可使单车智能硬件成本下降 40%，路口通信延迟降至 20ms，紧急制动率降低 30%。

2. 数据闭环与仿真效率提升

- 数据生成效率优化：基于 “开悟” 世界模型等工具，1 个 GPU 生成的仿真数据等效 500 台量产车采集效果，极端场景数据覆盖度从 35% 提升至 82%；
- 标注与训练效率提升：4D-BEV 自动化标注使标注速度提升 10 倍，HPC 分布式训练将模型迭代周期从 2 周缩短至 3 天，数据标注成本降低 60%。

3. 产业生态与商业化进展

- **成本下探与场景覆盖**：国产低成本激光雷达（如禾赛 AT128）、端到端轻量化部署（如轻舟智航基于地平线征程 6M 芯片方案），推动智驾功能向 10-15 万元车型渗透，“智驾平权” 加速；
- **垂直场景规模化落地**：港口（西井科技 24h 无人集装箱转运）、矿山（图森未来无人载货汽车日均运营 800km）等封闭场景已实现盈利，Robotaxi 在北上广深等城市完成全无人收费运营试点，单车日均订单超 15 单。

 4. 现存挑战与未来方向

- **待突破瓶颈**：数据质量不均（标注误差率约 5%-8%）、端到端模型可解释性不足（ISO 21448 功能安全标准适配困难）、车路协同标准不统一（跨区域通信协议差异）；
- **核心发展路径**：
    - 技术层面：研发神经符号混合架构提升模型可解释性，探索生物启发式架构（脉冲神经网络）降低车端算力消耗；
    - 生态层面：构建车路云数据共享标准，推动 C-V2X 6G 技术落地，实现 “统一时空底座” 下的多端协同；
    - 政策层面：完善 L3 + 事故责任认定法规，建立跨区域测试标准，降低全球化部署风险。



### 端到端的多任务车辆自动驾驶行为决策模型（欧阳德霖）


==对于端到端自动驾驶模型的算法优化==


#### 一、摘要（解决的问题）

针对自动驾驶端到端决策中 “时空特征融合不足、多任务依赖处理低效、性能与算力失衡” 三大核心问题，提出基于 3D 窗口自注意力机制的多任务端到端模型，具体如下：

1. 核心痛点

- **时空特征提取局限**：传统模型（如 FMNet、Swin-Transformer）多采用 “空间特征单独提取 + 时间特征拼接” 模式，易造成信息损失，难以捕捉驾驶场景中连续视频帧的时空关联性；
- **多任务训练冲突**：现有多任务学习多采用固定线性权重分配损失，忽视速度、转向角、扭矩等任务的特性差异，导致训练过程中任务间相互干扰，收敛效果不佳；
- **算力与性能矛盾**：高精度模型（如 FMNet）计算量过大（424.91 GFLOPs），难以满足车端实时决策需求；轻量化模型（如 Swin-Transformer）虽算力低，但预测准确率不足。

2. 解决方案

（1）时空特征融合优化：3D 窗口自注意力机制

- 提出 3D ST-DSM 模型：基于 Swin-Transformer 架构，采用 3D Patch 分块将视频序列划分为时空立方体，通过 3D 窗口自注意力（3D W-MSA）与 3D 移位窗口自注意力（3D SW-MSA）交替计算，同步提取空间维度（图像像素）与时间维度（连续帧）的关联特征；
- 级联特征浓缩：通过 4 个 Stage 的 Patch 融合层与 3D Swin-Transformer 块级联，逐步下采样并扩充特征通道，实现时空特征的深度挖掘与高效浓缩。

（2）多任务损失动态优化

- 多任务设计：以速度预测、转向角预测为主任务，引入扭矩预测作为辅助任务，通过任务间特征共享提升模型泛化能力；
- 动态权重策略：采用 UWL-2 损失调整策略，基于不确定性理论动态分配速度、转向角任务的损失权重，对辅助扭矩任务采用固定线性权重，平衡主辅任务训练优先级，避免任务冲突。

（3）轻量化架构设计

- 精简模型参数：通过 3D 窗口局部注意力计算替代全局注意力，减少冗余计算，模型参数量控制在 2748 万，仅为 FMNet 的 2.76%；
- 算力优化：优化网络层级与 Patch 分块尺寸，在保证特征提取精度的前提下，将计算量控制在合理范围，适配车端部署需求。

#### 二、结论（实现的效果）

1. 预测精度显著领先

- 主任务性能：在 Udacity 驾驶数据集上，转向角预测准确率 86.32%、速度预测准确率 85.36%，较 FMNet（转向角 83.78%）、MobileT-DSM（转向角 81.69%、速度 83.17%）、Swin-Transformer（转向角 78.91%、速度 80.17%）均有明显提升；
- 误差指标优化：转向角 MAE 降至 0.119 rad、RMSE 0.148 rad，速度 MAE 1.77 km/h、RMSE 2.38 km/h，均为对比模型中最优，表明模型对驾驶行为的预测更精准。

2. 算力与性能平衡优异

- 计算量可控：模型计算量仅 57.48 GFLOPs，仅为传统高精度模型 FMNet（424.91 GFLOPs）的 13.53%，远低于车端实时决策的算力阈值；
- 参数量精简：模型参数量 2748 万，与轻量化模型 Swin-Transformer（2752 万）相当，在保证轻量化的同时实现精度超越。

3. 多任务训练效率提升

- 收敛速度更快：采用 UWL-2 动态损失策略后，模型训练损失收敛速度较固定线性权重策略提升 30% 以上，且收敛后损失值更低，避免局部最优陷阱；
- 任务协同有效：辅助扭矩任务的引入使主任务特征提取更全面，转向角与速度预测的 AUC 值分别达 0.897、0.868，体现任务间的协同增益。

 4. 现存局限与优化方向

- 现有不足：模型可解释性较弱，缺乏极端驾驶场景（如突发碰撞、恶劣天气）的数据验证；
- 未来方向：融合基于规则的方法提升模型可信度，补充极端场景数据增强鲁棒性，结合闭环仿真与大模型进一步优化多模态输入的特征处理能力。


### 端到端深度学习视觉SLAM泛化_李院明

==为当前端到端视觉slam提出两个优化方案==
#### 一、摘要（解决的问题）

现有端到端视觉 SLAM 系统存在泛化性能不足、传统几何方法鲁棒性弱，且在复杂场景中易受干扰的问题，具体痛点及解决方案如下：

1. **核心痛点**：
    - 端到端视觉 SLAM 泛化能力受训练数据集约束，在光照变化、动态遮挡、纹理稀疏等未见场景中表现不稳定，易出现过拟合、尺度漂移等问题；
    - 传统几何方法虽精度较高，但对环境鲁棒性弱，难以适应多变场景，且对人工模型依赖程度高；
    - 现有公开数据集（如部分 SLAM 相关数据集）大小受限且标签不完整，难以涵盖复杂环境变化，影响模型泛化测试范围。

为此，研究提出两类解决方案：

- 方案一（GeoFormer-SLAM 模型）：结合 Transformer 和元学习策略，集成视觉编码器、位置回归器和空间注意模块，采用 SuperPoint 为前端特征提取器，引入多尺度注意力机制增强关键帧特征，实现图像序列端到端的相机轨迹和深度图预测；
- 方案二（联合优化与 EMA 策略）：设计联合损失函数，融合位姿回归误差、深度估计误差和图像重建损失，平衡训练时各任务梯度贡献；采用 EMA（指数滑动平均）机制动态调整模型参数分布，增强对光照、纹理扰动的鲁棒性，同时通过元学习预训练提升模型在新环境中的快速适应性。

#### 二、结论（实现的效果）

1. **模型泛化性能显著提升**：
    - GeoFormer-SLAM 在 TUM、KITTI 及真实室内环境测试中表现优异，ATE（绝对轨迹误差）达 0.17m、VDR（视角漂移率）达 1.83%，RTE（相对轨迹误差）0.11m、DDE（深度估计误差）0.21m，显著优于 ORB-SLAM（ATE 0.34m、VDR 4.32%）和 DeepVO（ATE 0.29m、VDR 3.27%），在复杂未见环境中泛化稳定性强；
    - 联合优化策略有效控制误差波动，在室内场景 5 天不同时点测试中，ATE 波动范围仅 0.17-0.19m，RTE 0.11-0.13m，DDE 0.21-0.24m，VDR 1.83-2.01%，整体稳定性远超传统方法。
2. **环境鲁棒性大幅增强**：
    - EMA 策略与元学习机制提升模型对光照变化、纹理模糊、动态遮挡的适应能力，在低纹理、遮挡场景及跨场景测试中，模型仍能保持高精度轨迹预测，轨迹连续性与环境理解一致性显著提升；
    - 深度特征提取与匹配模块（SuperPoint+LightGlue）减少传统算法干扰，有效降低 RTE 和 ATE，确保模型在真实动态场景中的可靠运行。
3. **工程应用适配性强**：
    - 模型支持轻量化部署，可运行于嵌入式 GPU 平台，以低功耗实现高性能 SLAM，适用于机器人导航、自动驾驶、AR/VR 等工程场景，尤其在 GPS 信号缺失的室内环境中潜力突出；
    - 提供的技术路径为跨场景泛化视觉 SLAM 实施奠定基础，推动视觉 SLAM 从特定任务向通用智能感知发展。
4. **现存优化方向**：
    - 未来可进一步探索自监督训练与大模型驱动的跨模态泛化能力，提升模型对更多复杂场景的适应范围；
    - 可结合更多新兴技术（如图神经网络深度应用）优化特征建模，进一步降低模型对训练数据的依赖，增强在极端环境下的鲁棒性。


### VLA：何时大规模落地_本报记者__赵建国

==就是提出了VLA而已，没啥新的==


#### 一、摘要（解决的问题）

现有智能驾驶技术存在端到端模型推理不可解释、复杂场景应对能力弱，以及 “端到端 + VLM” 方案算力需求高、3D 空间理解不足等问题，具体痛点及解决方案如下：

1. **核心痛点**：
    - 传统端到端模型为 “黑箱” 架构，缺乏显式逻辑推理环节，在异常或罕见场景中决策不可预测；
    - “端到端 + VLM” 方案需处理海量数据与大参数模型，对训练算力要求极高，且车载算力紧张导致联合训练困难，同时存在 3D 空间理解、驾驶知识储备不足等局限；
    - 多模态（视觉、语言、动作）特征对齐难度大，数据获取与训练复杂，现有智驾芯片并非专为大模型设计，难以支撑 VLA 落地运行。

为此，研究提出核心解决方案：

- 方案（VLA 模型架构）：作为多模态大模型驱动的智能体架构，引入思维链实现环境理解与决策推理的可解释性，通过对比学习、注意力机制完成跨模态特征对齐；
- 配套支撑：构建世界模型仿真系统生成高价值数据，借助 RAG 技术整合动态知识库，结合大算力芯片研发与产学研协同，突破数据、算力、技术适配瓶颈。

#### 二、结论（实现的效果）

1. **技术优势显著优于前代方案**：
    - VLA 具备更强泛化性与拟人化决策能力，可模仿人类 “观察 - 思考 - 行动” 逻辑，在潮汐车道、环岛通行等复杂场景中能生成多步规划，而非单步控制指令；
    - 通过仿真系统单日可完成 30 万公里智能驾驶测试，大幅降低对实车数据的依赖，理想汽车世界模型仿真复现率已达 99.9%。
2. **落地进程逐步推进但仍受约束**：
    - 短期（2025~2026 年）已有搭载 VLA 的车型落地，可在高速公路、封闭园区等特定场景实现自动泊车、高速领航等功能；
    - 当前受算力不足、芯片适配性差、极端场景数据积累不足等影响，VLA 实时运行时延、决策可靠性仍需优化，大规模落地需 3~5 年。
3. **长期发展潜力明确**：
    - 中期（2027~2029 年）随着 2000TOPS 及以上大算力芯片量产，VLA 将覆盖城市道路全场景，无接管里程或突破 100 公里，接管率显著下降；
    - 长期（2030 年后）结合专用 AI 芯片与脑机接口技术，有望实现类人驾驶的直觉决策能力，成为 L3 + 自动驾驶与通用人形机器人技术发展的核心范式。

### 基于视觉的机器人端到端策略抓取估计综述_苏康


==建立了完整的端到端抓取估计方法分类框架，服务机器人可以参考==

#### 一、摘要（解决的问题）

现有机器人端到端抓取估计方法缺乏系统分类梳理，且存在泛化性不足、适配场景有限、评价机制单一等问题，具体痛点及解决方案如下：

1. **核心痛点**：
    - 传统抓取方法需分步进行目标定位与姿态估计，易产生错误累积，且端到端策略相关研究缺乏系统性分类与对比分析；
    - 算法通用性不足，多局限于特定对象或场景，对杂乱、遮挡、未知物体的抓取泛化性能差；
    - 模型轻量化程度不够，复杂网络架构导致计算成本高，难以满足机器人实时操作需求；
    - 评价机制单一，侧重 “抓住” 的精度指标，忽视 “抓好” 的拟人化高质量抓取需求。

为此，研究提出核心解决方案：

- 方案（系统分类与梳理框架）：将基于视觉的端到端抓取估计方法分为平面级（含估计抓取接触点、估计定向矩形两类）和空间级（含面向对象、面向场景两类），细分各子类方法并汇总对比；
- 配套支撑：梳理相关公开数据集（如 Cornell、GraspNet-1billion）与评估指标（如抓取成功率、有效抓取率），明确方法优势与局限性，为后续研究提供参考。

#### 二、结论（实现的效果）

1. **方法体系清晰化**：
    - 建立了完整的端到端抓取估计方法分类框架，系统梳理了平面级与空间级各细分方法的技术路径，填补了该领域缺乏系统性综述的空白；
    - 明确了不同方法的适用场景，如平面级方法适用于固定角度抓取，空间级方法可实现 6 自由度灵活抓取，为实际应用提供选型依据。
2. **关键问题凸显与方向明确**：
    - 总结出算法通用性、模型轻量化、评价机制多元化三大核心挑战，指出数据不足、网络复杂、指标单一等关键制约因素；
    - 提出多源数据融合、结构化学习范式、模型压缩、统一多元评价体系等未来发展方向，为技术突破提供指导。
3. **实践参考价值显著**：
    - 汇总了各类方法的抓取成功率等关键指标，如平面级估计接触点方法成功率 73.0%~96.7%，空间级面向对象方法成功率 71.4%~98.38%，为方法优化提供量化参考；
    - 梳理的数据集与评估指标，为后续模型训练、性能验证提供了明确支撑，降低了研究入门门槛。


## 1118
